---
layout: post
title: "NER命名实体识别项目"
date: 2019-07-27 10:36
toc: true
comments: true
categories: 技术学习
tags: 
	- python
	- 机器学习
---

#### NER概述

命名实体识别（NER）是指在文本中识别出特殊对象，这些对象的语义类别通常在识别前被预定义好，预定义类别如人、地址、组织等。命名实体识别不仅仅是独立的信息抽取任务，它在许多大型nlp应用系统如信息检索、自动文本摘要、问答系统、机器翻译以及知识建库（知识图谱）中也扮演了关键的角色。

<!--more-->

##### 数据集

所有数据集中，最常见的数据集为 **CoNLL03 和 OneNotes**，分别常见于粗粒度的NER任务和细粒度的NER任务。

常见的数据集列举如下：

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic@master/pic/2019-07-27-NER命名实体识别项目/1252882-20190418100821087-874379776.png)

##### NER工具

现成的NER工具来源于学界、工业界以及开源项目。列举如下：

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic@master/pic/2019-07-27-NER命名实体识别项目/1252882-20190418100916769-571424262.png)

##### 评估标准

**1. 精确匹配评估**

NER任务需要同时确定实体边界以及实体类别。在精确匹配评估中，只有当实体边界以及实体类别同时被精确标出时，实体识别任务才能被认定为成功。

基于数据的TP、FP以及FN，可以计算NER任务的准确率，召回率以及F-score用于评估任务优劣。

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic@master/pic/2019-07-27-NER命名实体识别项目/1252882-20190418102115228-1520214846.png)

　　

![image-20200519120544842](https://cdn.jsdelivr.net/gh/siyuanzhou/pic@master/pic/2019-07-27-NER命名实体识别项目/image-20200519120544842.png) 

绝大多数的NER任务需要识别多种实体类别，需要对所有的实体类别评估NER的效果。基于这个思路，有两类评估指标：

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic@master/pic/2019-07-27-NER命名实体识别项目/1252882-20190418102220289-1755447297.png)

**2. 宽松匹配评估**

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic@master/pic/2019-07-27-NER命名实体识别项目/1252882-20190418102516690-1859773115.png)

#### 项目原理

##### 实体标注体系

一、BMES  四位序列标注法

B表示一个词的词首位值，M表示一个词的中间位置，E表示一个词的末尾位置，S表示一个单独的字词。

我/S 是/S 广/B 东/M 人/E    （符号标注，‘东’是‘广’和‘人’的中间部分，凑成‘广东人’这个实体）

我/ 是/ 广东人/        （标注上分出来的实体块）

二、BIO  三位标注  (B-begin，I-inside，O-outside)

B-X 代表实体X的开头， I-X代表实体的结尾  O代表不属于任何类型的

三、BIOES   (B-begin，I-inside，O-outside，E-end，S-single)

B 表示开始，I表示内部， O表示非实体 ，E实体尾部，S表示改词本身就是一个实体。

##### 流程

![image-20200509025146955](https://cdn.jsdelivr.net/gh/siyuanzhou/pic@master/pic/2019-07-27-NER命名实体识别项目/image-20200509025146955.png)

```
输入是词向量，这个直接用word2vec训练就能得到
输出是每个句子预测的标签
```

词向量输入到 **BILSTM层** ，然后输出值是这句话每个标签的预测分数，这些分数便是 **CRF层** 的输入，其实没有CRF层我们也可以训练 BILSTM，但是我们就不能保证每次预测的都是对的，因为它有可能胡来，比如比如在B之后再来一个B。第一个预测的是B-PER，下一个预测的是B-ORG，这就不符合自然语言的规则了，所以我们加入了CRF这一层，用来约束这些标签，它可以自动地去学习这些约束。
 那么CRF是怎么学习这些约束的呢？
 简单地说就是计算每个标签下一个标签地概率，概率大就有可能出现这样的标签，概率小就不会出现了。

CRF的**特征函数**的存在就是为了对所给序列观察学习各种特征（n-gram窗口），这些特征就是在限定窗口下的各种词之间的关系。然后一般都会学到这样的一条规律（特征）：B后面不会直接再出现B,B后面接E不会再出现E。这个限定特征会使得CRF的预测结果不出现上述例子的错误。

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic@master/pic/2019-07-27-NER命名实体识别项目/v2-cf73dad66de3c8840ae558cd273d2773_1440w.jpg)