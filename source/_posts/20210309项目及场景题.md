---
layout: post
title: "项目及场景题"
date: 2021-03-10 10:36
toc: true
comments: true
categories: 技术学习
tags:
	- 基础
	- 复习 

---

### 项目

##### 自我介绍

我叫周思远，大工软院19届，现保研到华科计院。在校期间参加过计算机设计大赛等科创竞赛，也获得过三好学生、优秀毕业生，优秀党员等荣誉。

<!--more-->

项目方面，弄过一个毕业论文格式检测系统，在校上线至今检测超4000篇论文，搞过一个类豆瓣的电影推荐系统，现在刚结题一个科技大数据分析项目。
 个人对后台开发比较感兴趣，学过计网，操作系统等核心课程，掌握Java基础知识及底层实现，了解jvm, java并发，innodb等相关内容。大概就这些。

##### 反问：

实习生要求？部门实习生进去干啥活如何培养？

职业规划请教：做架构，还是做业务？

问部门要求、问部门定位、问部门发展等关系部门技术吸引力的地方

请问贵部门在应届毕业生的要求上，基础和应用技能更看重哪方面？

请问贵部门在整个集团中是作为一个怎么样的角色与其他部门做交互？网上的资料比较片面，想详细了解下

##### 大数据项目

爬虫，关键词谷歌爬取？

1.翻墙 自己搭vps

2.通用爬取，结构不同

2.反爬，user-agent模拟，selenium（模拟浏览器）（一个多小时封），换谷歌URL（台湾，香港服务器不同、不同网址有事结构不同），花钱ip代理池（解决），微信->搜狗搜索—>定向爬取（根据微信id封，id解析真实地址，2000次）->三方机构爬取（提微信号）

**数据处理**

不相关，标注软件，每个人不一样（反向标注，修改快）

**实体识别**

通用性

##### 电影推荐

DataModel：DataModel 是用户喜好信息的抽象接口，它的具体实现支持从任意类型的数据源抽取用户喜好信息。Taste 默认提供 JDBCDataModel 和 FileDataModel，分别支持从数据库和文件中读取用户的喜好信息。
    UserSimilarity 和 ItemSimilarity：UserSimilarity 用于定义两个用户间的相似度，它是基于协同过滤的推荐引擎的核心部分，可以用来计算用户的“邻居”，这里我们将与当前用户口味相似的用户称为他的邻居。ItemSimilarity 类似的，计算内容之间的相似度。
    UserNeighborhood：用于基于用户相似度的推荐方法中，推荐的内容是基于找到与当前用户喜好相似的“邻居用户”的方式产生的。UserNeighborhood 定义了确定邻居用户的方法，具体实现一般是基于 UserSimilarity 计算得到的。

​    Recommender：Recommender 是推荐引擎的抽象接口，Taste 中的核心组件。程序中，为它提供一个 DataModel，它可以计算出对不同用户的推荐内容。Recommender是Taste中的核心组件，它可以根据提供的数据模型计算出对不同用户的推荐结果。其中包含的子类可以从内存中缓存其他的推荐结果，因此在低内存情况下可以通过让Java虚拟机取回推荐的结果再输出。在Recommender组件里包含的推荐方法一般会将结果储存在List中，另外estimatePreference()方法还能预估用户对物品的评分。

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105022.png)

![image-20191229215007041](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105023.png)

```java
public class AuthenticationSuccessHandlerImpl implements AuthenticationSuccessHandler {

    @Override
    public void onAuthenticationSuccess(HttpServletRequest request, HttpServletResponse response, Authentication auth)
            throws IOException, ServletException {
        UserAuth userAuth = (UserAuth) auth.getPrincipal();
        HttpSession session = request.getSession();
        switch (userAuth.getRole()) {
        case "ADMIN":
            session.setAttribute("id", userAuth.getId());
            session.setAttribute("name", userAuth.getUsername());
            session.setAttribute("role", "ADMIN");
            response.sendRedirect("admin");
            break;
        case "USER":
            session.setAttribute("id", userAuth.getId());
            session.setAttribute("name", userAuth.getUsername());
            session.setAttribute("role", "USER");
            response.sendRedirect("user");
            break;
        }
    }
}
```

##### 论文格式检测系统

**文档英文，自己摸索对应关系，有错误的，段落格式，单字格式**

**瞎搞，把无关的文档往里面传，系统崩溃，try catch** 

**修改论文，有些不能改，只能给提示**

（1） 研究word论文格式与对应的xml映射关系，利用OpenXML等工具研究word下.doc及.docx文件实现过程中用到的标签、类、库，为提取属性及属性对比打下基础。

（2） 如何从xml中提取格式特征,即利用C#语言提取出每个格式特征的XML标签，并运用到检测过程当中。

（3） 上传的的论文与指定的模板进行对比，须分别提取上传论文与给定模板的同种属性，依次完成所有属性的对比。

（4） 全面且准确的将word论文格式封装进库，拟建立一个新的架构层次，避免对比过程中出现耦合，利于系统后期维护与升级。

通过修改docx文件的后缀名为zip并解压，或得到一个名为word的文件夹，其包含了一篇Word文档中的全部内容。Word文件夹下的document.xml文件则包含了文档之中绝大多数的文本内容。

**WordprocessingML和命名空间中的类的对照表**

| 包部分   | WordprocessingML元素 | OpenXml SDK中的类 | 说明               |
| -------- | -------------------- | ----------------- | ------------------ |
| 主文档   | document             | Document          | 表示主文档的元素   |
| 页脚     | ftr                  | Footer            | 表示页脚部分的元素 |
| 页眉     | hdr                  | Header            | 表示页眉部分的元素 |
| 文档样式 | styles               | Styles            | 表示样式定义的元素 |

通过上述表中的内容分析，
Paragraph类表示在当前的XML格式文档之中的段落，并使用<.p>标签来表示，通过使用Paragrapgh类可以而已解析OpenXml文档之中的<.p>标签。在WordprocessingML中，使用段落属性<.pPr>元素来表示段落的属性。段落的属性包括字体、字号、颜色、行距、缩进等。而<.rPr>元素在WordprocessingML中表示的则是文档的运行属性，其与文档的段落属性基本一致。一篇有Word编写的文档在其段落之中通常都会傲寒这大量的文本内容，在WordprocessingML文档所使用的架构中，<.r>元素被用来划分文本块中的那些连续的文字。相对于<.r>元素，<.t>元素则相当于一个容器，代替其保存那些文本化的内容。一段连续的文儿内容通常会有相同的属性，这些属性被称为样式或者格式，使用<.r>元素能够保存这些属性的设置，并将其运用在一段连续文本的整体或者部分之中。每一段连续的文本和段落一样都会有自己的属性，<.r>元素的属性则是通过段落运行属性元素<.rPr>来设置，通过对<.rPr>元素的设置，可以对<.t>元素中保存的文本内容加上例如加粗、下划线、颜色、字体、字号等各种各样的属性。

**WordprocessingML表格元素和类的对应关系**

| WordprocessingML元素 | OpenXML SDK中的类                  |
| -------------------- | ---------------------------------- |
| tr tblPr gridCol     | TableRow TableProperties GridColum |
| tblGrid              | TableGrid                          |
| tc                   | TableCell                          |

**2.字号**

< sz>指出了< r>元素中的文本< t>的字号样式。< sz>的属性Val的值代表了字号的大小，如<w:sz w:val=”24”/>代表字号为24/2=12磅。查询字号对照表【参考文献】得到字号和磅数的对应关系，就可以得到实际的字号为“小四”。

### 场景题

##### 在O(1)时间内删除链表节点

![这里写图片描述](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105024.png)

#### 海量数据处理

##### 怎样对10亿个数字（字符串）快速去重？

对于海量数据处理，思路基本上是：必须分块处理，然后再合并起来。

方法一：

通过哈希算法，将10亿个电话号码按照哈希值落在多个文件中，

重复的电话号码有相同的哈希值，肯定位于一个文件中，

这样就可以分别对每个文件排序删除重复的电话号码。

方法二：

使用位图来进行处理。比如说这10亿个数的范围为【0-10亿】，那么就申请一个10亿的数组，

数组类型为boolen，只有0和1，0表示没有，1表示有。

这样自然而然的就删掉了重复的部分。

##### 100亿个数取出最大的10000个

算法：如果把100亿个数全部读入内存，需要100 0000 0000 * 4B 大约40G的内存，这显然是不现实的。　　

我们可以在内存中维护一个**大小为10000的最小堆**，每次从文件读一个数，与最小堆的堆顶元素比较（也可先分割排序），若比堆顶元素大，则替换掉堆顶元素，然后调整堆。最后剩下的堆内元素即为最大的1万个数，算法复杂度为O(NlogN)　　

实现：从文件读数据有讲究，如果每次只读一个数，效率太低，可以维护一个输入缓冲区，一次读取一大块数据到内存，用完了又从文件接着读，这样效率高很多，缓冲区的大小也有讲究，一般要设为4KB的整数倍，因为磁盘的块大小一般就是4KB。

##### 如何在海量数据中找出重复最多⼀个。（提取出某⽇访问百度次数最多的那个IP）

通过hash映射为⼩⽂件
通过hash_map统计各个⼩⽂件重读最多的并记录次数
对每个⼩⽂件重复最多的进⾏建⽴⼤根堆

##### 有10个1G⽂件，每⾏都是⼀个可重复⽤户query，按query频度排序。

顺序读取⼗个⽂件并采取哈希，将query写⼊10个⽂件中
通过hash_map(query, count)统计每个query出现次数，⾄少2G内存
通过得到的hashmap 中 query 和 querycount，对query_count排序并将重新输出到⽂件
中，得到已排序好的⽂件
对⼗个⽂件进⾏归并排序（外排序）

##### A,B两个⽂件各存放50亿url，每个为64Byte，限制内存4G找出公共url。

对A和B两个⼤⽂件，先通过url % 1000将数据映射到1000个⽂件中，单个⽂件⼤⼩约
320M（我们只需要检查对应⼩⽂件A1 V B1......，不对应⼩⽂件不会有相同url）
通过hashset 统计，把 A1 的 url 存储到 hashset中，再遍历对应的B1⼩⽂件，检查是否在
hash_set中，若存在则写⼊外存。重复循环处理对应的1000个对。

#### BitMap

32位机器上，对于一个整型数，比如int a=1 在内存中占32bit位，这是为了方便计算机的运算。但是对于某些应用场景而言，这属于一种巨大的浪费，因为我们可以用对应的32bit位对应存储十进制的0-31个数，而这就是Bit-
map的基本思想。Bit-map算法利用这种思想处理大量数据的排序、查询以及去重。 Bitmap在用户群做交集和并集运算的时候也有极大的便利。

![image-20210408124030233](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105025.png)

![image-20210408124139472](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105026.png)

![image-20210408124156380](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105027.png)

#### 常见的限流算法

##### 计数器法

计数器法是限流算法里最简单也是最容易实现的一种算法。比如我们规定，对于A接口来说，我们1分钟的访问次数不能超过100个。那么我们可以这么做：在一开 始的时候，我们可以设置一个计数器counter，每当一个请求过来的时候，counter就加1，如果counter的值大于100并且该请求与第一个 请求的间隔时间还在1分钟之内，那么说明请求数过多；如果该请求与第一个请求的间隔时间大于1分钟，且counter的值还在限流范围内，那么就重置
counter，具体算法的示意图如下：

![image-20210408124654747](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105028.png)

这个算法虽然简单，但是有一个十分致命的问题，那就是临界问题，我们看下图：

![image-20210408124747364](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105029.png)

从上图中我们可以看到，假设有一个恶意用户，他在0:59时，瞬间发送了100个请求，并且1:00又瞬间发送了100
个请求，那么其实这个用户在 1秒里面，瞬间发送了200个请求。我们刚才规定的是1分钟最多100个请求，也就是
每秒钟最多1.7个请求，用户通过在时间窗口的重置节点处突发请求， 可以瞬间超过我们的速率限制。用户有可能
通过算法的这个漏洞，瞬间压垮我们的应用。

##### 滑动窗口

滑动窗口，又称rolling window。为了解决这个问题，我们引入了滑动窗口算法。

![image-20210408124904461](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105030.png)

在上图中，整个红色的矩形框表示一个时间窗口，在我们的例子中，一个时间窗口就是一分钟。然后我们将时间窗
口进行划分，比如图中，我们就将滑动窗口 划成了6格，所以每格代表的是10秒钟。每过10秒钟，我们的时间窗口就会往右滑动一格。每一个格子都有自己独立的计数器counter，比如当一个请求 在0:35秒的时候到达，那么
0:30~0:39对应的counter就会加1。
那么滑动窗口怎么解决刚才的临界问题的呢？我们可以看上图，0:59到达的100个请求会落在灰色的格子中，而
1:00到达的请求会落在橘黄色的格 子中。当时间到达1:00时，我们的窗口会往右移动一格，那么此时时间窗口内的总请求数量一共是200个，超过了限定的100个，所以此时能够检测出来触 发了限流

##### 漏桶算法

漏桶算法，又称leaky bucket。首先，我们有一个固定容量的桶，有水流进来，也有水流出去。对于流进来的水来说，我们无法预计一共有多 少水会流进来，也无法预计水流的速度。但是对于流出去的水来说，这个桶可以固定水流出的速率。而且，当桶满了之后，多余的水将会溢出。

![image-20210408125032043](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105031.png)

##### 令牌桶算法

令牌桶算法，又称token bucket。从图中我们可以看到，令牌桶算法比漏桶算法稍显复杂。首先，我们有一个固定容量的桶，桶里存放着令牌（token）。桶一开始是空的，token以 一个固定的速率r往桶里填充，直到达到桶的容量，多余的令牌将会被丢弃。每当一个请求过来时，就会尝试从桶里移除一个令牌，如果没有令牌的话，请求无法通 过。

令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况
下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送(百科)。

![image-20210408125304994](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105032.png)

**计数器 VS 滑动窗口**
计数器算法是最简单的算法，可以看成是滑动窗口的低精度实现。滑动窗口由于需要存储多份的计数器（每一个格
子存一份），所以滑动窗口在实现上需要更多的存储空间。也就是说，如果滑动窗口的精度越高，需要的存储空间
就越大。
**漏桶算法 VS 令牌桶算法**
漏桶算法和令牌桶算法最明显的区别是令牌桶算法允许流量一定程度的突发。因为默认的令牌桶算法，取走token
是不需要耗费时间的，也就是说，假设桶内有100个token时，那么可以瞬间允许100个请求通过。
令牌桶算法由于实现简单，且允许某些流量的突发，对用户友好，所以被业界采用地较多。当然我们需要具体情况
具体分析，只有最合适的算法，没有最优的算法。

#### 设计一个分布式环境下全局唯一的发号器

##### 1、UUID

常见的方式。可以利用数据库也可以利用程序生成，一般来说全球唯一。
优点：

1. 简单，代码方便。
2. 生成ID性能非常好，基本不会有性能问题。 \3. 全球唯一，在遇见数据迁移，系统数据合并，或者数据库变更
   等情况下，可以从容应对。

缺点：

1. 没有排序，无法保证趋势递增。
2. UUID往往是使用字符串存储，查询的效率比较低。
3. 存储空间比较大，如果是海量数据库，就需要考虑存储量的问题。
4. 传输数据量大
5. 不可读。

##### 2、数据库自增长序列或字段

最常见的方式。利用数据库，全数据库唯一。
优点：

1. 简单，代码方便，性能可以接受。
2. 数字ID天然排序，对分页或者需要排序的结果很有帮助。

缺点：

1. 不同数据库语法和实现不同，数据库迁移的时候或多数据库版本支持的时候需要处理。
2. 在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障的风险。
3. 在性能达不到要求的情况下，比较难于扩展。
4. 如果遇见多个系统需要合并或者涉及到数据迁移会相当痛苦。
5. 分表分库的时候会有麻烦。

优化方案：
针对主库单点，如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个
数。比如：Master1 生成的是 1，4，7，10，Master2生成的是2,5,8,11 Master3生成的是 3,6,9,12。这样就可以
有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载。

##### 3、数据库sequence表以及乐观锁

我们可以单独设置一张表，来存储所有表的下一个主键的值，例如现在有A、B、C三个表，sequence表结构如下

![image-20210408205931380](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105033.png)

然后，每当需要获取下一个主键值的时候，首先使用select语句获取主键，然后使用数据库的乐观锁机制去update
这个sequence表，更新成功则说明获取主键成功，更新失败则说明存在并发，当前主键被别的机器抢走了，需要
重新select出新的主键，载update。例如要获取表B的下一个主键，需要发送sql

```sql
select id from sequence where name=B
//获得id=100,更新sequence表
update sequence set id=id+1 where name=B and id=100
```

优点：

1. 操作简单，使用乐观锁可以提高性能
2. 生成的id有序递增，连续
3. 可适用于分布式环境，可以进行分库分表

缺点

1. 需要单独设置一张表，浪费存储空间
2. 数据库更新比较频繁，写压力太大

改进方案
可以将每次获取一个主键，改为每次获取500个或者更多，然后缓存再当前机器中，用完这500个后，再去请求数
据库，做更新操作，可以减少数据库的读写压力，但是会造成主键的不连续

##### 4、Redis生成ID

当使用数据库来生成ID性能不够要求的时候，我们可以尝试使用Redis来生成ID。这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现。
可以使用Redis集群来获取更高的吞吐量。假如一个集群中有5台Redis。可以初始化每台Redis的值分别1,2,3,4,5，然后步长都是5。各个Redis生成的ID为：
A：1,6,11,16,21 B：2,7,12,17,22 C：3,8,13,18,23 D：4,9,14,19,24 E：5,10,15,20,25
这个，随便负载到哪个机确定好，未来很难做修改。但是3-5台服务器基本能够满足器上，都可以获得不同的ID。
但是步长和初始值一定需要事先需要了。使用Redis集群也可以方式单点故障的问题。
另外，比较适合使用Redis来生成每天从0开始的流水号。比如订单号=日期+当日自增长号。可以每天在Redis中生
成一个Key，使用INCR进行累加。
优点：

1. 不依赖于数据库，灵活方便，且性能优于数据库。
2. 数字ID天然排序，对分页或者需要排序的结果很有帮助。

缺点：

1. 如果系统中没有Redis，还需要引入新的组件，增加系统复杂度。
2. 需要编码和配置的工作量比较大。

##### 5、Twitter的snowflake算法

snowflake 是 twitter 开源的分布式ID生成算法，其核心思想为，一个long型的ID：

41 bit 作为毫秒数 - 41位的长度可以使用69年
10 bit 作为机器编号 （5个bit是数据中心，5个bit的机器ID） - 10位的长度最多支持部署1024个节点
12 bit 作为毫秒内序列号 - 12位的计数顺序号支持每个节点每毫秒产生4096个ID序号

```sql
select id from sequence where name=B
//获得id=100,更新sequence表
update sequence set id=id+1 where name=B and id=100
```

![image-20210408210308572](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414105034.png)

Snowflake图示
算法单机每秒内理论上最多可以生成1000*(2^12)，也就是400W的ID，完全能满足业务的需求。
snowflake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数，每个数据中心的机器数
以及统一毫秒可以能的并发数来调整在算法中所需要的bit数。
优点：

1. 不依赖于数据库，灵活方便，且性能优于数据库。
2. ID按照时间在单机上是递增的。

缺点：
在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步，也许有时候也会出现不是全
局递增的情况。