---
layout: post
title: "分布式与中间件复习"
date: 2021-03-11 10:36
toc: true
comments: true
categories: 技术学习
tags:
	- 基础
	- 复习 
---

#### 大型网站架构演化发展历程

![image-20210407163257554](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110734.png)

<!--more-->

1. 拆分：不同的多台服务器上面部署不同的服务模块，模块之间通过RPC通信和调用，用于拆分业务功能，独立部署，多个服务器共同组成一个整体对外提供服务。
2. 集群：不同的多台服务器上面部署相同的服务模块，通过分布式调度软件进行统一的调度，用于分流容灾，降低单个服务器的访问压力。



##### 初始阶段的网站架构

小型网站最开始没有太多人访问，只需要一台服务器就绰绰有余，应用程序、数据库、文件等所有资源都在一台服务器上。这时的网站架构如下图所示：

![image-20210407162234274](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110735.png)

##### 应用服务和数据服务分离

```
应用服务器需要处理大量的业务逻辑，因此需要更快更强大的CPU；
数据库服务器需要快速磁盘检索和数据缓存，因此需要更快的磁盘和更大的内存；
文件服务器需要存储大量用户上传的文件，因此需要更大的硬盘。
```

![image-20210407162339201](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110736.png)

##### 使用缓存改善网站性能

如果把这一小部分数据缓存在内存中，就可以减少数据库的访问压力，提高整个网站的数据访问速度，改善数据库的写入性能了。

```
本地缓存的访问速度更快一些，但是受应用服务器内存限制，其缓存数据量有限，而且会出现和应用程序争用内存的情况。
远程分布式缓存可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器，可以在理论上做到不受内存容量限制的缓存服务。
```

![image-20210407162524730](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110737.png)

##### 使用应用服务器集群改善网站的并发处理能力

通过负载均衡调度服务器，可以将来自用户浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多用户，就在集群中加入更多的应用服务器，使应用服务器的压力不再成为整个网站的瓶颈。

![image-20210407162559564](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110738.png)

##### 数据库读写分离

目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器的数据更新同步到另一台服务器上。

![image-20210407162717596](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110739.png)

##### 使用反向代理和 CDN 加速网站响应

CDN 和反向代理的基本原理都是缓存。

```
CDN 部署在网络提供商的机房，使用户在请求网站服务时，可以从距离自己最近的网络提供商机房获取数据
反向代理则部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器是反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户
```

使用 CDN 和反向代理的目的都是尽早返回数据给用户，一方面加快用户访问速度，另一方面也减轻后端服务器的负载压力。

![image-20210407162753331](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110740.png)

##### 使用分布式文件系统和分布式数据库系统

分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务分库，将不同业务的数据部署在不同的物理服务器上。

![image-20210407162911704](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110741.png)

##### 使用 NoSQL 和搜索引擎

NoSQL 和搜索引擎都是源自互联网的技术手段，对可伸缩的分布式特性具有更好的支持。应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。

![image-20210407163015722](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110742.png)

##### 业务拆分

大型网站为了应对日益复杂的业务场景，通过使用分而治之的手段将整个网站业务分成不同的产品线。如大型购物交易网站都会将首页、商铺、订单、买家、卖家等拆分成不同的产品线，分归不同的业务团队负责。
具体到技术上，也会根据产品线划分，将一个网站拆分成许多不同的应用，每个应用独立部署。应用之间可以通过一个超链接建立关系（在首页上的导航链接每个都指向不同的应用地址），也可以通过消息队列进行数据分发，当然最多的还是通过访问同一个数据存储系统来构成一个关联的完整系统，如下图所示：

![image-20210407163152524](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110743.png)

##### 分布式微服务

随着业务拆分越来越小，存储系统越来越庞大，应用系统的整体复杂度呈指数级增加，部署维护越来越困难。由于所有应用要和所有数据库系统连接，在数万台服务器规模的网站中，这些连接的数目是服务器规模的平方，导致数据库连接资源不足，拒绝服务。
既然每一个应用系统都需要执行许多相同的业务操作，比如用户管理、商品管理等，那么可以将这些**共用的业务提取出来，独立部署**。由这些可复用的业务连接数据库，提供共用业务服务，而应用系统只需要管理用户界面，通过分布式服务调用共用业务服务完成具体业务操作。如下图所示：

![image-20210407163251463](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110744.png)

#### 数据库架构发展历程

##### 单机MySQL的美好年代

![image-20210408103732149](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110745.png)

##### Memcached(缓存)+MySQL+垂直拆分

![image-20210408103912789](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110746.png)

Memcached作为一个独立的分布式的缓存服务器，为多个web服务器提供了一个共享的高性能缓存服务，在
Memcached服务器上，又发展了根据hash算法来进行多台Memcached缓存服务的扩展，然后又出现了一致性
hash来解决增加或减少缓存服务器导致重新hash带来的大量缓存失效的弊端

##### Mysql主从复制读写分离

由于数据库的写入压力增加，Memcached只能缓解数据库的读取压力。读写集中在一个数据库上让数据库不堪重负，大部分网站开始使用主从复制技术来达到读写分离，以提高读写性能和读库的可扩展性。Mysql的master-slave模式成为这个时候的网站标配了。

![image-20210408104213351](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110747.png)

##### 分表分库+水平拆分+mysql集群

在Memcached的高速缓存，MySQL的主从复制，读写分离的基础之上，这时MySQL主库的写压力开始出现瓶颈，而数据量的持续猛增，由于MyISAM使用表锁，在高并发下会出现严重的锁问题，大量的高并发MySQL应用开始使用InnoDB引擎代替MyISAM。

同时，开始流行使用分表分库来缓解写压力和数据增长的扩展问题。这个时候，分表分库成了一个热门技术，是面试的热门问题也是业界讨论的热门技术问题。也就在这个时候，MySQL推出了还不太稳定的表分区，这也给技术实力一般的公司带来了希望。虽然MySQL推出了MySQL Cluster集群，但性能也不能很好满足互联网的要求，只是在高可靠性上提供了非常大的保证。

![image-20210408104334954](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110748.png)

##### NoSQL

![image-20210408104521288](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110749.png)

##### 数据的水平拆分和垂直拆分

当我们使用读写分离、缓存后，数据库的压力还是很大的时候，这就需要使用到数据库拆分了。
数据库拆分简单来说，就是指通过某种特定的条件，按照某个维度，将我们存放在同一个数据库中的数据分散存放
到多个数据库（主机）上面以达到分散单库（主机）负载的效果。
切分模式： 垂直（纵向）拆分、水平拆分。

垂直拆分
一个数据库由很多表的构成，每个表对应着不同的业务，垂直切分是指按照业务将表进行分类，分布到不同的数据
库上面，这样也就将数据或者说压力分担到不同的库上面，如下图：

![image-20210408121335272](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110750.png)

优点：
1. 拆分后业务清晰，拆分规则明确。
2. 系统之间整合或扩展容易。
3. 数据维护简单

缺点：

1. 部分业务表无法join，只能通过接口方式解决，提高了系统复杂度。
2. 受每种业务不同的限制存在单库性能瓶颈，不易数据扩展跟性能提高。
3. 事务处理复杂。

水平拆分
垂直拆分后遇到单机瓶颈，可以使用水平拆分。相对于垂直拆分的区别是：垂直拆分是把不同的表拆到不同的数据库中，而水平拆分是把同一个表拆到不同的数据库中。
相对于垂直拆分，水平拆分不是将表的数据做分类，而是按照某个字段的某种规则来分散到多个库之中，每个表中
包含一部分数据。简单来说，我们可以将数据的水平切分理解为是按照数据行的切分，就是将表中 的某些行切分到一个数据库，而另外的某些行又切分到其他的数据库中，主要有分表，分库两种模式，如图：

![image-20210408121426591](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110751.png)

优点：
1. 不存在单库大数据，高并发的性能瓶颈。
2. 对应用透明，应用端改造较少。
3. 按照合理拆分规则拆分，join操作基本避免跨库。
4. 提高了系统的稳定性跟负载能力。

缺点：

1. 拆分规则难以抽象。
2. 分片事务一致性难以解决。
3. 数据多次扩展难度跟维护量极大。
4. 跨库join性能较差。

```
拆分原则
1. 尽量不拆分，架构是进化而来，不是一蹴而就。(SOA)
2. 最大可能的找到最合适的切分维度。
3. 由于数据库中间件对数据Join 实现的优劣难以把握，而且实现高性能难度极大，业务读取 尽量少使用多表Join -
尽量通过数据冗余，分组避免数据垮库多表join。
4. 尽量避免分布式事务。
5. 单表拆分到数据1000万以内。
切分方
范围、枚举、时间、取模、哈希、指定等

场景3:上海公积金，养老金，社保系统
分析：
    社保系统
    实时性要求不高
    不存在瞬时压力
    大规模分析？
    数据规模大
    数据重要不可丢失
    偏于查询？
方案1：按照用户取模，
带来的问题：后续扩容困难
方案2：按用户ID范围分片（1-1000万=分片1，xxx）
带来的问题：用户活跃度无法掌握，可能存在热点问题
方案3：按省份区县地区枚举
数据分配不一定均匀
```



### 中间件

#### 缓存

##### 为什么要使用缓存

（一）性能 如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入
缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。

![image-20210407164425598](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110752.png)

（二）并发 如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。

![image-20210407164450638](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110753.png)

##### 优秀的缓存系统Redis

```java
	Redis是用C语言开发的一个开源的高性能键值对（key-value）数据库，基于内存运行并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一,也被人们称为数据结构服务器。
	官方提供测试数据，50个并发执行100000个请求,读的速度是110000次/s,写的速度是81000次/s ，且Redis通过提供多种键值数据类型来适应不同场景下的存储需求。目前为止Redis支持的键值数据类型如下：
1) 字符串类型 string：一些复杂的计数功能的缓存。
	1. 存储： set key value
	2. 获取： get key
	3. 删除： del key
	
2) 哈希类型 hash ： map格式，单点登录，cookieId为key，30分钟过期，模拟session
	1. 存储： hset key field value
	2. 获取： hget key field: 获取指定的field对应的值 
			 hgetall key：获取所有的field和value
	3. 删除： hdel key field
	
3) 列表类型 list ： linkedlist格式。支持重复元素,消息队列,分页功能
	1. 添加：
		1. lpush key value: 将元素加入列表左表	
		2. rpush key value：将元素加入列表右边
	2. 获取：lrange key start end ：范围获取
	3. 删除：
		lpop key： 删除列表最左边的元素，并将元素返回
		rpop key： 删除列表最右边的元素，并将元素返回
		
4) 集合类型 set  ： 不允许重复元素,全局去重,交集、并集、差集
	1. 存储：sadd key value
	2. 获取：smembers key:获取set集合中所有元素
	3. 删除：srem key value:删除set集合中的某个元素	
	
5) 有序集合类型 sortedset：不允许重复元素，且元素有顺序,排行榜应用，范围查找，延时应用
	1. 存储：zadd key score value
	2. 获取：zrange key start end [withscores]
	3. 删除：zrem key value
	
通用命令
    1. keys * : 查询所有的键
    2. type key ： 获取键对应的value的类型
    3. del key：删除指定的key value
```

具有如下优点：

```
Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用
Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储
Redis支持数据的备份，即master-slave模式的数据备份
```

 redis的应用场景

```
•	缓存（数据查询、短连接、新闻内容、商品内容等等）
•	聊天室的在线好友列表
•	任务队列。（秒杀、抢购、12306等等）
•	应用排行榜
•	网站访问统计
•	数据过期处理（可以精确到毫秒
•	分布式集群架构中的session分离
```

##### redis为什么这么快

```
纯内存操作
单线程操作，避免了频繁的上下文切换
采用了非阻塞I/O多路复用机制
```

我们的redis-client在操作的时候，会产生具有不同事件类型的socket。在服务端，有一段I/0多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。 需要说明的是，这个I/O多路复用机制，redis还提供了select、epoll、evport、kqueue等多路复用函数库

![image-20210407165146422](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110754.png)

##### Redis持久化

```
1. redis是一个内存数据库，当redis服务器重启，获取电脑重启，数据会丢失，我们可以将redis内存中的数据持久化保存到硬盘的文件中。
2. redis持久化机制：
    1. RDB：默认方式，不需要进行配置，默认就使用这种机制
    * 在一定的间隔时间中，检测key的变化情况，然后持久化数据
    1. 编辑redis.windwos.conf文件
    #   after 900 sec (15 min) if at least 1 key changed
    save 900 1
    #   after 300 sec (5 min) if at least 10 keys changed
    save 300 10
    #   after 60 sec if at least 10000 keys changed
        save 60 10000

        2. 重新启动redis服务器，并指定配置文件名称
        D:\JavaWeb2018\day23_redis\资料\redis\windows-64\redis-2.8.9>redis-server.exe redis.windows.conf	

            2. AOF：日志记录的方式，可以记录每一条命令的操作。可以每一次命令操作后，持久化数据
            1. 编辑redis.windwos.conf文件
            appendonly no（关闭aof） --> appendonly yes （开启aof）

            # appendfsync always ： 每一次操作都进行持久化
            appendfsync everysec ： 每隔一秒进行一次持久化
            # appendfsync no	 ： 不进行持久化
```

##### redis的过期策略及内存淘汰机制

redis采用的是定期删除+惰性删除策略。

定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。 于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。 

**采用定期删除+惰性删除就没其他问题了么?** 

不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。

##### Redis内存淘汰机制

在redis.conf中有一行配置该配置就是配内存淘汰策略的

```
maxmemory-policy volatile-lru
```

1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。应该没人用吧。

 2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。推荐使用，目前项目在用这种。 

3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。应该也没人用吧，你不删最少使用Key,去随机删。 

4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。这种情况一般是把redis既当缓存，又做持久化存储的时候才用。不推荐 

5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。依然不推荐

6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键
空间中，有更早过期时间的key优先移除。不推荐 ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。

**为什么不用定时删除策略?** 

定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略. 

##### 渐进式ReHash

扩展或收缩哈希表需要将 `ht[0]` 里面的所有键值对 rehash 到 `ht[1]` 里面， 但是， 这个 rehash 动作并不是一次性、集中式地完成的， 而是分多次、渐进式地完成的。

如果哈希表里保存的键值对数量不是四个， 而是四百万、四千万甚至四亿个键值对， 那么要一次性将这些键值对全部 rehash 到 `ht[1]` 的话， 庞大的计算量可能会导致服务器在一段时间内停止服务。渐进式rehash的好处在于它采取分为而治的方式，将rehash键值对的计算均摊到每个字典增删改查操作，避
免了集中式rehash的庞大计算量。

以下是哈希表渐进式 rehash 的详细步骤：

1. 为 `ht[1]` 分配空间， 让字典同时持有 `ht[0]` 和 `ht[1]` 两个哈希表。
2. 在字典中维持一个索引计数器变量 `rehashidx` ， 并将它的值设置为 `0` ， 表示 rehash 工作正式开始。
3. 在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 `ht[0]` 哈希表在 `rehashidx` 索引上的所有键值对 rehash 到 `ht[1]` ， 当 rehash 工作完成之后， 程序将 `rehashidx` 属性的值增一。
4. 随着字典操作的不断执行， 最终在某个时间点上， `ht[0]` 的所有键值对都会被 rehash 至 `ht[1]` ， 这时程序将 `rehashidx` 属性的值设为 `-1` ， 表示 rehash 操作已完成。

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110755.png)

在进行渐进式 rehash 的过程中， 字典会同时使用 `ht[0]` 和 `ht[1]` 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 `ht[0]` 里面进行查找， 如果没找到的话， 就会继续到 `ht[1]` 里面进行查找， 诸如此类。

另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 `ht[1]` 里面， 而 `ht[0]` 则不再进行任何添加操作： 这一措施保证了 `ht[0]` 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。

##### 缓存穿透

概念访问一个不存在的key，缓存不起作用，请求会穿透到DB，流量大时DB会挂掉。
解决方案：
采用布隆过滤器，使用一个足够大的bitmap，用于存储可能访问的key，不存在的key直接被过滤；
访问key未在DB查询到值，也将空值写进缓存，但可以设置较短过期时间。

##### 缓存雪崩

大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。
解决方案
可以给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效；
采用限流算法，限制流量；
采用分布式锁，加锁访问。

#### 消息队列

消息队列中间件是分布式系统中重要的组件，主要解决应用耦合，异步消息，流量削锋等问题
实现高性能，高可用，可伸缩和最终一致性架构
使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ

![image-20210307191714942](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110756.png)

缺点：系统可用性降低、系统复杂性提高：怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性、一致性问题

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110757.png)

##### 异步处理

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110758.png)

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110759.png)

##### 应用解耦

场景说明：用户下单后，订单系统需要通知库存系统。传统做法是，订单系统调用库存系统的接口。如下图

![image-20210407225046264](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110800.png)

传统模式的缺点：
假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，同时，订单系统与库存系统耦合

![image-20210407225145007](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110801.png)

订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功
库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作
假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦

##### 流量削锋

流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛
应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。
可以控制活动的人数
可以缓解短时间内高流量压垮应用

![image-20210407225344907](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110802.png)

用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面
秒杀业务根据消息队列中的请求信息，再做后续处理

##### 日志处理

日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下

![image-20210407225433351](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110803.png)

日志采集客户端，负责日志数据采集，定时写受写入Kafka队列
Kafka消息队列，负责日志数据的接收，存储和转发
日志处理应用：订阅并消费kafka队列中的日志数据

##### 消息通讯

消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等
点对点通讯：

![image-20210407225557334](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110804.png)

聊天室通讯：

![image-20210407225619737](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110805.png)



##### 电商系统

![image-20210407225743294](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110806.png)

消息队列采用高可用，可持久化的消息中间件。比如Active MQ，Rabbit MQ，Rocket Mq。
（1）应用将主干逻辑处理完成后，写入消息队列。消息发送是否成功可以开启消息的确认模式。（消息队列返回消息接收成功状态后，应用再返回，这样保障消息的完整性）
（2）扩展流程（发短信，配送处理）订阅队列消息。采用推或拉的方式获取消息并处理。
（3）消息将应用解耦的同时，带来了数据一致性问题，可以采用最终一致性方式解决。比如主数据写入数据库，扩展应用根据消息队列，并结合数据库方式实现基于消息队列的后续处理。

##### 日志收集系统

![image-20210407225849548](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110807.png)

为Zookeeper注册中心，日志收集客户端，Kafka集群和Storm集群（OtherApp）四部分组成。
Zookeeper注册中心，提出负载均衡和地址查找服务
日志收集客户端，用于采集应用系统的日志，并将数据推送到kafka队列
Kafka集群：接收，路由，存储，转发等消息处理
Storm集群：与OtherApp处于同一级别，采用拉的方式消费队列中的数据

##### JMS消息服务

讲消息队列就不得不提JMS 。JMS（JAVA Message Service,java消息服务）API是一个消息服务的标准/规范，允许
应用程序组件基于JavaEE平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。
在EJB架构中，有消息bean可以无缝的与JM消息服务集成。在J2EE架构模式中，有消息服务者模式，用于实现消息与应用直接的解耦。

##### 两种消息模型P2P（Point to Point）,Publish/Subscribe(Pub/Sub)

如果希望发送的每个消息都会被成功处理的话，那么需要P2P模式。

P2P模式包含三个角色：消息队列（Queue），发送者(Sender)，接收者(Receiver)。每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，直到他们被消费或超时。
P2P的特点
每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中)，发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列
接收者在成功接收消息之后需向队列应答成功

![image-20210407230426794](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110808.png)

如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型。

Pub/sub模式包含三个角色主题（Topic），发布者（Publisher），订阅者（Subscriber） 多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。
Pub/Sub的特点
每个消息可以有多个消费者
发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息
为了消费消息，订阅者必须保持运行的状态
为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运
行），它也能接收到发布者的消息。

![image-20210407230510471](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110809.png)

在JMS中，消息的产生和消费都是异步的。对于消费来说，JMS的消息者可以通过两种方式来消费消息。
（1）同步
订阅者或接收者通过receive方法来接收消息，receive方法在接收到消息之前（或超时之前）将一直阻塞；
（2）异步
订阅者或接收者可以注册为一个消息监听器。当消息到达之后，系统自动调用监听器的onMessage方法。

##### 防止消息丢失

由于网络问题，我们很难保证生产者发送的消息能100%到达消息队列服务器，也就是说有消息丢失的可能性，因此，生产者就必须具有消息丢失检测和重发机制，也就是我们常说的消息队列的事物机制

不能把可靠性的保证全部交给TCP，TCP只保证了传输层的可靠传输，但是无法保证与应用层的交互是否出错
TCP无法给应用层任何反馈，因此必须在应用层处理差错
**同步的事务——停止等待**
所谓停止等待协议就是没发送完一组数据后，等待对方确认并且收到确认后，再发送下一组数据。

![image-20210407230625065](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110810.png)

**同步的事务——连续ARQ**
类似于TCP的滑动窗口模型

![image-20210407230654497](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110811.png)

**异步的事务——回调机制**
生产者在发送消息的时候，注册一个回调函数，这样生产者便不用停下来等待确认了，而是可以一直持续发送消
息，当消息到达消息队列服务器的时候，服务器便会调用生产者注册的回调函数，告知生产者消息发送成功了还是
失败了，进而做进一步的处理，从而提高了并发量。

![image-20210407230718032](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110812.png)

#### 负载均衡

##### dns域名解析负载均衡

原理：在DNS服务器上配置多个域名对应IP的记录。例如一个域名www.baidu.com对应一组web服务器IP地址，域名解析时经过DNS服务器的算法将一个域名请求分配到合适的真实服务器上。

![image-20210408160022369](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110813.png)

优点：将负载均衡的工作交给了DNS，省却了网站管理维护负载均衡服务器的麻烦，许多DNS还支持基于地
理位置的域名解析，将域名解析成距离用户地理最近的一个服务器地址，加快访问速度，改善性能。
缺点：目前的DNS解析是多级解析，每一级DNS都可能缓存记录A，当某一服务器下线后，该服务器对应的DNS
记录A可能仍然存在，导致分配到该服务器的用户访问失败。
DNS负载均衡的控制权在域名服务商手里，网站可能无法做出过多的改善和管理。
不能够按服务器的处理能力来分配负载。DNS负载均衡采用的是**简单的轮询算法**，不能区分服务器之间的差异，
不能反映服务器当前运行状态，所以其的负载均衡效果并不是太好。
可能会造成额外的网络问题。为了使本DNS服务器和其他DNS服务器及时交互，保证DNS数据及时更新，使地址
能随机分配，一般都要将DNS的刷新时间设置的较小，但太小将会使DNS流量大增造成额外的网络问题。

##### 反向代理负载均衡

原理：反向代理处于web服务器这边，反向代理服务器提供负载均衡的功能，同时管理一组web服务器，它根据负载均衡算法将请求的浏览器访问转发到不同的web服务器处理，处理结果经过反向服务器返回给浏览器。

![image-20210408160246561](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110814.png)

例如：浏览器访问请求的地址是反向代理服务器的地址114.100.80.10，反向代理服务器收到请求，经过负载均衡算法后得到一个真实物理地址10.0.03，并将请求结果发给真实无服务，真实服务器处理完后通过反向代理服务器返回给请求用户。
优点：部署简单，处于http协议层面。
缺点：使用了反向代理服务器后，web 服务器地址不能直接暴露在外，因此web服务器不需要使用外部IP地址，
而反向代理服务作为沟通桥梁就需要配置双网卡、外部内部两套IP地址。

##### http重定向协议实现负载均衡

原理：根据用户的http请求计算出一个真实的web服务器地址，并将该web服务器地址写入http重定向响应中返回给浏览器，由浏览器重新进行访问。

![image-20210408160410793](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110815.png)

优点：比较简单
缺点：浏览器需要两次次请求服务器才能完成一次访问，性能较差。
http重定向服务器自身的处理能力可能成为瓶颈。
使用http302响应重定向，有可能使搜索引擎判断为SEO作弊，降低搜索排名。

##### 一致性hash+虚拟节点

**一致性hash**——改进的分布式方法

1）求出服务器节点的哈希值， 将其配置到0～232的圆上；

2）用同样的方法求出存储数据的键的哈希值并映射到圆上；

3）从数据映射到的位置开始顺时针查找，将数据保存到找到的第一台服务器上；

4）如果超过232仍然找不到服务器，就保存到第一台服务器上。

![image-20210408161138645](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110816.png)

**虚拟节点：** 

使用一般的hash函数，服务器的映射地点的分布可能出现不均匀的情况。

  为每个物理节点（服务器）在圆环上分配100～200个点，从而抑制分布不均匀，最大限度地减小服务器增减时的缓存重新分布。

![img](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110817.jpg)

#### Zookeeper

##### ZK简述

Zookeeper从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架， 它负责存储和管理大家都关心的数据， 然后接受观察者的注册， 一旦这些数据的状态发生变化， Zookeeper就将负责通知已经在
Zookeeper上注册的那些观察者做出 相应 的反 应 ， 从而 实现集群中类似Master/Slave管理模式

##### 数据结构

![image-20210408164737111](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110818.png)

![image-20210408164850759](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110819.png)

```
此外，znode还有操作权限。如果我们把以上几类属性细化，又可以得到以下属性的细节：
czxid：创建节点的事务的zxid
mzxid：对znode最近修改的zxid
ctime：以距离时间原点(epoch)的毫秒数表示的znode创建时间
mtime：以距离时间原点(epoch)的毫秒数表示的znode最近修改时间
version：znode数据的修改次数
cversion：znode子节点修改次数
aversion：znode的ACL修改次数
ephemeralOwner：如果znode是临时节点，则指示节点所有者的会话ID；如果不是临时节点，则为零。
dataLength：znode数据长度。
numChildren：znode子节点个数。
```

znode中的存在类型
我们知道了zookeeper内部维护了一套数据结构：由znode构成的集合，znode的集合又是一个树形结构。每一个znode又有很多属性进行描述。并且znode的存在性还分为四类，如下如所示：

![image-20210408165138724](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110820.png)

```
znode是由客户端创建的，它和创建它的客户端的内在联系，决定了它的存在性：
PERSISTENT-持久化节点：创建这个节点的客户端在与zookeeper服务的连接断开后，这个节点也不会被删除（除非您使用API强制删除）。
PERSISTENT_SEQUENTIAL-持久化顺序编号节点：当客户端请求创建这个节点A后，zookeeper会根据parent-znode的zxid状态，为这个A节点编写一个全目录唯一的编号（这个编号只会一直增长）。当客户端与zookeeper服务的连接断开后，这个节点也不会被删除。
EPHEMERAL-临时目录节点：创建这个节点的客户端在与zookeeper服务的连接断开后，这个节点（还有涉及
到的子节点）就会被删除。
EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点：当客户端请求创建这个节点A后，zookeeper会根据parent-znode的zxid状态，为这个A节点编写一个全目录唯一的编号（这个编号只会一直增长）。当创建这个节点的客户端与zookeeper服务的连接断开后，这个节点被删除。
另外，无论是EPHEMERAL还是EPHEMERAL_SEQUENTIAL节点类型，在zookeeper的client异常终止后，节
点也会被删除。
```

##### 统一命名服务

![image-20210408165643277](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110821.png)

##### 负载均衡

![image-20210408165657899](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110822.png)

##### 统一配置管理

![image-20210408165714977](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110823.png)

##### 集群管理

![image-20210408165736904](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110824.png)

##### 服务器动态上下线

![image-20210408165752431](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110825.png)

##### 写数据流程

Zookeeper提供的是 弱一致性，CAP限制，读的的数据可能不是最新的，如果想读到最新的数据，应该手动调用sync方法从Leader同步数据

![image-20210408165826077](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110826.png)

##### Leader选举

ZK的Leader负责同步数据，发起选举
1）半数机制：集群中半数以上机器存活，集群可用。所以zookeeper适合装在奇数台机器上。
2）Zookeeper虽然在配置文件中并没有指定master和slave。但是，zookeeper工作时，是有一个节点为leader，
其他则为follower，Leader是通过内部的选举机制临时产生的
3）以一个简单的例子来说明整个选举的过程。
假设有五台服务器组成的zookeeper集群，它们的id从1-5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。

![image-20210408165856735](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110827.png)

```
（1）服务器1启动，此时只有它一台服务器启动了，它发出去的报没有任何响应，所以它的选举状态一直是
LOOKING状态。
（2）服务器2启动，它与最开始启动的服务器1进行通信，互相交换自己的选举结果，由于两者都没有历史数据，
所以id值较大的服务器2胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是
3)，所以服务器1、2还是继续保持LOOKING状态。
（3）服务器3启动，根据前面的理论分析，服务器3成为服务器1、2、3中的老大，而与上面不同的是，此时有三
台服务器选举了它，所以它成为了这次选举的leader。
（4）服务器4启动，根据前面的分析，理论上服务器4应该是服务器1、2、3、4中最大的，但是由于前面已经有半
数以上的服务器选举了服务器3，所以它只能接收当小弟的命了。
（5）服务器5启动，同4一样当小弟
```

### 秒杀

##### 业务特点

![image-20210408095317899](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110828.png)

##### 技术难点

**现有业务的冲击**
秒杀是营销活动中的一种，如果和其他营销活动应用部署在同一服务器上，肯定会对现有其他活动造成冲击，极端情况下可能导致整个电商系统服务宕机。
**直接下订单**
下单页面是一个正常的 URL 地址，需要控制在秒杀开始前，不能下订单，只能浏览对应活动商品的信息。简单来说，需要 Disable 订单按钮。
**页面流量突增**
秒杀活动开始前后，会有很多用户请求对应商品页面，会造成后台服务器的流量突增，同时对应的网络带宽增加，需要控制商品页面的流量不会对后台服务器、DB、Redis 等组件的造成过大的压力

##### 架构设计思想

![image-20210408095639159](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110829.png)

##### 客户端优化

客户端优化主要有两个问题：
**秒杀页面**
秒杀活动开始前，其实就有很多用户访问该页面了。如果这个页面的一些资源，比如 CSS、JS、图片、商品详情
等，都访问后端服务器，甚至 DB 的话，服务肯定会出现不可用的情况。所以一般我们会把这个页面整体进行静态化，并将页面静态化之后的页面分发到 CDN 边缘节点上，起到压力分散的作用。
**防止提前下单**
防止提前下单主要是在静态化页面中加入一个 JS 文件引用，该 JS 文件包含活动是否开始的标记以及开始时的动态下单页面的 URL 参数。同时，这个 JS 文件是不会被 CDN 系统缓存的，会一直请求后端服务的，所以这个 JS 文件一定要很小。当活动快开始的时候（比如提前），通过后台接口修改这个 JS 文件使之生效。

##### API 接入层优化

客户端优化，对于不是搞计算机方面的用户还是可以防止住的。但是稍有一定网络基础的用户就起不到作用了，他会自己写post,因此服务端也需要加些对应控制，不能信任客户端的任何操作。一般控制分为 2 大类：
**限制用户维度访问频率**
针对同一个用户（ Userid 维度），做页面级别缓存，单元时间内的请求，统一走缓存，返回同一个页面。
**限制商品维度访问频率**
大量请求同时间段查询同一个商品时，可以做页面级别缓存，不管下回是谁来访问，只要是这个页面就直接返回。

##### 秒杀整体流程图

![image-20210408102940798](https://cdn.jsdelivr.net/gh/siyuanzhou/pic/img/20210414110830.png)

通过上面流程图就会发现压力最大的地方在哪里？
MQ 排队服务，只要 MQ 排队服务顶住，后面下订单与扣减库存的压力都是自己能控制的，根据数据库的压力，可以定制化创建订单消费者的数量，避免出现消费者数据量过多，导致数据库压力过大或者直接宕机。
库存服务专门为秒杀的商品提供库存管理，实现提前锁定库存，避免超卖的现象。同时，通过超时处理任务发现已抢到商品，但未付款的订单，并在规定付款时间后，处理这些订单，将恢复订单商品对应的库存量。

总结核心思想：**层层过滤**
尽量将请求拦截在上游，降低下游的压力
充分利用缓存与消息队列，提高请求处理速度以及削峰填谷的作用