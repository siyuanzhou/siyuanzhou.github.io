<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="dns-prefetch" href>
  <title>吴恩达深度学习笔记汇总1-神经网络和深度学习 | 既白</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="课程概述在第一门课程中，你将学习如何建立神经网络（包含一个深度神经网络），以及如何在数据上面训练他们。在这门课程的结尾，你将用一个深度神经网络进行辨认猫。 在第二门课中，你将进行深度学习方面的实践，学习严密地构建神经网络，如何真正让它表现良好，因此你将要学习超参数调整、正则化、诊断偏差和方差以及一些高级优化算法，比如 Momentum 和 Adam 算法，犹如黑魔法一样根据你建立网络的方式。">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="吴恩达深度学习笔记汇总1-神经网络和深度学习">
<meta property="og:url" content="/2019/20190725深度学习笔记/index.html">
<meta property="og:site_name" content="既白">
<meta property="og:description" content="课程概述在第一门课程中，你将学习如何建立神经网络（包含一个深度神经网络），以及如何在数据上面训练他们。在这门课程的结尾，你将用一个深度神经网络进行辨认猫。 在第二门课中，你将进行深度学习方面的实践，学习严密地构建神经网络，如何真正让它表现良好，因此你将要学习超参数调整、正则化、诊断偏差和方差以及一些高级优化算法，比如 Momentum 和 Adam 算法，犹如黑魔法一样根据你建立网络的方式。">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1566363171528.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1566363254583.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567135490347.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1566464612563.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1566465632425.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567135805492.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567234361044.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567233331653.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567233610847.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567233540892.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567236406729.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567236488836.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567236637687.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567237433322.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567733781692.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567733935641.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567734655114.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567735347366.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567735737378.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567735912423.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567736049339.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567740474532.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567740766598.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567752808420.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567753315120.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567753897268.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567755100768.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567755679332.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567755790140.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567755423004.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567757169699.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567757112382.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567757689257.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567758056574.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567758554030.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567758516983.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567758732152.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567759099948.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567759963479.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567760037825.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568268534183.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568268627285.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1563967374118.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568683382157.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568792151018.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568792614324.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568794165306.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568794569310.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568796728786.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568797570701.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568797824859.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568798195177.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568798556182.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568798673304.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568949475847.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568949569181.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568949864186.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568950046292.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569221392292.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569221347277.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569221863695.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569222487522.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569222706502.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569223012486.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569223921852.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569223962474.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569224340891.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569224519093.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569224741965.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569225149665.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569225813881.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569225906864.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569227135734.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569227372084.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570245104302.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570245584550.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570245973748.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570246571952.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570247001482.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570247798205.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570261405282.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569288981511.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569289431937.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569289748196.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569289867624.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570244153559.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570862112463.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570862838582.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570863520948.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570863924205.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570865613094.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570866484828.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570866949429.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570867690094.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570868523271.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570869546288.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570872074698.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570930138925.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570930002910.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570931168253.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570931912128.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570933101020.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570937014397.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570938662864.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570939219156.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571559653256.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571559885971.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571559969673.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571560271760.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571560597128.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571560805105.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571561171670.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571561823489.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571562423233.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571563376284.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571575064532.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571576433362.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571577042210.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571577508713.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571577935466.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571578148185.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571578246075.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571578435669.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571579036127.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571579178802.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571579407747.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571796325642.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571796604495.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571796903608.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571797414663.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571798132891.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571799248155.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571799678094.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571799859519.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571800167984.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571800517344.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571800534680.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571800863102.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571801027736.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571801539063.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571811264770.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571811545828.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571812142263.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571812561045.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571812860011.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571813038555.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627162412790.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627162444224.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627164619019.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627164952279.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627165703471.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627170635526.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627170920900.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627172242335.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627172448107.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627173818473.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627174032970.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627174948200.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627175024164.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627175855057.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628114628225.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628114827154.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628114934803.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628115218616.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628115602408.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628115553752.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628115813846.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628120050843.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628120539066.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628120909998.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628121209972.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628121357739.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628121619706.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628122552856.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628122658022.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571036986094.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571037457563.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571037926023.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571038257737.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571038816029.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571038997134.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571039183004.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571039446169.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571040629276.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571041723310.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571042446861.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571043809693.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571043945772.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571044930893.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571057902547.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571058201529.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571058464967.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571059465965.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571102283869.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571188216739.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571188377038.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571188960022.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571189765075.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571190390469.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571191116845.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571191479373.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571194211944.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571194415590.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571194871380.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571195653127.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571196350537.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571197193342.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571206219097.png">
<meta property="og:image" content="/132456/blogSource/_posts/n../assets/blogimg/1571206333247.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571207074320.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571207799664.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571207894300.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571209308057.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571210280755.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571210601665.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571211192176.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571212881333.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571215752213.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571215985146.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571216211587.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571282972958.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571283241947.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571283564069.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571283648650.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571284095137.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571557027383.png">
<meta property="og:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571557303981.png">
<meta property="og:updated_time" content="2023-07-18T13:26:56.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="吴恩达深度学习笔记汇总1-神经网络和深度学习">
<meta name="twitter:description" content="课程概述在第一门课程中，你将学习如何建立神经网络（包含一个深度神经网络），以及如何在数据上面训练他们。在这门课程的结尾，你将用一个深度神经网络进行辨认猫。 在第二门课中，你将进行深度学习方面的实践，学习严密地构建神经网络，如何真正让它表现良好，因此你将要学习超参数调整、正则化、诊断偏差和方差以及一些高级优化算法，比如 Momentum 和 Adam 算法，犹如黑魔法一样根据你建立网络的方式。">
<meta name="twitter:image" content="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1566363171528.png">
  
    <link rel="alternative" href="/atom.xml" title="既白" type="application/atom+xml">
  
  
    <link rel="icon" href="/assets/img/f.ico">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  
<script>
var _hmt = _hmt || [];
(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?a30844fa2bcbce0a9e001fe06cefeddf";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
})();
</script>


</head>
</html>
<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="" class="profilepic">
			<img src="/assets/img/touxiang.jpg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">方既白</a></h1>
		</hgroup>
		
		<p class="header-subtitle">常思己过，莫论人非</p>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/categories/learning">学习</a></li>
	        
				<li><a href="/categories/thinking">生活</a></li>
	        
				<li><a href="/categories/project">项目</a></li>
	        
				<li><a href="/photos">相册</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有</a>
    			
            
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/siyuanzhou" title="github"><i class="icon-github"></i></a>
		        
					<a class="rss" target="_blank" href="/atom.xml" title="rss"><i class="icon-rss"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="/assets/img/touxiang.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">方既白</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>常思己过，莫论人非<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
				
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/siyuanzhou" title="github"><i class="icon-github"></i></a>
			        
						<a class="rss" target="_blank" href="/atom.xml" title="rss"><i class="icon-rss"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 70%">
				
				
					<li style="width: 25%"><a href="/categories/learning">学习</a></li>
		        
					<li style="width: 25%"><a href="/categories/thinking">生活</a></li>
		        
					<li style="width: 25%"><a href="/categories/project">项目</a></li>
		        
					<li style="width: 25%"><a href="/photos">相册</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
<article id="post-20190725深度学习笔记" class="article article-type-post " itemscope itemprop="blogPost">
  <div class="article-inner">  
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      吴恩达深度学习笔记汇总1-神经网络和深度学习
    </h1>
  
	

		
			<span class="archive-article-date">
				阅读量 <span id="busuanzi_value_page_pv"></span>
			</span>
		
        
        <a href="/2019/20190725深度学习笔记/" class="archive-article-date">
  	<time datetime="2019-07-25T02:36:00.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-07-25</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="课程概述"><a href="#课程概述" class="headerlink" title="课程概述"></a>课程概述</h4><p>在第一门课程中，你将学习如何建立神经网络（包含一个深度神经网络），以及如何在数据上面训练他们。在这门课程的结尾，你将用一个深度神经网络进行辨认猫。</p>
<p>在第二门课中，你将进行深度学习方面的实践，学习严密地构建神经网络，如何真正让它表现良好，因此你将要学习超参数调整、正则化、诊断偏差和方差以及一些高级优化算法，比如 Momentum 和 Adam 算法，犹如黑魔法一样根据你建立网络的方式。</p>
<a id="more"></a>
<p>在第三门课中，我们将使用两周时间来学习如何结构化你的机器学习工程。事实证明，构建机器学习系统的策略改变了深度学习的错误。</p>
<p>在第四门课程中，我们将会提到卷积神经网络(CNN(s))，它经常被用于图像领域，你将会在第四门课程中学到如何搭建这样的模型。</p>
<p>最后在第五门课中，你将会学习到序列模型，以及如何将它们应用于自然语言处理，以及其它问题。序列模型包括的模型有循环神经网络（RNN）、全称是长短期记忆网络（LSTM）。你将在课程五中了解其中的时期是什么含义，并且有能力应用到自然语言处理（NLP）问题。</p>
<h4 id="深度学习应用"><a href="#深度学习应用" class="headerlink" title="深度学习应用"></a>深度学习应用</h4><p>对于图像应用，我们经常在神经网络上使用卷积（Convolutional Neural Network），通常缩写为 CNN。对于序列数据，例如音频，有一个时间组件，随着时间的推移，音频被播放出来，所以音频是最自然的表现。作为一维时间序列（两种英文说法 one-dimensional timeseries / temporal sequence）.对于序列数据，经常使用 RNN，一种递归神经网络（RecurrentNeural Network），语言，英语和汉语字母表或单词都是逐个出现的，所以语言也是最自然的序列数据，因此更复杂的 RNNs 版本经常用于这些应用。</p>
<p>从趋近于零开始，然后变成一条直线。这个函数被称作 <strong>ReLU 激活函数</strong>，它的全称是 Rectified Linear Unit。</p>
<h4 id="神经网络编程基础"><a href="#神经网络编程基础" class="headerlink" title="神经网络编程基础"></a>神经网络编程基础</h4><h5 id="二分类-Binary-Classification"><a href="#二分类-Binary-Classification" class="headerlink" title="二分类(Binary Classification)"></a>二分类(Binary Classification)</h5><p>所以在二分类问题中，我们的目标就是习得一个分类器，它以图片的特征向量作为输入，然后预测输出结果𝑧为 1 还是 0，也就是预测图片中是否有猫：</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1566363171528.png" alt="1566363171528"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1566363254583.png" alt="1566363254583"></p>
<h5 id="逻辑回归-Logistic-Regression"><a href="#逻辑回归-Logistic-Regression" class="headerlink" title="逻辑回归(Logistic Regression)"></a>逻辑回归(Logistic Regression)</h5><p>详情见机器学习笔记的逻辑回归模块</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567135490347.png" alt="1567135490347"></p>
<p>损失函数只适用于像这样的单个训练样本，而代价函数是参数的总代价，所以在训练逻辑回归模型时候，我们需要找到合适的w和b，来让代价函数 J 的总代价降到最低。</p>
<h5 id="梯度下降法（Gradient-Descent-）"><a href="#梯度下降法（Gradient-Descent-）" class="headerlink" title="梯度下降法（Gradient Descent ）"></a>梯度下降法（Gradient Descent ）</h5><p>在你测试集上，通过最小化代价函数（成本函数）J(w,b)来训练的参数w和b，</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1566464612563.png" alt="1566464612563"></p>
<h5 id="计算图（Computation-Graph）"><a href="#计算图（Computation-Graph）" class="headerlink" title="计算图（Computation Graph）"></a>计算图（Computation Graph）</h5><p>一个神经网络的计算，都是按照前向或反向传播过程组织的。首先我们计算出一个新的网络的输出（前向过程），紧接着进行一个反向传输操作。后者我们用来计算出对应的梯度或导数。计算图解释了为什么我们用这种方式组织这些计算过程。</p>
<h5 id="使用计算图求导数"><a href="#使用计算图求导数" class="headerlink" title="使用计算图求导数"></a>使用计算图求导数</h5><p>在上一个视频中，我们看了一个例子使用流程计算图来计算函数J。现在我们看看流程图的描述，看看你如何利用它计算出函数J的导数。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1566465632425.png" alt="1566465632425"></p>
<h5 id="逻辑回归中的梯度下降"><a href="#逻辑回归中的梯度下降" class="headerlink" title="逻辑回归中的梯度下降"></a>逻辑回归中的梯度下降</h5><p>本节我们讨论怎样通过计算偏导数来实现逻辑回归的梯度下降算法。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567135805492.png" alt="1567135805492"></p>
<h5 id="m-个样本的梯度下降"><a href="#m-个样本的梯度下降" class="headerlink" title="m 个样本的梯度下降"></a>m 个样本的梯度下降</h5><p>之前学习了应用梯度下降在逻辑回归的一个训练样本上。现在我们想要把它应用在m个训练样本上。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567234361044.png" alt="1567234361044"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">J=0;dw1=0;dw2=0;db=0;</span><br><span class="line">for i = 1 to m</span><br><span class="line">    z(i) = wx(i)+b;</span><br><span class="line">    a(i) = sigmoid(z(i));</span><br><span class="line">    J += -[y(i)log(a(i))+(1-y(i)）log(1-a(i));</span><br><span class="line">    dz(i) = a(i)-y(i);</span><br><span class="line">    dw1 += x1(i)dz(i);</span><br><span class="line">    dw2 += x2(i)dz(i);</span><br><span class="line">    db += dz(i);</span><br><span class="line">J/= m;</span><br><span class="line">dw1/= m;</span><br><span class="line">dw2/= m;</span><br><span class="line">db/= m;</span><br><span class="line">w=w-alpha*dw</span><br><span class="line">b=b-alpha*db</span><br></pre></td></tr></table></figure>
<h5 id="向量化-Vectorization"><a href="#向量化-Vectorization" class="headerlink" title="向量化(Vectorization)"></a>向量化(Vectorization)</h5><p>向量化是非常基础的去除代码中 for 循环的艺术,经验提醒我，当我们在写神经网络程序时，或者在写逻(logistic)回归，或者其他神经网络模型时，应该避免写循环(loop)语句。虽然有时写循环(loop)是不可避免的，但是我们可以使用比如 numpy 的内置函数或者其他办法去计算。当你这样使用后，程序效率总是快于循环(loop)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">a=np.random.rand(1000000)</span><br><span class="line">b=np.random.rand(1000000)</span><br><span class="line">tic=time.time()</span><br><span class="line">c=np.dot(a,b)</span><br><span class="line">toc=time.time()</span><br><span class="line">print(&quot;Vectorization: &quot;+str(1000*(toc-tic))+&quot;ms&quot;)</span><br><span class="line">print(c)</span><br><span class="line">c=0</span><br><span class="line">tic=time.time()</span><br><span class="line">for i in range(1000000):</span><br><span class="line">    c+=a[i]*b[i]</span><br><span class="line">toc=time.time()</span><br><span class="line">print(&quot;For loop: &quot;+str(1000*(toc-tic))+&quot;ms&quot;)</span><br><span class="line">print(c)</span><br><span class="line">-------------------------------------</span><br><span class="line">Vectorization: 0.9992122650146484ms</span><br><span class="line">250263.52748534942</span><br><span class="line">For loop: 486.6981506347656ms</span><br><span class="line">250263.52748535923</span><br></pre></td></tr></table></figure>
<h5 id="向量化逻辑回归"><a href="#向量化逻辑回归" class="headerlink" title="向量化逻辑回归"></a>向量化逻辑回归</h5><p>本次视频中我们将讨论如何实现逻辑回归的向量化计算</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567233331653.png" alt="1567233331653"></p>
<h5 id="向量化-logistic-回归的梯度输出"><a href="#向量化-logistic-回归的梯度输出" class="headerlink" title="向量化 logistic  回归的梯度输出"></a>向量化 logistic  回归的梯度输出</h5><p>本次视频的重点是如何同时向量化地计算 m个数据的梯度，并且实现一个非常高效的逻辑回归算法(Logistic Regression)。dz为预测值与实际值得误差，dw为误差在参数w上的偏导数</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567233610847.png" alt="1567233610847"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567233540892.png" alt="1567233540892"></p>
<p>现在我们利用前五个公式完成了前向和后向传播，也实现了对所有训练样本进行预测和求导，再利用后两个公式，梯度下降更新参数，这样通过一次迭代实现一次梯度下降。</p>
<h5 id="Python-中的广播（Broadcasting）"><a href="#Python-中的广播（Broadcasting）" class="headerlink" title="Python  中的广播（Broadcasting）"></a>Python  中的广播（Broadcasting）</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567236406729.png" alt="1567236406729"></p>
<p>下面再来解释一下 A.sum(axis = 0) 中的参数 axis 。axis  用来指明将要进行的运算在是沿着哪个轴执行，在 numpy  中，0  轴是垂直的，也就是列，而 1 轴是水平的，也就是行。</p>
<p>第二个 A/cal.reshape(1,4) 指令则调用了 numpy 中的广播机制：</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567236488836.png" alt="1567236488836"></p>
<p>如果两个数组的后缘维度的轴长度相符或其中一方的轴长度为 1 ，则认为它们是广播兼容的。广播会在缺失维度和轴长度为 1 的维度上进行。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567236637687.png" alt="1567236637687"></p>
<h5 id="关于numpy向量的说明"><a href="#关于numpy向量的说明" class="headerlink" title="关于numpy向量的说明"></a>关于numpy向量的说明</h5><p>本节主要讲 Python 中的 numpy 一维数组的特性，以及与行向量或列向量的区别，并介绍了老师在实际应用中的一些小技巧，去避免在 coding 中由于这些特性而导致的 bug。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567237433322.png" alt="1567237433322"></p>
<h5 id="Jupyter-快速入门"><a href="#Jupyter-快速入门" class="headerlink" title="Jupyter 快速入门"></a>Jupyter 快速入门</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">命令模式：</span><br><span class="line">    shift + enter : 运行当前单元后，选中下一单元</span><br><span class="line">    ctrl + enter ：只运行当前单元</span><br><span class="line">    Enter: 进入编辑模式</span><br><span class="line">    Y ： 切换code状态</span><br><span class="line">    M ： 切换Markdown状态</span><br><span class="line">    A ：在上方插入单元格</span><br><span class="line">    B ：在下方插入单元格</span><br><span class="line">    连按两次D ：删除当前单元格</span><br><span class="line">    连按两次 I ： 中断内核运行</span><br><span class="line">    C ：复制当前单元格</span><br><span class="line">    shift + v ：粘贴单元格</span><br><span class="line">    shift + Tab：查看当前函数的说明（光标要在函数的位置内如下图所示）</span><br><span class="line"></span><br><span class="line">编辑模式：</span><br><span class="line">    编辑模式暂时用的不多，用到的时候再补充</span><br><span class="line">    shift + enter : 运行当前单元后，选中下一单元</span><br><span class="line">    ctrl + enter ：只运行当前单元</span><br><span class="line">    Esc or Ctrl-M: 进入命令模式</span><br><span class="line"></span><br><span class="line">高级使用技巧</span><br><span class="line">    Cell 内 Undo 用 CTRL + Z，如恢复删除的代码</span><br><span class="line">    Cell 外 Undo 用 ESC + Z，如恢复删除的 Cell</span><br></pre></td></tr></table></figure>
<h5 id="logistic-损失函数的解释"><a href="#logistic-损失函数的解释" class="headerlink" title="logistic  损失函数的解释"></a>logistic  损失函数的解释</h5><p>在逻辑回归中我们需要最小化损失函数，因此最小化损失函数与最大化条件概率的对数关联起来了</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567733781692.png" alt="1567733781692"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567733935641.png" alt="1567733935641"></p>
<h3 id="浅层神经网络"><a href="#浅层神经网络" class="headerlink" title="浅层神经网络"></a>浅层神经网络</h3><h5 id="神经网络概述"><a href="#神经网络概述" class="headerlink" title="神经网络概述"></a>神经网络概述</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567734655114.png" alt="1567734655114"></p>
<h5 id="神经网络的表示"><a href="#神经网络的表示" class="headerlink" title="神经网络的表示"></a>神经网络的表示</h5><p>在传统的符号使用中，如果你阅读研究论文或者在这门课中，你会看到人们将这个神经网络称为一个两层的神经网络，因为我们不将输入层看作一个标准的层。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567735347366.png" alt="1567735347366"></p>
<p>x表示输入特征，a表示每个神经元的输出，W表示特征的权重，上标表示神经网络的层数（隐藏层为 1），下标表示该层的第几个神经元。这是神经网络的 符号惯例.</p>
<h5 id="神经网络的计算"><a href="#神经网络的计算" class="headerlink" title="神经网络的计算"></a>神经网络的计算</h5><p>通过本视频，你能够根据给出的一个单独的输入特征向量，运用四行代码计算出一个简单神经网络的输出。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567735737378.png" alt="1567735737378"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567735912423.png" alt="1567735912423"></p>
<h5 id="多样本神经网络的向量化计算"><a href="#多样本神经网络的向量化计算" class="headerlink" title="多样本神经网络的向量化计算"></a><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567736049339.png" alt="1567736049339">多样本神经网络的向量化计算</h5><p>在这个视频，将会了解到如何向量化多个训练样本，并计算出结果。该过程与你在逻辑回归中所做类似。逻辑回归是将各个训练样本组合成矩阵，对矩阵的各列进行计算。神经网络是通过对逻辑回归中的等式简单的变形，让神经网络计算出输出值。这种计算是所有的训练样本同时进行的，以下是实现它具体的步骤：</p>
<p><strong>非向量化形式</strong>的实现，而且要计算出它的预测值，对于所有训练样本，需要让i从 1 到m实现这四个等式：a[2](1)是指第i训练样本而[2]是指第二层。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567740474532.png" alt="1567740474532"></p>
<p><strong>向量化实现</strong>从水平上看，矩阵A代表了各个训练样本。从竖直上看，矩阵A的不同的索引对应于不<br>同的隐藏单元。对于矩阵Z ， X情况也类似，水平方向上，对应于不同的训练样本；竖直方向上，对应不<br>同的输入特征，而这就是神经网络输入层中各个节点。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567740766598.png" alt="1567740766598"></p>
<h5 id="向量化实现的解释"><a href="#向量化实现的解释" class="headerlink" title="向量化实现的解释"></a>向量化实现的解释</h5><p>在这个视频中，我们将会继续了解到，为什么上一节中写下的公式就是将多个样本向量化的正确实现。</p>
<p> W [1] 是一个矩阵，x(1) ,x(2) ,x (3) 都是列向量，矩阵乘以列向量得到列向量，下面将它们用图形直观的表示出来</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567752808420.png" alt="1567752808420"></p>
<h5 id="激活函数（Activation-functions-）"><a href="#激活函数（Activation-functions-）" class="headerlink" title="激活函数（Activation functions ）"></a>激活函数（Activation functions ）</h5><p>使用一个神经网络时，需要决定使用哪种激活函数用隐藏层上，哪种用在输出节点上。到目前为止，之前的视频只用过 sigmoid 激活函数，但是，有时其他的激活函数效果会更好。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567753315120.png" alt="1567753315120"></p>
<p>在讨论优化算法时，有一点要说明：我基本已经不用 sigmoid 激活函数了，tanh 函数在所有场合都优于 sigmoid 函数。但有一个例外：在二分类的问题中，对于输出层，因为y的值是 0 或 1，所以想让y^ 的数值介于 0 和 1 之间，而不是在-1 和+1 之间。所以需要使用 sigmoid 激活函数。</p>
<p>sigmoid 函数和 tanh 函数两者共同的缺点是，在z特别大或者特别小的情况下，导数的梯度或者函数的斜率会变得特别小，最后就会接近于 0，导致降低梯度下降的速度。</p>
<p>如果输出是 0、1 值（二分类问题），则输出层选择 sigmoid 函数，然后其它的所有单元都选择 Relu(修正线性单元的函数) 函数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sigmoid 激活函数：除了输出层是一个二分类问题基本不会用它。</span><br><span class="line">tanh 激活函数：tanh 是非常优秀的，几乎适合所有场合。</span><br><span class="line">ReLu 激活函数：最常用，如果不确定用哪个激活函数，就使用 ReLu 或者Leaky ReLu。</span><br></pre></td></tr></table></figure>
<h5 id="为什么需要非线性激活函数"><a href="#为什么需要非线性激活函数" class="headerlink" title="为什么需要非线性激活函数"></a>为什么需要非线性激活函数</h5><p>如果你是用线性激活函数或者叫恒等激励函数，那么神经网络只是把输入线性组合再输出。如果你使用线性激活函数或者没有使用一个激活函数，那么无论你的神经网络有多少层一直在做的只是计算线性函数，所以不如直接去掉全部隐藏层。</p>
<p>事实证明如果你在隐藏层用线性激活函数，在输出层用 sigmoid 函数，那么这个模型的复杂度和没有任何隐藏层的标准 Logistic 回归是一样的.</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567753897268.png" alt="1567753897268"></p>
<p>总而言之，不能在隐藏层用线性激活函数，可以用 ReLU 或者 tanh 或者 leaky ReLU 或者其他的非线性激活函数，唯一可以用线性激活函数的通常就是输出层。</p>
<h5 id="激活函数的导数"><a href="#激活函数的导数" class="headerlink" title="激活函数的导数"></a>激活函数的导数</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567755100768.png" alt="1567755100768"></p>
<h5 id="神经网络的梯度下降"><a href="#神经网络的梯度下降" class="headerlink" title="神经网络的梯度下降"></a>神经网络的梯度下降</h5><p>在这个视频中，我会给你实现反向传播或者说梯度下降算法的方程组</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567755679332.png" alt="1567755679332"></p>
<p>训练参数需要做梯度下降，在训练神经网络的时候，随机初始化参数很重要，而不是初始化成全零。当你参数初始化成某些值后，每次梯度下降都会循环计算以下预测值：</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567755790140.png" alt="1567755790140"></p>
<p>下图是正向和反向传播的公式，这些都是针对所有样本进行过向量化。axis=1 表示水平相加求和， keepdims 是防止python 输出那些古怪的秩数(n,)</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567755423004.png" alt="1567755423004"></p>
<h5 id="直观理解反向传播"><a href="#直观理解反向传播" class="headerlink" title="直观理解反向传播"></a>直观理解反向传播</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567757169699.png" alt="1567757169699"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567757112382.png" alt="1567757112382"></p>
<h5 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h5><p>当你训练神经网络时，权重随机初始化是很重要的。对于逻辑回归，把权重初始化为 0当然也是可以的。但是对于一个神经网络，如果你把权重或者参数都初始化为 0，那么梯度下降将不会起作用。</p>
<p>如果你要初始化成 0，由于所有的隐含单元都是对称的，无论你运行梯度下降多久，他们一直计算同样的函数。这没有任何帮助，因为你想要两个不同的隐含单元计算不同的函数，这个 问 题 的 解 决 方 法 就 是 随 机 初 始 化 参 数 。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567757689257.png" alt="1567757689257"></p>
<h4 id="深层神经网络"><a href="#深层神经网络" class="headerlink" title="深层神经网络"></a>深层神经网络</h4><h5 id="深层神经网络-1"><a href="#深层神经网络-1" class="headerlink" title="深层神经网络"></a>深层神经网络</h5><p>但是在过去的几年中，DLI（深度学习学院 deep learning institute）已经意识到有一些函数，只有非常深的神经网络能学会，而更浅的模型则办不到。尽管对于任何给定的问题很难去提前预测到底需要多深的神经网络，所以先去尝试逻辑回归，尝试一层然后两层隐含层，然后把隐含层的数量看做是另一个可以自由选择大小的超参数，然后再保留交叉验证数据上评估，或者用你的开发集来评估。<br>我们再看下深度学习的符号定义：</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567758056574.png" alt="1567758056574"></p>
<h5 id="前向传播和反向传播"><a href="#前向传播和反向传播" class="headerlink" title="前向传播和反向传播"></a>前向传播和反向传播</h5><p>之前我们学习了构成深度神经网络的基本模块，比如每一层都有前向传播步骤以及一个相反的反向传播步骤，这次视频我们讲讲如何实现这些步骤。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567758554030.png" alt="1567758554030"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567758516983.png" alt="1567758516983"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567758732152.png" alt="1567758732152"></p>
<h5 id="深层网络中的前向传播"><a href="#深层网络中的前向传播" class="headerlink" title="深层网络中的前向传播"></a>深层网络中的前向传播</h5><p>我们先来看对其中一个训练样本 x 如何应用前向传播，之后讨论向量化的版本。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567759099948.png" alt="1567759099948"></p>
<h5 id="核对矩阵的维数"><a href="#核对矩阵的维数" class="headerlink" title="核对矩阵的维数"></a>核对矩阵的维数</h5><p>当实现深度神经网络的时候，其中一个我常用的检查代码是否有错的方法就是拿出一张纸过一遍算法中矩阵的维数。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567759963479.png" alt="1567759963479"></p>
<p>向量化后：</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1567760037825.png" alt="1567760037825"></p>
<p>在你做深度神经网络的反向传播时，一定要确认所有的矩阵维数是前后一致的，可以大大提高代码通过率。</p>
<h5 id="为什么使用深层表示"><a href="#为什么使用深层表示" class="headerlink" title="为什么使用深层表示"></a>为什么使用深层表示</h5><p>首先，深度网络究竟在计算什么？如果你在建一个人脸识别或是人脸检测系统，深度神经网络所做的事就是，当你输入一张脸部的照片，然后你可以把深度神经网络的第一层，当成一个特征探测器或者边缘探测器。</p>
<p>你可以直觉上把这种神经网络的前几层当作探测简单的函数，比如边缘，之后把它们跟后几层结合在一起，那么总体上就能学习更多复杂的函数。这些图的意义，我们在学习卷积神经网络的时候再深入了解。</p>
<p>所以深度神经网络的这许多隐藏层中，较早的前几层能学习一些低层次的简单特征，等到后几层，就能把简单的特征结合起来，去探测更加复杂的东西。比如你录在音频里的单词、词组或是句子，然后就能运行语音识别了。同时我们所计算的之前的几层，也就是相对简单的输入函数，比如图像单元的边缘什么的。到网络中的深层时，你实际上就能做很多复杂的事，比如探测面部或是探测单词、短语或是句子。</p>
<p>深层的网络隐藏单元数量相对较少，隐藏层数目较多，如果浅层的网络想要达到同样的计算结果则需要指数级增长的单元数量才能达到。</p>
<h5 id="搭建神经网络块"><a href="#搭建神经网络块" class="headerlink" title="搭建神经网络块"></a>搭建神经网络块</h5><p>这周的前几个视频和之前几周的视频里，你已经看到过正向反向传播的基础组成部分了，它们也是深度神经网络的重要组成部分，现在我们来用它们建一个深度神经网络。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568268534183.png" alt="1568268534183"></p>
<p>这是一个层数较少的神经网络，我们选择其中一层（方框部分），从这一层的计算着手。然后如果实现了这两个函数（正向和反向），然后神经网络的计算过程会是这样的：</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568268627285.png" alt="1568268627285"></p>
<p>在编程练习中你缓存了Z，还有W和b对吧？从实现角度上看，我认为是一个很方便的方法，可以将参数复制到你在计算反向传播时所需要的地方。现在你们见过实现深度神经网络的基本元件，在每一层中有一个正向传播步骤，以及对应的反向传播步骤，以及把信息从一步传递到另一步的缓存。</p>
<h5 id="参数-VS-超参数（Parameters-vs-Hyperparameters-）"><a href="#参数-VS-超参数（Parameters-vs-Hyperparameters-）" class="headerlink" title="参数 VS  超参数（Parameters vs Hyperparameters ）"></a>参数 VS  超参数（Parameters vs Hyperparameters ）</h5><p>想要你的深度神经网络起很好的效果，你还需要规划好你的参数以及超参数。<br>什么是超参数？<br>比如算法中的 learning rate α（学习率）、iterations(梯度下降法循环的数量)、L（隐藏层数目）、n [l] （隐藏层单元数目）、choice of activation function（激活函数的选择）都需要你来设置，这些数字实际上控制了最后的参数W和b的值，所以它们被称作超参数。</p>
<p>实际上深度学习有很多不同的超参数，之后我们也会介绍一些其他的超参数，如momentum、mini batch size、regularization parameters 等等</p>
<p>如何寻找超参数的最优值？走 Idea—Code—Experiment—Idea 这个循环，尝试各种不同的参数，实现模型并观察是否成功，然后再迭代。</p>
<p>有一条经验规律：经常试试不同的超参数，勤于检查结果，看看有没有更好的超参数取值，你将会得到设定超参数的直觉。</p>
<h4 id="深度学习的实践层面"><a href="#深度学习的实践层面" class="headerlink" title="深度学习的实践层面"></a>深度学习的实践层面</h4><p>本周，我们将继续学习如何有效运作神经网络，内容涉及超参数调优，如何构建数据，以及如何确保优化算法快速运行，从而使学习算法在合理时间内完成自我学习。</p>
<p>在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助大家创建高效的神经网络。训练神经网络时，我们需要做出很多决策，例如：<br>神经网络分多少层；每层含有多少个隐藏单元；学习速率是多少；各层采用哪些激活函数。</p>
<h5 id="训练，验证，测试集（Train-Dev-Test-sets-）"><a href="#训练，验证，测试集（Train-Dev-Test-sets-）" class="headerlink" title="训练，验证，测试集（Train / Dev / Test sets ）"></a>训练，验证，测试集（Train / Dev / Test sets ）</h5><p>假设这是训练数据，我用一个长方形表示，我们通常会将这些数据划分成几部分，一部分作为训练集，一部分作为简单交叉验证集，有时也称之为验证集，方便起见，我就叫它验证集（dev set），其实都是同一个概念，最后一部分则作为测试集。<br>接下来，我们开始对训练执行算法，通过验证集或简单交叉验证集选择最好的模型，经过充分验证，我们选定了最终模型，然后就可以在测试集上进行评估了，为了无偏评估算法的运行状况。<br>在机器学习发展的小数据量时代，常见做法是将所有数据三七分，就是人们常说的 70%验证集，30%测试集，如果没有明确设置验证集，也可以按照 60%训练，20%验证和 20%测试集来划分。这是前几年机器学习领域普遍认可的最好的实践方法。</p>
<p>但是在大数据时代，我们现在的数据量可能是百万级别，那么验证集和测试集占数据总量的比例会趋向于变得更小。因为验证集的目的就是验证不同的算法，检验哪种算法更有效，因此，验证集要足够大才能评估，比如 2 个甚至 10 个不同算法，并迅速判断出哪种算法更有效。我们可能不需要拿出 20%的数据作为验证集。</p>
<p>我建议大家要确保验证集和测试集的数据来自同一分布，关于这个问题我也会多讲一些。因为你们要用验证集来评估不同的模型，尽可能地优化性能。如果验证集和测试集来自同一个分布就会很好。</p>
<p>但由于深度学习算法需要大量的训练数据，为了获取更大规模的训练数据集，我们可以采用当前流行的各种创意策略，例如，网页抓取，代价就是训练集数据与验证集和测试集数据有可能不是来自同一分布。</p>
<h5 id="偏差，方差（Bias-Variance）"><a href="#偏差，方差（Bias-Variance）" class="headerlink" title="偏差，方差（Bias /Variance）"></a>偏差，方差（Bias /Variance）</h5><p>假设这就是数据集，如果给这个数据集拟合一条直线，可能得到一个逻辑回归拟合，但它并不能很好地拟合该数据，这是高偏差（high bias）的情况，我们称为“欠拟合” （underfitting）。</p>
<p>相反的如果我们拟合一个非常复杂的分类器，比如深度神经网络或含有隐藏单元的神经网络，可能就非常适用于这个数据集，但是这看起来也不是一种很好的拟合方式分类器方差较高（high variance），数据过度拟合（overfitting）。</p>
<p>在两者之间，可能还有一些像图中这样的，复杂程度适中，数据拟合适度的分类器，这个数据拟合看起来更加合理，我们称之为“适度拟合”（just right）是介于过度拟合和欠拟合中间的一类。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1563967374118.png" alt="1563967374118"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568683382157.png" alt="1568683382157"></p>
<p>总结一下，我们讲了如何通过分析在训练集上训练算法产生的误差和验证集上验证算法产生的误差来诊断算法是否存在高偏差和高方差，是否两个值都高，或者两个值都不高，根据算法偏差和方差的具体情况决定接下来你要做的工作，下节课，我会根据算法偏差和方差的高低情况讲解一些机器学习的基本方法，帮助大家更系统地优化算法。</p>
<h5 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h5><p>这是我在训练神经网络时用到基本方法，初始模型训练完成后，我首先要知道算法的偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至无法拟合训练集，那么你要做的就是选择一个新的网络，比如含有更多隐藏层或者隐藏单元的网络，或者花费更多时间来训练网络，或者尝试更先进的优化算法，后面我们会讲到这部分内容。你也可以尝试其他方法，可能有用，也可能没用。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568792151018.png" alt="1568792151018"></p>
<p>一会儿我们会看到许多不同的神经网络架构，或许你能找到一个更合适解决此问题的新的网络架构，加上括号，因为其中一条就是你必须去尝试，可能有用，也可能没用，不过采用规模更大的网络通常都会有所帮助，延长训练时间不一定有用，但也没什么坏处。训练学习算法时，我会不断尝试这些方法，直到解决掉偏差问题，这是最低标准，反复尝试，直到可以拟合数据为止，至少能够拟合训练集。</p>
<p>如果方差高，最好的解决办法就是采用更多数据，如果你能做到，会有一定的帮助，但有时候，我们无法获得更多数据，我们也可以尝试通过正则化来减少过拟合</p>
<p>只要正则适度，通常构建一个更大的网络便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时减少方差。</p>
<h5 id="正则化（Regularization）"><a href="#正则化（Regularization）" class="headerlink" title="正则化（Regularization）"></a>正则化（Regularization）</h5><p>深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568792614324.png" alt="1568792614324"></p>
<p>L2正则化是最常见的正则化类型，你们可能听说过L1正则化，L1正则化，加的不是L2范数.如果用的是L1正则化，w最终会是稀疏的，也就是说w向量中有很多 0，有人说这样有利于压缩模型，因为集合中参数均为 0，存储模型所占用的内存更少。实际上，虽然𝑀1正则化使模型变得稀疏，却没有降低太多存储内存，所以我认为这并不是𝑀1正则化的目的，至少不是为了压缩模型，人们在训练网络时，越来越倾向于使用L2正则化。</p>
<h5 id="为-什-么-正-则-化-有-利-于-预-防-过-拟-合"><a href="#为-什-么-正-则-化-有-利-于-预-防-过-拟-合" class="headerlink" title="为 什 么 正 则 化 有 利 于 预 防 过 拟 合"></a>为 什 么 正 则 化 有 利 于 预 防 过 拟 合</h5><p>直观上理解就是如果正则化λ设置得足够大，权重矩阵𝑋被设置为接近于 0 的值，直观理解就是把多隐藏单元的权重设为 0，于是基本上消除了这些隐藏单元的许多影响。如果是这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单元，可是深度却很大，它会使这个网络从过度拟合的状态更接近高偏差状态。</p>
<p>但是λ会存在一个中间值，于是会有一个接近“Just Right”的中间状态。</p>
<h5 id="dropout-正则化（Dropout-Regularization"><a href="#dropout-正则化（Dropout-Regularization" class="headerlink" title="dropout  正则化（Dropout Regularization)"></a>dropout  正则化（Dropout Regularization)</h5><p>除了L2正则化，还有一个非常实用的正则化方法——“Dropout（随机失活）”.</p>
<p>我们复制这个神经网络，dropout 会遍历网络的每一层，并设置消除神经网络中节点的概率。假设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率都是 0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后得到一个节点更少，规模更小的网络，然后用 backprop 方法进行训练。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568794165306.png" alt="1568794165306"></p>
<p>这是网络节点精简后的一个样本，对于其它样本，我们照旧以抛硬币的方式设置概率，保留一类节点集合，删除其它类型的节点集合。对于每个训练样本，我们都将采用一个精简后神经网络来训练它，这种方法似乎有点怪，单纯遍历节点，编码也是随机的，可它真的有效。</p>
<h5 id="理解-dropout"><a href="#理解-dropout" class="headerlink" title="理解 dropout"></a>理解 dropout</h5><p>Dropout 可以随机删除网络中的神经单元，他为什么可以通过正则化发挥如此大的作用呢？<br>直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施 dropout 的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；𝑀2对不同权重衰减是不同的，它取决于激活函数倍增的大小</p>
<p>总结一下，dropout 的功能类似于L2正则化，与L2正则化不同的是应用方式不同会带来一点点小变化，甚至更适用于不同的输入</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568794569310.png" alt="1568794569310"></p>
<p>第二个直观认识是，我们从单个神经元入手，如图，这个单元的工作就是输入并生成一些有意义的输出。通过 dropout，该单元的输入几乎被消除，有时这两个单元会被删除，有时会删除其它单元，就是说，我用紫色圈起来的这个单元，它不能依靠任何特征，因为特征都有可能被随机清除，或者说该单元的输入也都可能被随机清除。我不愿意把所有赌注都放在一个节点上，不愿意给任何一个输入加上太多权重，因为它可能会被删除，因此该单元将通过这种方式积极地传播开，并为单元的四个输入增加一点权重，通过传播所有权重，dropout 将产生收缩权重的平方范数的效果，和我们之前讲过的L2正则化类似，实施 dropout的结果是它会压缩权重，并完成一些预防过拟合的外层正则化。</p>
<p>总结一下，如果你担心某些层比其它层更容易发生过拟合，可以把某些层的 keep-prob值设置得比其它层更低，缺点是为了使用交叉验证，你要搜索更多的超级参数，另一种方案是在一些层上应用 dropout，而有些层不用 dropout，应用 dropout 的层只含有一个超级参数，就是 keep-prob。</p>
<p>计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据，所以 dropout在计算机视觉中应用得比较频繁，有些计算机视觉研究人员非常喜欢用它，几乎成了默认的选择，但要牢记一点，dropout 是一种正则化方法，它有助于预防过拟合，因此除非算法过拟合，不然我是不会使用 dropout 的，所以它在其它领域应用得比较少，主要存在于计算机视觉领域，因为我们通常没有足够的数据，所以一直存在过拟合，这就是有些计算机视觉研究人员如此钟情于 dropout 函数的原因。直观上我认为不能概括其它学科。</p>
<h5 id="其他正则化方法"><a href="#其他正则化方法" class="headerlink" title="其他正则化方法"></a>其他正则化方法</h5><p>一.数据扩增</p>
<p>假设你正在拟合猫咪图片分类器，如果你想通过扩增训练数据来解决过拟合，但扩增数据代价高，而且有时候我们无法扩增数据，但我们可以通过添加这类图片来增加训练集。通过随意翻转和裁剪图片，我们可以增大数据集，额外生成假训练数据。</p>
<p>二.early stopping</p>
<p>验证集误差通常会先呈下降趋势，然后在某个节点处开始上升，early stopping 的作用是，你会说，神经网络已经在这个迭代过程中表现得很好了，我们在此停止训练吧，得到验证集误差</p>
<p>当你还未在神经网络上运行太多迭代过程的时候，参数𝑥接近 0，因为随机初始化𝑥值时，它的值可能都是较小的随机值，所以在你长期训练神经网络之前𝑥依然很小，在迭代过程和训练过程中𝑥的值会变得越来越大，比如在这儿，神经网络中参数𝑥的值已经非常大了，所以 early stopping 要做就是在中间点停止迭代过程，我们得到一个𝑥值中等大小的弗罗贝尼乌斯范数</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568796728786.png" alt="1568796728786"></p>
<p>我认为机器学习过程包括几个步骤，其中一步是选择一个算法来优化代价函数J，我们有很多种工具来解决这个问题，如梯度下降，后面我会介绍其它算法，例如 Momentum，RMSprop 和 Adam 等等，但是优化代价函数𝐾之后，我也不想发生过拟合，也有一些工具可以解决该问题，比如正则化，扩增数据等等</p>
<p>一组工具优化代价函数J，机器学习就会变得更简单，在重点优化代价函数𝐾时，你只需要留意w和b，J(w,b)的值越小越好，你只需要想办法减小这个值，其它的不用关注。然后，预防过拟合还有其他任务，换句话说就是减少方差，这一步我们用另外一套工具来实现，这个原理有时被称为“正交化”。</p>
<p>但对我来说 early stopping 的主要缺点就是你不能独立地处理这两个问题，因为提早停止梯度下降，也就是停止了优化代价函数J，因为现在你不再尝试降低代价函数J，所以代价函数J的值可能不够小，同时你又希望不出现过拟合，你没有采取不同的方式来解决这两个问题，而是用一种方法同时解决两个问题，这样做的结果是我要考虑的东西变得更复杂。</p>
<h5 id="归一化输入（Normalizing-inputs"><a href="#归一化输入（Normalizing-inputs" class="headerlink" title="归一化输入（Normalizing inputs)"></a>归一化输入（Normalizing inputs)</h5><p>训练神经网络，其中一个加速训练的方法就是归一化输入。假设一个训练集有两个特征，输入特征为 2 维，归一化需要两个步骤：1.零均值2.归一化方差；</p>
<p>然而如果你归一化特征，代价函数平均起来看更对称，如果你在上图这样的代价函数上运行梯度下降法，你必须使用一个非常小的学习率。因为如果是在这个位置，梯度下降法可能需要多次迭代过程，直到最后找到最小值。但如果函数是一个更圆的球形轮廓，那么不论从哪个位置开始，梯度下降法都能够更直接地找到最小值，你可以在梯度下降法中使用较大步长，而不需要像在左图中那样反复执行。</p>
<p>当然，实际上w是一个高维向量，因此用二维绘制w并不能正确地传达并直观理解，但总地直观理解是代价函数会更圆一些，而且更容易优化.</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568797570701.png" alt="1568797570701"></p>
<h5 id="梯度消失-梯度爆炸（Vanishing-Exploding-gradients-）"><a href="#梯度消失-梯度爆炸（Vanishing-Exploding-gradients-）" class="headerlink" title="梯度消失/ 梯度爆炸（Vanishing / Exploding gradients ）"></a>梯度消失/ 梯度爆炸（Vanishing / Exploding gradients ）</h5><p>训练神经网络，尤其是深度神经所面临的一个问题就是梯度消失或梯度爆炸，也就是你训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变小，这加大了训练的难度。</p>
<p>对于当前的神经网络，假设L= 150，最近 Microsoft 对 152 层神经网络的研究取得了很大进展，在这样一个深度神经网络中，如果激活函数或梯度函数以与𝑀相关的指数增长或递减，它们的值将会变得极大或极小，从而导致训练难度上升，尤其是梯度指数小于L时，梯度下降算法的步长会非常非常小，梯度下降算法将花费很长时间来学习。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568797824859.png" alt="1568797824859"></p>
<p>如上图：权重W只比 1 略大一点，或者说只是比单位矩阵大一点，深度神经网络的激活函数将爆炸式增长，如果W比 1 略小一点，激活函数将以指数级递减.</p>
<h5 id="神经网络的权重初始化"><a href="#神经网络的权重初始化" class="headerlink" title="神经网络的权重初始化"></a>神经网络的权重初始化</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568798195177.png" alt="1568798195177"></p>
<h5 id="梯度的数值逼近和梯度检验（Gradient-checking-）"><a href="#梯度的数值逼近和梯度检验（Gradient-checking-）" class="headerlink" title="梯度的数值逼近和梯度检验（Gradient checking ）"></a>梯度的数值逼近和梯度检验（Gradient checking ）</h5><p>在实施 backprop 时，有一个测试叫做梯度检验，它的作用是确保 backprop 正确实施。</p>
<p>梯度检验帮我们节省了很多时间，也多次帮我发现 backprop 实施过程中的 bug，接下来，我们看看如何利用它来调试或检验 backprop 的实施是否正确。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568798556182.png" alt="1568798556182"></p>
<p>在实施神经网络时，我经常需要执行 foreprop 和 backprop，然后我可能发现这个梯度检验有一个相对较大的值，我会怀疑存在 bug，然后开始调试，调试，调试，调试一段时间后，我得到一个很小的梯度检验值，现在我可以很自信的说，神经网络实施是正确的。</p>
<h5 id="梯度检验应用的注意事项"><a href="#梯度检验应用的注意事项" class="headerlink" title="梯度检验应用的注意事项"></a>梯度检验应用的注意事项</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568798673304.png" alt="1568798673304"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">首先，不要在训练中使用梯度检验，它只用于调试。</span><br><span class="line">第二点，如果算法的梯度检验失败，要检查所有项，检查每一项，并试着找出 bug</span><br><span class="line">第三点，在实施梯度检验时，如果使用正则化，请注意正则项。</span><br><span class="line">第四点，梯度检验不能与 dropout 同时使用，因为每次迭代过程中，dropout 会随机消除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的代价函数𝐾。</span><br></pre></td></tr></table></figure>
<p>回顾这一周，我们讲了如何配置训练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方差并存的问题，如何在神经网络中应用不同形式的正则化，如𝑀2正则化和 dropout，还有加<br>快神经网络训练速度的技巧，最后是梯度检验。</p>
<h4 id="优化算法-Optimization-algorithms"><a href="#优化算法-Optimization-algorithms" class="headerlink" title="优化算法 (Optimization algorithms)"></a>优化算法 (Optimization algorithms)</h4><p>本周将学习优化算法，这能让你的神经网络运行得更快。机器学习的应用是一个高度依赖经验的过程，伴随着大量迭代的过程，你需要训练诸多模型，才能找到合适的那一个，所以，优化算法能够帮助你快速训练模型。</p>
<h5 id="Mini-batch梯度下降"><a href="#Mini-batch梯度下降" class="headerlink" title="Mini-batch梯度下降"></a>Mini-batch梯度下降</h5><p>向量化能够让你相对较快地处理所有m个样本。如果𝑛很大的话，处理速度仍然缓慢。比如说，如果m是 500 万或 5000 万或者更大的一个数，在对整个训练集执行梯度下降法时，你要做的是，你必须处理整个训练集，然后才能进行一步梯度下降法，然后你需要再重新处理 500 万个训练样本，才能进行下一步梯度下降法。</p>
<p>你可以把训练集分割为小一点的子集训练，这些子集被取名为 mini-batch，假设每一个子集中只有 1000 个样本，那么把其中的x (1) 到x (1000) 取出来，将其称为第一个子训练集，也叫做 mini-batch，然后你再取出接下来的 1000 个样本，从x (1001) 到x(2000) ，然后再取 1000个样本，以此类推。</p>
<p>在继续课程之前，先确定一下我的符号，之前我们使用了上角小括号(i)表示训练集里的值，所以x (i) 是第i个训练样本。我们用了上角中括号[l]来表示神经网络的层数，z [l] 表示神经网络中第l层的z值，我们现在引入了大括号t来代表不同的mini-batch，所以我们有x {t} 和Y{t} ，检查一下自己是否理解无误。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568949475847.png" alt="1568949475847"></p>
<p>在训练集上运行 mini-batch 梯度下降法，你运行 for t=1……5000 ，因为我们有 5000 个各有 1000 个样本的组，在 for 循环里你要做得基本就是对X{t} 和Y{t} 执行一步梯度下降法。首先执行前向传播，接下来你要计算损失成本函数J,接下来，你执行反向传播来计算J{t} 的梯度,然后你更新加权值.</p>
<p>这是使用 mini-batch 梯度下降法训练样本的一步，我写下的代码也可被称为进行“一代”（1 epoch）的训练。一代这个词意味着只是一次遍历了训练集。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568949569181.png" alt="1568949569181"></p>
<h5 id="理解-mini-batch-梯度下降法"><a href="#理解-mini-batch-梯度下降法" class="headerlink" title="理解 mini-batch  梯度下降法"></a>理解 mini-batch  梯度下降法</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568949864186.png" alt="1568949864186"></p>
<p>你需要决定的变量之一是 mini-batch 的大小，m就是训练集的大小.</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1568950046292.png" alt="1568950046292"></p>
<p>首先，如果训练集较小，直接使用 batch 梯度下降法，样本集较小就没必要使用 mini-batch 梯度下降法，你可以快速处理整个训练集，所以使用 batch 梯度下降法也很好，这里的少是说小于 2000 个样本，这样比较适合使用 batch 梯度下降法。不然，样本数目较大的话，一般的 mini-batch 大小为 64 到 512，考虑到电脑内存设置和使用的方式，如果 mini-batch 大小是 2 的𝑜次方，代码会运行地快一些，64 就是 2 的 6 次方，以此类推，128 是 2 的7 次方，256 是 2 的 8 次方，512 是 2 的 9 次方。所以我经常把 mini-batch 大小设成 2 的次方。在上一个视频里，我的 mini-batch 大小设为了 1000，建议你可以试一下 1024，也就是2 的 10 次方。也有 mini-batch 的大小为 1024，不过比较少见，64 到 512 的 mini-batch 比较常见。</p>
<h5 id="指数加权平均数"><a href="#指数加权平均数" class="headerlink" title="指数加权平均数"></a>指数加权平均数</h5><p>指数加权平均数经常被使用，再说一次，它在统计学中被称为指数加权移动平均值，我们就简称为指数加权平均数。通过调整这个参数（β），或者说后面的算法学习，你会发现这是一个很重要的参数，可以取得稍微不同的效果，往往中间有某个值效果最好，为中间值时得到的红色曲线，比起绿线和黄线更好地平均了温度</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569221392292.png" alt="1569221392292"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569221347277.png" alt="1569221347277"></p>
<p>我们平均了大约1/（1-β）天的温度，当β= 0.9的时候，我们说仿佛你在计算一个指数加权平均数，只关注了过去 10天的温度，因为 10 天后，权重下降到不到当日权重的三分之一。</p>
<p>指数加权平均数公式的好处之一在于，它占用极少内存，电脑内存中只占用一行数字而已，然后把最新数据代入公式，不断覆盖就可以了，正因为这个原因，其效率，它基本上只占用一行代码，计算指数加权平均数也只占用单行数字的存储和内存，当然它并不是最好的，也不是最精准的计算平均数的方法。</p>
<h5 id="指数加权平均的偏差修正"><a href="#指数加权平均的偏差修正" class="headerlink" title="指数加权平均的偏差修正"></a>指数加权平均的偏差修正</h5><p>学过了如何计算指数加权平均数，有一个技术名词叫做偏差修正，可以让平均数运算更加准确，来看看它是怎么运行的。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569221863695.png" alt="1569221863695"></p>
<p>如果你执行写在这里的公式，在β等于 0.98 的时候，得到的并不是绿色曲线，而是紫色曲线，你可以注意到紫色曲线的起点较低，模型無法很好地估计前几天的温度。有个办法可以修改这一估测，让估测变得更好，更准确，特别是在估测初期，也就是不用vt,用右边那个。</p>
<p>所以当t很大的时候，偏差修正几乎没有作用，因此当t较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，你才开始预测热身练习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。</p>
<h5 id="动量梯度下降法（Gradient-descent-with-Momentum-）"><a href="#动量梯度下降法（Gradient-descent-with-Momentum-）" class="headerlink" title="动量梯度下降法（Gradient descent with Momentum ）"></a>动量梯度下降法（Gradient descent with Momentum ）</h5><p>还有一种算法叫做 Momentum，或者叫做动量梯度下降法，运行速度几乎总是快于标准的梯度下降算法，简而言之，基本的想法就是计算梯度的指数加权平均数，并利用该梯度更新你的权重.</p>
<p>例如，如果你要优化成本函数，函数形状如图，红点代表最小值的位置，假设你从这里（蓝色点）开始梯度下降法，如果进行梯度下降法的一次迭代，无论是 batch 或 mini-batch下降法，也许会指向这里，现在在椭圆的另一边，计算下一步梯度下降，结果或许如此，然后再计算一步，再一步，计算下去</p>
<p>慢慢摆动到最小值，这种上下波动减慢了梯度下降法的速度，你就无法使用更大的学习率，如果你要用较大的学习率（紫色箭头），结果可能会偏离函数的范围，为了避免摆动过大，你要用一个较小的学习率。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569222487522.png" alt="1569222487522"></p>
<p>另一个看待问题的角度是，在纵轴上，你希望学习慢一点，因为你不想要这些摆动，但是在横轴上，你希望加快学习，你希望快速从左向右移，移向最小值，移向红点。所以使用动量梯度下降法，你需要做的是，在每次迭代中，确切来说在第𝑢次迭代的过程中，你会计算微分dW，db.</p>
<p>在上几个导数中，你会发现这些纵轴上的摆动平均值接近于零，所以在纵轴方向，你希望放慢一点，平均过程中，正负数相互抵消，所以平均值接近于零。但在横轴方向，所有的微分都指向横轴方向，因此横轴方向的平均值仍然较大，因此用算法几次迭代后，你发现动量梯度下降法，最终纵轴方向的摆动变小了，横轴方向运动更快，因此你的算法走了一条更加直接的路径，在抵达最小值的路上减少了摆动。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569222706502.png" alt="1569222706502"></p>
<h5 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h5><p>知道了动量（Momentum）可以加快梯度下降，还有一个叫做 RMSprop 的算法，全称是 root mean square prop 算法，它也可以加速梯度下降，我们来看看它是如何运作的。</p>
<p>想减缓b方向的学习，即纵轴方向，同时加快，至少不是减缓横轴方向的学习，RMSprop 算法可以实现这一点</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569223012486.png" alt="1569223012486"></p>
<p>你看这些微分，垂直方向的要比水平方向的大得多，所以斜率在b方向特别大，所以这些微分中，db较大，dw较小，db的平方较大，所以S db 也会较大，结果就是纵轴上的更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除。</p>
<p>RMSprop 的影响就是你的更新最后会变成这样（绿色线），纵轴方向上摆动较小，而横轴方向继续推进。还有个影响就是，你可以用一个更大学习率a，然后加快学习，而无须在纵轴上垂直方向偏离。</p>
<h5 id="Adam-优化算法"><a href="#Adam-优化算法" class="headerlink" title="Adam 优化算法"></a>Adam 优化算法</h5><p>在深度学习的历史上，包括许多知名研究者在内，提出了优化算法，并很好地解决了一些问题，但随后这些优化算法被指出并不能一般化，并不适用于多种神经网络，时间久了，深度学习圈子里的人开始多少有些质疑全新的优化算法，很多人都觉得动量（Momentum）梯度下降法很好用，很难再想出更好的优化算法。所以 RMSprop 以及 Adam 优化算法（Adam优化算法也是本视频的内容），就是少有的经受住人们考验的两种算法，已被证明适用于不同的深度学习结构，这个算法我会毫不犹豫地推荐给你，因为很多人都试过，并且用它很好地解决了许多问题。</p>
<p>Adam 优化算法基本上就是将 Momentum 和 RMSprop 结合在一起，那么来看看如何使用 Adam 算法。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569223921852.png" alt="1569223921852"></p>
<p>本算法中有很多超参数，超参数学习率𝑏很重要，也经常需要调试，你可以尝试一系列值，然后看哪个有效.这就是关于 Adam 优化算法的全部内容，有了它，你可以更加快速地训练神经网络</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569223962474.png" alt="1569223962474"></p>
<h5 id="学习率衰减-Learning-rate-decay"><a href="#学习率衰减-Learning-rate-decay" class="headerlink" title="学习率衰减(Learning rate decay)"></a>学习率衰减(Learning rate decay)</h5><p>加快学习算法的一个办法就是随时间慢慢减少学习率，我们将之称为学习率衰减，我们来看看如何做到，首先通过一个例子看看，为什么要计算学习率衰减。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569224340891.png" alt="1569224340891"></p>
<p>假设你要使用 mini-batch 梯度下降法，mini-batch 数量不大，大概 64 或者 128 个样本，在迭代过程中会有噪音（蓝色线），下降朝向这里的最小值，但是不会精确地收敛，所以你的算法最后在附近摆动，并不会真正收敛，因为你用的a是固定值，不同的 mini-batch 中有噪音</p>
<p>但要慢慢减少学习率𝑏的话，在初期的时候，a学习率还较大，你的学习还是相对较快，但随着a变小，你的步伐也会变慢变小，所以最后你的曲线（绿色线）会在最小值附近的一小块区域里摆动，而不是在训练过程中，大幅度在最小值附近摆动。</p>
<p>所以慢慢减少𝑏的本质在于，在学习初期，你能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些</p>
<p>decay-rate称为衰减率，epoch-num 为代数，a0 为初始学习率</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569224519093.png" alt="1569224519093"></p>
<p>除了这个学习率衰减的公式，人们还会用其它的公式。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569224741965.png" alt="1569224741965"></p>
<p>比如，这个叫做指数衰减，其中a相当于一个小于 1 的值,你的学习率呈指数下降</p>
<h5 id="局部最优的问题"><a href="#局部最优的问题" class="headerlink" title="局部最优的问题"></a>局部最优的问题</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569225149665.png" alt="1569225149665"></p>
<p>但是一个具有高维度空间的函数，如果梯度为 0，那么在每个方向，它可能是凸函数，也可能是凹函数,那么想要得到局部最优，所有的 2 万个方向都需要是这样，但发生的机率也许很小.所以我们从深度学习历史中学到的一课就是，我们对低维度空间的大部分直觉，比如你可以画出上面的图，并不能应用到高维度空间中。适用于其它算法，因为如果你有 2 万个参数，那么J函数有 2 万个维度向量，你更可能遇到鞍点，而不是局部最优点。</p>
<p>结果是平稳段会减缓学习，平稳段是一块区域，其中导数长时间接近于 0，如果你在此处，梯度会从曲面从从上向下下降，因为梯度等于或接近 0，曲面很平坦，你得花上很长时间慢慢抵达平稳段的这个点.在这些情况下，更成熟的优化算法，如 Adam 算法，能够加快速度，让你尽早往下走出平稳段</p>
<h4 id="超-参-数-调-试-Batch-正-则-化-和-程-序-框-架"><a href="#超-参-数-调-试-Batch-正-则-化-和-程-序-框-架" class="headerlink" title="超 参 数 调 试 Batch 正 则 化 和 程 序 框 架"></a>超 参 数 调 试 Batch 正 则 化 和 程 序 框 架</h4><h5 id="调试处理（Tuning-process-）"><a href="#调试处理（Tuning-process-）" class="headerlink" title="调试处理（Tuning process ）"></a>调试处理（Tuning process ）</h5><p>神经网络的改变会涉及到许多不同超参数的设置。现在，对于超参数而言，你要如何找到一套好的设定呢？分享一些指导原则，一些关于如何系统地组织超参调试过程的技巧，让你更有效的聚焦到合适的超参设定中。</p>
<p>但希望你粗略了解到哪些超参数较为重要，a无疑是最重要的，接下来是我用橙色圈住的那些，然后是我用紫色圈住的那些，但这不是严格且快速的标准，我认为，其它深度学习的研究者可能会很不同意我的观点或有着不同的直觉。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569225813881.png" alt="1569225813881"></p>
<p>现在，如果你尝试调整一些超参数，该如何选择调试值呢？在早一代的机器学习算法中，如果你有两个超参数，这里我会称之为超参 1，超参 2，常见的做法是在网格中取样点，像这样，然后系统的研究这些数值。</p>
<p>在深度学习领域，我们常做的，我推荐你采用下面的做法，随机选择点，所以你可以选择同等数量的点，对吗？25 个点，接着，用这些随机取的点试验超参数的效果。之所以这么做是因为，对于你要解决的问题而言，你很难提前知道哪个超参数最重要，正如你之前看到的，一些超参数的确要比其它的更重要。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569225906864.png" alt="1569225906864"></p>
<p>当你给超参数取值时，另一个惯例是采用由粗糙到精细的策略。比如在二维的那个例子中，你进行了取值，也许你会发现效果最好的某个点，也许这个点周围的其他一些点效果也很好，那在接下来要做的是放大这块小区域（小蓝色方框内），然后在其中更密集得取值或随机取值，聚集更多的资源，在这个蓝色的方格中搜索，如果你怀疑这些超参数在这个区域的最优结果，那在整个的方格中进行粗略搜索后，你会知道接下来应该聚焦到更小的方格中。在更小的方格中，你可以更密集得取点。所以这种从粗到细的搜索也经常使用。</p>
<h5 id="超参数合适的范围"><a href="#超参数合适的范围" class="headerlink" title="超参数合适的范围"></a>超参数合适的范围</h5><p>在上一个视频中，你已经看到了在超参数范围中，随机取值可以提升你的搜索效率。但随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数，这很重要。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569227135734.png" alt="1569227135734"></p>
<p>假设你在搜索超参数a（学习速率），假设你怀疑其值最小是 0.0001 或最大是 1。如果你画一条从 0.0001 到 1 的数轴，沿其随机均匀取值，那 90%的数值将会落0.1 到 1 之间，结果就是，在 0.1 到 1 之间，应用了 90%的资源，而在 0.0001 到 0.1 之间，只有 10%的搜索资源，这看上去不太对。</p>
<p>所以总结一下，在对数坐标下取值，取最小值的对数就得到a的值，取最大值的对数就得到b值，所以现在你在对数轴上的10^a 到10^b 区间取值，在a，b间随意均匀的选取r值，将超参数设置为10^r，这就是在对数轴上取值的过程。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569227372084.png" alt="1569227372084"></p>
<p>关于为什么我们要这样做，为什么用线性轴取值不是个好办法，这是因为当β接近 1 时，所得结果的灵敏度会变化，即使β有微小的变化。所以β在 0.9 到 0.9005 之间取值，无关紧要，你的结果几乎不会变化。</p>
<h5 id="超参数调试实践"><a href="#超参数调试实践" class="headerlink" title="超参数调试实践"></a>超参数调试实践</h5><p>一种是你照看一个模型，通常是有庞大的数据组，但没有许多计算资源或足够的 CPU 和GPU 的前提下，基本而言，你只可以一次负担起试验一个模型或一小批模型，在这种情况下，即使当它在试验时，你也可以逐渐改良。所以这是一个人们照料一个模型的方法，观察它的表现，耐心地调试学习率，但那通常是因为你没有足够的计算能力，不能在同一时间试验大量模型时才采取的办法。</p>
<p>另一种方法则是同时试验多种模型，你设置了一些超参数，尽管让它自己运行，或者是一天甚至多天，然后你会获得像这样的学习曲线，这可以是损失函数 J 或实验误差或损失或数据误差的损失，但都是你曲线轨迹的度量。用这种方式你可以试验许多不同的参数设定，然后只是最后快速选择工作效果最好的那个。在这个例子中，也许这条看起来是最好的（下方绿色曲线）。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570245104302.png" alt="1570245104302"></p>
<h5 id="归一化网络的激活函数：Batch-Norm"><a href="#归一化网络的激活函数：Batch-Norm" class="headerlink" title="归一化网络的激活函数：Batch Norm"></a>归一化网络的激活函数：Batch Norm</h5><p>在深度学习兴起后，最重要的一个思想是它的一种算法，叫做 Batch 归一化，Batch归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是你的训练更加容易，甚至是深层网络。让我们来看看 Batch 归一化是怎么起作用的吧。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570245584550.png" alt="1570245584550"></p>
<p>当训练一个模型，比如 logistic 回归时，你也许会记得，归一化输入特征可以加快学习过程。你计算了平均值，从训练集中减去平均值，计算了方差，接着根据方差归一化你的数据集，在之前的视频中我们看到，这是如何把学习问题的轮廓，从很长的东西，变成更圆的东西，更易于算法优化。所以这是有效的，对 logistic 回归和神经网络的归一化输入特征值而言。</p>
<p>那么更深的模型呢？你不仅输入了特征值𝑦，而且这层有激活值a [1] ，这层有激活值a [2]等等。如果你想训练这些参数，比如w[3] ，b[3] ，那归一化a [2] 的平均值和方差岂不是很好？以便使w [3] ，b[3]  的训练更有效率。在 logistic 回归的例子中，我们看到了如何归一化x1 ，x2 ，x3 ，会帮助你更有效的训练w和b。所以问题来了，对任何一个隐藏层而言，我们能否归一化a值</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570245973748.png" alt="1570245973748"></p>
<p>所有这些都是针对l层，但我省略l及方括号，然后用正如你常用的那个公式计算方差，接着，你会取每个z(i) 值，使其规范化，方法如下，减去均值再除以标准偏差，为了使数值稳定，通常将𝜀作为分母，以防𝜎 = 0的情况。</p>
<p>所以现在我们已把这些z值标准化，化为含平均值 0 和标准单位方差，所以z的每一个分量都含有平均值 0 和方差 1，但我们不想让隐藏单元总是含有平均值 0 和方差 1，也许隐藏单元有了不同的分布会有意义，所以我们所要做的就是计算z^,这里β和𝛾是你模型的学习参数。</p>
<p>所以我希望你学到的是，归一化输入特征X是怎样有助于神经网络中的学习，Batch 归一化的作用是它适用的归一化过程，不只是输入层，甚至同样适用于神经网络中的深度隐藏层。你应用 Batch 归一化了一些隐藏单元值中的平均值和方差，不过训练输入和这些隐藏单元值的一个区别是，你也许不想隐藏单元值必须是平均值 0 和方差 1。</p>
<p>比如，如果你有 sigmoid 激活函数，你不想让你的值总是全部集中在这里，你想使它们有更大的方差，或不是 0 的平均值，以便更好的利用非线性的 sigmoid 函数，而不是使所有的值都集中于这个线性版本中，这里β和𝛾模型的学习参数就起到了作用。</p>
<h5 id="将-Batch-Norm-拟合进神经网络"><a href="#将-Batch-Norm-拟合进神经网络" class="headerlink" title="将 Batch Norm  拟合进神经网络"></a>将 Batch Norm  拟合进神经网络</h5><p>你已经看到那些等式，它可以在单一隐藏层进行 Batch 归一化，接下来，让我们看看它怎样在深度网络训练中拟合的吧。其过程如下图</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570246571952.png" alt="1570246571952"></p>
<p>在 TensorFlow框架中，你可以用这个函数（ tf.nn.batch_normalization ）来实现 Batch 归一化。</p>
<p>实践中，Batch 归一化通常和训练集的 mini-batch 一起使用。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570247001482.png" alt="1570247001482"></p>
<p>在此例中的 mini-batch 中增加任何常数，数值都不会改变，因为加上的任何常数都将会被均值减去所抵消。所以，如果你在使用 Batch 归一化，其实你可以消除这个参数（b [𝑚] ），或者你也可以，暂时把它设置为 0.总结：</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570247798205.png" alt="1570247798205"></p>
<p>如果你已将梯度计算如下，你就可以使用梯度下降法了，这就是我写到这里的，但也适用于有 Momentum、RMSprop、Adam 的梯度下降法。与其使用梯度下降法更新 mini-batch，你可以使用这些其它算法来更新，我们在之前几个星期中的视频中讨论过的，也可以应用其它的一些优化算法来更新由 Batch 归一化添加到算法中的 参数。</p>
<p>为什么 Batch 归一化会起作用呢？</p>
<p>Batch 归一化做的，是它减少了这些隐藏值分布变化的数量。Batch 归一化减少了输入值改变的问题，它的确使这些值变得更稳定，神经网络的之后层就会有更坚实的基础。即使使输入分布改变了一些，它会改变得更少。它做的是当前层保持学习，当改变时，迫使后层适应的程度减小了，你可以这样想，它减弱了前层参数的作用与后层参数的作用之间的联系，它使得网络每层都可以自己学习，稍稍独立于其它层，这有助于加速整个网络的学习。</p>
<p>所以，希望这能带给你更好的直觉，重点是 Batch 归一化的意思是，尤其从神经网络后层之一的角度而言，前层不会左右移动的那么多，因为它们被同样的均值和方差所限制，所以，这会使得后层的学习工作变得更容易些。</p>
<p>Batch 归一化还有一个作用，它有轻微的正则化效果。对比而言，Batch 归一化含几重噪音，因为标准偏差的缩放和减去均值带来的额外噪音。这里的均值和标准差的估计值也是有噪音的，所以类似于 dropout，Batch 归一化有轻微的正则化效果，因为给隐藏单元添加了噪音，这迫使后部单元不过分依赖任何一个隐藏单元，类似dropout，它给隐藏层增加了噪音，因此有轻微的正则化效果。因为添加的噪音很微小，所以并不是巨大的正则化效果，你可以将 Batch 归一化和 dropout 一起使用，如果你想得到 dropout 更强大的正则化效果。</p>
<p>不要把 Batch 归一化当作正则化，把它当作将你归一化隐藏单元激活值并加速学习的方式，我认为正则化几乎是一个意想不到的副作用。</p>
<p>Batch 归一化一次只能处理一个 mini-batch 数据，它在 mini-batch 上计算均值和方差。所以测试时，你试图做出预测，试着评估神经网络，你也许没有mini-batch 的例子，你也许一次只能进行一个简单的例子，所以测试时，你需要做一些不同的东西以确保你的预测有意义。</p>
<h5 id="测试时的Batch-Norm"><a href="#测试时的Batch-Norm" class="headerlink" title="测试时的Batch Norm"></a>测试时的Batch Norm</h5><p>Batch 归一化将你的数据以 mini-batch 的形式逐一处理，但在测试时，你可能需要对每个样本逐一处理，我们来看一下怎样调整你的网络来做到这一点。</p>
<p>在测试时，你可能不能将一个 mini-batch 中的 6428 或 2056 个样本同时处理，因此你需要用其它方式来得到μ和𝜎^2 ，而且如果你只有一个样本，一个样本的均值和方差没有意义。那么实际上，为了将你的神经网络运用于测试，就需要单独估算μ和𝜎^2 ，在典型的 Batch 归一化运用中，你需要用一个指数加权平均来估算，这个平均数涵盖了所有 mini-batch，接下来我会具体解释。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570261405282.png" alt="1570261405282"></p>
<p>正如我们之前用的指数加权平均来计算均值，当时是试着计算当前气温的指数加权平均，你会这样来追踪你看到的这个均值向量的最新平均值，于是这个指数加权平均就成了你对这一隐藏层的Z均值的估值。</p>
<p>总结一下就是，在训练时，μ和𝜎^2  是在整个 mini-batch 上计算出来的包含了像是 64 或28 或其它一定数量的样本，但在测试时，你可能需要逐一处理样本，方法是根据你的训练集估算μ和𝜎^2  ，估算的方式有很多种，理论上你可以在最终的网络中运行整个训练集来得到μ和𝜎^2  ，但在实际操作中，我们通常运用指数加权平均来追踪在训练过程中你看到的μ和𝜎^2 的值。还可以用指数加权平均，有时也叫做流动平均来粗略估算μ和𝜎^2 ，然后在测试中使用μ和𝜎^2 的值来进行你所需要的隐藏单元Z值的调整。在实践中，不管你用什么方式估算μ和𝜎^2 ，这套过程都是比较稳健的，因此我不太会担心你具体的操作方式，而且如果你使用的是某种深度学习框架，通常会有默认的估算μ和𝜎^2 的方式，应该一样会起到比较好的效果。但在实践中，任何合理的估算你的隐藏单元Z值的均值和方差的方式，在测试中应该都会有效。</p>
<h5 id="Softmax-回归（Softmax-regression）"><a href="#Softmax-回归（Softmax-regression）" class="headerlink" title="Softmax  回归（Softmax regression）"></a>Softmax  回归（Softmax regression）</h5><p>有一种 logistic回归的一般形式，叫做 Softmax 回归，能让你在试图识别某一分类时做出预测，或者说是多种分类中的一个。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569288981511.png" alt="1569288981511"></p>
<p>我们将建立一个神经网络，其输出层有 4 个，或者说C个输出单元，因此𝑜，即输出层也就是L层的单元数量，等于 4，或者一般而言等于C。我们想要输出层单元的数字告诉我们这 4 种类型中每个的概率有多大，所以这里的第一个节点(最后输出的第 1个方格+圆圈)输出的应该是或者说我们希望它输出“其它”类的概率。</p>
<p>算出了Z后，你需要应用 Softmax 激活函数，这个激活函数对于 Softmax 层而言有些不同.Softmax 激活函数的特殊之处在于，因为需要将所有可能的输出归一化，就需要输入一个向量，最后输出一个向量。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569289431937.png" alt="1569289431937"></p>
<p>这个例子中（左边图）𝐷 = 4，因此这个绿色分类和Softmax 仍旧可以代表多种分类之间的这些类型的线性决策边界。另一个例子（中间图）是𝐷 = 5类，最后一个例子（右边图）是𝐷 = 6，这显示了 Softmax 分类器在没有隐藏层的情况下能够做到的事情，当然更深的神经网络会有𝑦，然后是一些隐藏单元，以及更多隐藏单元等等，你就可以学习更复杂的非线性决策边界，来区分多种不同分类。</p>
<p>下面你将更深入地了解 Softmax 分类，并学习如何训练一个使用了 Softmax 层的模型。</p>
<p>Softmax 这个名称的来源是与所谓 hardmax 对比，hardmax 函数会观察z的元素，然后在z中最大元素的位置放上 1，其它位置放上 0.与之相反，Softmax 所做的从z到这些概率的映射更为温和。<img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569289748196.png" alt="1569289748196"></p>
<p>训练softmat</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1569289867624.png" alt="1569289867624"></p>
<p>损失函数所做的就是它找到你的训练集中的真实类别，然后试图使该类别相应的概率尽可能地高，如果你熟悉统计学中最大似然估计，这其实就是最大似然估计的一种形式。</p>
<p>这是单个训练样本的损失，整个训练集的损失J又如何呢？也就是设定参数的代价之类的，还有各种形式的偏差的代价，它的定义你大致也能猜到，就是整个训练集损失的总和，把你的训练算法对所有训练样本的预测都加起来，</p>
<h5 id="深度学习框架"><a href="#深度学习框架" class="headerlink" title="深度学习框架"></a>深度学习框架</h5><p>现在有很多好的深度学习软件框架，可以帮助你实现这些模型。现在有许多深度学习框架，能让实现神经网络变得更简单，我们来讲主要的几个。</p>
<p>一个重要的标准就是便于编程，这既包括神经网络的开发和迭代，还包括为产品进行配置，为了成千上百万，甚至上亿用户的实际使用，取决于你想要做什么。<br>第二个重要的标准是运行速度，特别是训练大数据集时，一些框架能让你更高效地运行和训练神经网络。</p>
<p>还有一个标准人们不常提到，但我觉得很重要，那就是这个框架是否真的开放，要是一个框架真的开放，它不仅需要开源，而且需要良好的管理。</p>
<p>框架通过提供比数值线性代数库更高程度的抽象化，这里的每一个程序框架都能让你在开发深度机器学习应用时更加高效。</p>
<h5 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570244153559.png" alt="1570244153559"></p>
<p>定义参数 w，在 TensorFlow 中，你要用 tf.Variable()来定义参数</p>
<p>让 TensorFlow 评估一个变量，我们要用到:session.run(w)</p>
<p>placeholder 函数告诉 TensorFlow，你稍后会为x提供数值。</p>
<p>希望这个让你对 TensorFlow 程序的大致结构有了了解，当你做编程练习，使用更多TensorFlow 代码时，我这里用到的一些函数你会熟悉起来，这里有个地方要注意，w是我们想要优化的参数，因此将它称为变量，注意我们需要做的就是定义一个损失函数，使用这些add 和 multiply 之类的函数。TensorFlow 知道如何对 add 和 mutiply ，还有其它函数求导，这就是为什么你只需基本实现前向传播，它能弄明白如何做反向传播和梯度计算，因为它已经内置在 add ， multiply 和平方函数中。</p>
<h3 id="结构化深度学习策略"><a href="#结构化深度学习策略" class="headerlink" title="结构化深度学习策略"></a>结构化深度学习策略</h3><p>通过这门课程你们能够学到如何更快速高效地优化你的机器学习系统。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570862112463.png" alt="1570862112463"></p>
<p>你可能有很多想法去改善你的系统，比如，你可能想我们去收集更多的训练数据吧。或者你会说，可能你的训练集的多样性还不够，你应该收集更多不同姿势的猫咪图片，或者更多样化的反例集。或者你想再用梯度下降训练算法，训练久一点。或者你想尝试用一个完全不同的优化算法，比如 Adam 优化算法。或者尝试使用规模更大或者更小的神经网络。或者你想试试 dropout 或者𝑀2正则化。或者你想修改网络的架构，比如修改激活函数，改变隐藏单元的数目之类的方法。</p>
<p>当你尝试优化一个深度学习系统时，你通常可以有很多想法可以去试，问题在于，如果你做出了错误的选择，你完全有可能白费 6 个月的时间，往错误的方向前进，在 6 个月之后才意识到这方法根本不管用。</p>
<p>我希望在这门课程中，可以教给你们一些策略，一些分析机器学习问题的方法，可以指引你们朝着最有希望的方向前进。这门课中，我会和你们分享我在搭建和部署大量深度学习产品时学到的经验和教训，我想这些内容是这门课程独有的。比如说，很多大学深度学习课程很少提到这些策略。</p>
<h5 id="正交化（Orthogonalization）"><a href="#正交化（Orthogonalization）" class="headerlink" title="正交化（Orthogonalization）"></a>正交化（Orthogonalization）</h5><p>搭建建立机器学习系统的挑战之一是，你可以尝试和改变的东西太多太多了。包括，比如说，有那么多的超参数可以调。我留意到，那些效率很高的机器学习专家有个特点，他们思维清晰，对于要调整什么来达到某个效果，非常清楚，这个步骤我们称之为正交化。</p>
<p>正交化的概念是指，你可以想出一个维度，这个维度你想做的是控制转向角，还有另一个维度来控制你的速度，那么你就需要一个旋钮尽量只控制转向角，另一个旋钮，在这个开车的例子里其实是油门和刹车控制了你的速度。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570862838582.png" alt="1570862838582"></p>
<p>如果你的算法在成本函数上不能很好地拟合训练集，你想要一个旋钮，是的我画这东西表示旋钮，或者一组特定的旋钮，这样你可以用来确保你的可以调整你的算法，让它很好地拟合训练集，所以你用来调试的旋钮是你可能可以训练更大的网络，或者可以切到更好的优化算法，比如 Adam 优化算法，等等。</p>
<p>你的算法在开发集上做的不好，它在训练集上做得很好，但开发集不行，然后你有一组正则化的旋钮可<br>以调节，尝试让系统满足第二个条件。</p>
<p>如果系统在开发集上做的很好，但测试集上做得不好呢？如果是这样，那么你需要调的旋钮，可能是更大的开发集。因为如果它在开发集上做的不错，但测试集不行这可能意味着你对开发集过拟合了，你需要往回退一步，使用更大的开发集。</p>
<p>如果它在测试集上做得很好，但无法给你的猫图片应用用户提供良好的体验，这意味着你需要回去，改变开发集或成本函数。因为如果根据某个成本函数，系统在测试集上做的很好，但它无法反映你的算法在现实世界中的表现，这意味着要么你的开发集分布设置不正确，要么你的成本函数测量的指标不对。</p>
<p>必须弄清楚到底是什么地方出问题了，然后我们刚好有对应的旋钮，或者一组对应的旋钮，刚好可以解决那个问题，那个限制了机器学习系统性能的问题。这就是我们这周和下周要讲到的，如何诊断出系统性能瓶颈到底在哪。还有找到你可以用的一组特定的旋钮来调整你的系统，来改善它特定方面的性能。</p>
<h5 id="单一数字评估指标"><a href="#单一数字评估指标" class="headerlink" title="单一数字评估指标"></a>单一数字评估指标</h5><p>无论你是调整超参数，或者是尝试不同的学习算法，或者在搭建机器学习系统时尝试不同手段，你会发现，如果你有一个单实数评估指标，你的进展会快得多，它可以快速告诉你，新尝试的手段比之前的手段好还是差。所以当团队开始进行机器学习项目时，我经常推荐他们为问题设置一个单实数评估指标。</p>
<p>如果用准确率和查全率，很难直观判断模型好坏，有一个单实数评估指标真的可以快速判断各种模型的好坏，从而提高你决策的效率。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570863520948.png" alt="1570863520948"></p>
<h5 id="满足和优化指标（Satisficing-and-optimizing-metrics-）"><a href="#满足和优化指标（Satisficing-and-optimizing-metrics-）" class="headerlink" title="满足和优化指标（Satisficing and optimizing metrics ）"></a>满足和优化指标（Satisficing and optimizing metrics ）</h5><p>要把你顾及到的所有事情组合成单实数评估指标有时并不容易，在那些情况里，我发现有时候设立满足和优化指标是很重要的。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570863924205.png" alt="1570863924205"></p>
<p>你可能选择一个分类器，能够最大限度提高准确度，但必须满足运行时间要求，就是对图像进行分类所需的时间必须小于等于 100 毫秒。所以在这种情况下，我们就说准确度是一个优化指标。</p>
<p>所以更一般地说，如果你要考虑N个指标，有时候选择其中一个指标做为优化指标是合理的。所以你想尽量优化那个指标，然后剩下N− 1个指标都是满足指标，意味着只要它们达到一定阈值，例如运行时间快于 100 毫秒，但只要达到一定的阈值，你不在乎它超过那个门槛之后的表现，但它们必须达到这个门槛。</p>
<h5 id="训练-开发-测试集划分"><a href="#训练-开发-测试集划分" class="headerlink" title="训练/ 开发/ 测试集划分"></a>训练/ 开发/ 测试集划分</h5><p>training set：训练集是用来训练模型的。遵循训练集大，开发，测试集小的特点，占了所有数据的绝大部分。</p>
<p>development set：有时叫交叉验证集，用来对训练集训练出来的模型进行测试，通过测试结果来不断地优化模型。</p>
<p>test set：在训练结束后，对训练出的模型进行一次最终的评估所用的数据集。</p>
<p>设立训练集，开发集和测试集的方式大大影响了你或者你的团队在建立机器学习应用方面取得进展的速度。让你的开发集和测试集来自同一分布,如果你的开发集和测试集来自不同的分布，就像你设了一个目标，让你的团队花几个月尝试逼近靶心，结果在几个月工作之后发现，你说“等等”，测试的时候，”我要把目标移到这里”。</p>
<p>为了避免这种情况，我建议的是你将所有数据随机洗牌，放入开发集和测试集，所以开发集和测试集都有来自八个地区的数据，并且开发集和测试集都来自同一分布，这分布就是你的所有数据混在一起。不管那些数据是什么，都要随机分配到开发集和测试集上。</p>
<h5 id="开发集和测试集的大小"><a href="#开发集和测试集的大小" class="headerlink" title="开发集和测试集的大小"></a>开发集和测试集的大小</h5><p>在上一个视频中你们知道了你的开发集和测试集为什么必须来自同一分布，但它们规模应该多大？在深度学习时代，设立开发集和测试集的方针也在变化。</p>
<p>你可能听说过一条经验法则，在机器学习中，把你取得的全部数据用 70/30 比例分成训练集和测试集。或者如果你必须设立训练集、开发集和测试集，你会这么分 60%训练集，20%开发集，20%测试集。在机器学习的早期，这样分是相当合理的，特别是以前的数据集大小要小得多。所以如果你总共有 100 个样本，这样 70/30 或者 60/20/20 分的经验法则是相当合理的。如果你有几千个样本或者有一万个样本，这些做法也还是合理的。</p>
<p>但在现代机器学习中，我们更习惯操作规模大得多的数据集，比如说你有 1 百万个训练样本，这样分可能更合理，98%作为训练集，1%开发集，1%测试集，我们用D和T缩写来表示开发集和测试集。</p>
<p>测试集的目的是完成系统开发之后，测试集可以帮你评估投产系统的性能。方针就是，令你的测试集足够大，能够以高置信度评估系统整体性能。所以除非你需要对最终投产系统有一个很精确的指标，一般来说测试集不需要上百万个例子。</p>
<p>对于某些应用，你也许不需要对系统性能有置信度很高的评估，也许你只需要训练集和开发集。我认为，不单独分出一个测试集也是可以的。事实上，有时在实践中有些人会只分成训练集和测试集，他们实际上在测试集上迭代，所以这里没有测试集，他们有的是训练集和开发集，但没有测试集。如果你真的在调试这个集，这个开发集或这个测试集，这最好称为开发集。</p>
<h5 id="什么时候该改变开发-测试集和指标"><a href="#什么时候该改变开发-测试集和指标" class="headerlink" title="什么时候该改变开发/ 测试集和指标"></a>什么时候该改变开发/ 测试集和指标</h5><p>学过如何设置开发集和评估指标，就像是把目标定在某个位置，让你的团队瞄准。但有时候在项目进行途中，你可能意识到，目标的位置放错了。这种情况下，你应该移动你的目标，即更改评估指标。如果你的评估指标无法正确评估好算法的排名，那么就需要花时间定义一个新的评估指标。如果你在指标上表现很好，在当前开发集或者开发集和测试集分布中表现很好，但你的实际应用程序，你真正关注的地方表现不好，那么就需要修改指标或者你的开<br>发测试集。</p>
<p>假设你在构建一个猫分类器，试图找到很多猫的照片，向你的爱猫人士用户展示，你决定使用的指标是分类错误率。所以算法A和B分别有 3％错误率和 5％错误率，所以算法A似乎做得更好。但算法A由于某些原因，把很多色情图像分类成猫了,这是你的公司完全不能接受的。所以从你们公司的角度来看，以及从用户接受的角度来看，算法B实际上是一个更好的算法，因为它不让任何色情图像通过。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570865613094.png" alt="1570865613094"></p>
<p>上面公式更改了评估指标，这样你赋予了色情图片更大的权重，让算法将色情图分类为猫图时，错误率这个项快速变大。这个例子里，你把色情图片分类成猫这一错误的惩罚权重加大 10 倍。</p>
<p>加权的细节并不重要，实际上要使用这种加权，你必须自己过一遍开发集和测试集，在开发集和测试集里，自己把色情图片标记出来，这样你才能使用这个加权函数。</p>
<p>我想你处理机器学习问题时，应该把它切分成独立的步骤。一步是弄清楚如何定义一个指标来衡量你想做的事情的表现，然后我们可以分开考虑如何改善系统在这个指标上的表现。</p>
<h5 id="为什么是人的表现"><a href="#为什么是人的表现" class="headerlink" title="为什么是人的表现"></a>为什么是人的表现</h5><p>在过去的几年里，更多的机器学习团队一直在讨论如何比较机器学习系统和人类的表现。有两个主要原因，首先是因为深度学习系统的进步，机器学习算法突然变得更好了。在许多机器学习的应用领域已经开始见到算法已经可以威胁到人类的表现了。其次，事实证明，当你试图让机器做人类能做的事情时，可以精心设计机器学习系统的工作流程，让工作流程效率更高，所以在这些场合，比较人类和机器是很自然的，或者你要让机器模仿人类的行为。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570866484828.png" alt="1570866484828"></p>
<p>随着时间的推移，当您继续训练算法时，可能模型越来越大，数据越来越多，但是性能无法超过某个理论上限，这就是所谓的贝叶斯最优错误率（Bayes optimal error）。所以贝叶斯最优错误率一般认为是理论上可能达到的最优错误率</p>
<p>为什么当你超越人类的表现时，进展会慢下来。一个原因是人类水平在很多任务中离贝叶斯最优错误率已经不远了，人们非常擅长看图像，分辨里面有没有猫或者听写音频。所以，当你超越人类的表现之后也许没有太多的空间继续改善了。但第二个原因是，只要你的表现比人类的表现更差，那么实际上可以使用某些工具来提高性能。一旦你超越了人类的表现，这些工具就没那么好用了。</p>
<h5 id="可避免偏差（Avoidable-bias-）"><a href="#可避免偏差（Avoidable-bias-）" class="headerlink" title="可避免偏差（Avoidable bias ）"></a>可避免偏差（Avoidable bias ）</h5><p>知道人类水平的表现是怎样的，可以确切告诉你算法在训练集上的表现到底应该有多好，或者有多不好。</p>
<p>你的算法在训练集上的表现和人类水平的表现有很大差距的话，说明你的算法对训练集的拟合并不好。所以从减少偏差和方差的工具这个角度看，在这种情况下，我会把重点放在减少偏差上。你需要做的是，比如说训练更大的神经网络，或者跑久一点梯度下降，就试试能不能在训练集上做得更好。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570866949429.png" alt="1570866949429"></p>
<p>假设人类水平错误实际上是 7.5%，也许你的数据集中的图像非常模糊，即使人类都无法判断这张照片中有没有猫。你就知道，也许你的系统在训练集上的表现还好，它只是比人类的表现差一点点。在第二个例子中，你能希望专注减少这个分量，减少学习算法的方差，也许你可以试试正则化，让你的开发错误率更接近你的训练错误率。</p>
<p>贝叶斯错误率或者对贝叶斯错误率的估计和训练错误率之间的差值称为可避免偏差。当你理解人类水平错误率，理解你对贝叶斯错误率的估计，你就可以在不同的场景中专注于不同的策略，使用避免偏差策略还是避免方差策略。</p>
<h5 id="理解人的表现"><a href="#理解人的表现" class="headerlink" title="理解人的表现"></a>理解人的表现</h5><p>假设一个普通的人类，未经训练的人类，在此任务上达到 3%的错误率。普通的医生，也许是普通的放射科医生，能达到 1%的错误率。经验丰富的医生做得更好，错误率为 0.7%。还有一队经验丰富的医生，就是说如果你有一个经验丰富的医生团队，让他们都看看这个图像，然后讨论并辩论，他们达成共识的意见达到 0.5%的错误率。所以我想问你的问题是，你应该如何界定人类水平错误率？人类水平错误率 3%,1%, 0.7%还是 0.5%？</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570867690094.png" alt="1570867690094"></p>
<p>对人类水平有大概的估计可以让你做出对贝叶斯错误率的估计，这样可以让你更快地作出决定是否应该专注于减少算法的偏差，或者减少算法的方差。</p>
<h5 id="超过人的表现"><a href="#超过人的表现" class="headerlink" title="超过人的表现"></a>超过人的表现</h5><p>机器学习有很多问题已经可以大大超越人类水平了。例如，我想网络广告，估计某个用户点击广告的可能性，可能学习算法做到的水平已经超越任何人类了。还有提出产品建议，向你推荐电影或书籍之类的任务。我想今天的网站做到的水平已经超越你最亲近的朋了。还有物流预测，从𝐵到𝐶开车需要多久，或者预测快递车从𝐵开到𝐶需要多少时间。或者预测某人会不会偿还贷款，这样你就能判断是否批准这人的贷款。我想这些问题都是今天的机器学习远远超过了单个人类的表现。</p>
<p>人类在自然感知任务中往往表现非常好，所以有可能对计算机来说在自然感知任务的表现要超越人类要更难一些。</p>
<h5 id="改善你的模型的表现"><a href="#改善你的模型的表现" class="headerlink" title="改善你的模型的表现"></a>改善你的模型的表现</h5><p>你们学过正交化，如何设立开发集和测试集，用人类水平错误率来估计贝叶斯错误率以及如何估计可避免偏差和方差。我们现在把它们全部组合起来写成一套指导方针，如何提高学习算法性能的指导方针。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570868523271.png" alt="1570868523271"></p>
<p>如果你想用尽一切办法减少可避免偏差，我建议试试这样的策略：比如使用规模更大的模型，这样算法在训练集上的表现会更好，或者训练更久。使用更好的优化算法，比如说加入 momentum 或者 RMSprop，或者使用更好的算法，比如 Adam。你还可以试试寻找更好新神经网络架构，或者说更好的超参数。这些手段包罗万有，你可以改变激活函数，改变层数或者隐藏单位数，虽然你这么做可能会让模型规模变大。或者试用其他模型，其他架构，<br>如循环神经网络和卷积神经网络。</p>
<p>另外当你发现方差是个问题时，你可以试用很多技巧，包括以下这些：你可以收集更多数据，因为收集更多数据去训练可以帮你更好地推广到系统看不到的开发集数据。你可以尝试正则化，包括L2正则化，dropout 正则化或者我们在之前课程中提到的数据增强。同时你也可以试用不同的神经网络架构，超参数搜索，看看能不能帮助你，找到一个更适合你的问题的神经网络架构。</p>
<h5 id="进行误差分析"><a href="#进行误差分析" class="headerlink" title="进行误差分析"></a>进行误差分析</h5><p>人工检查一下你的算法犯的错误也许可以让你了解接下来应该做什么。这个过程称为错误分析.如果你要搭建应用系统，那这个简单的人工统计步骤，错误分析，可以节省大量时间，可以迅速决定什么是最重要的，或者最有希望的方向。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570869546288.png" alt="1570869546288"></p>
<p>首先，收集一下，比如说 100 个错误标记的开发集样本，然后手动检查，一次只看一个，看看你的开发集里有多少错误标记的样本是狗。现在，假设事实上，你的 100 个错误标记样本中只有 5%是狗，就是说在 100 个错误标记的开发集样本中，有 5个是狗。这意味着即使你完全解决了狗的问题，那么你最多只能希望你的错误率从 10%下降到 9.5%.在机器学习中，有时我们称之为性能上限，就意味着，最好能到哪里，完全解决狗的问题可以对你有多少帮助。</p>
<p>有时你在做错误分析时，也可以同时并行评估几个想法，比如，你有几个改善猫检测器的想法，也许你可以改善针对狗图的性能，或者有时候要注意，那些猫科动物，如狮子，豹，猎豹等等，它们经常被分类成小猫或者家猫，所以你也许可以想办法解决这个错误。或者也许你发现有些图像是模糊的，如果你能设计出一些系统，能够更好地处理模糊图像。</p>
<p>所以总结一下，进行错误分析，你应该找一组错误样本，可能在你的开发集里或者测试集里，观察错误标记的样本，看看假阳性（false positives）和假阴性（false negatives），统计属于不同错误类型的错误数量。在这个过程中，你可能会得到启发，归纳出新的错误类型，就像我们看到的那样。</p>
<h5 id="清除标注错误的数据"><a href="#清除标注错误的数据" class="headerlink" title="清除标注错误的数据"></a>清除标注错误的数据</h5><p>你的监督学习问题的数据由输入x和输出标签 y构成，如果你观察一下你的数据，并发现有些输出标签 y是错的，你的数据有些标签是错的，是否值得花时间去修正这些标签呢？</p>
<p>我们来考虑训练集，事实证明，深度学习算法对于训练集中的随机错误是相当健壮的（robust）。只要你的标记出错的样本，只要这些错误样本离随机错误不太远，有时可能做标记的人没有注意或者不小心，按错键了，如果错误足够随机，那么放着这些错误不管可能也没问题，而不要花太多时间修复它们。</p>
<p>深度学习算法对随机误差很健壮，但对系统性的错误就没那么健壮了。所以比如说，如果做标记的人一直把白色的狗标记成猫，那就成问题了。</p>
<p>是否值得修正这 6%标记出错的样本，我的建议是，如果这些标记错误严重影响了你在开发集上评估算法的能力，那么就应该去花时间修正错误的标签。</p>
<p>如果你决定要去修正开发集数据，手动重新检查标签，并尝试修正一些标签，这里还有一些额外的方针和原则需要考虑。首先，我鼓励你不管用什么修正手段，都要同时作用到开发集和测试集上，我们之前讨论过为什么，开发和测试集必须来自相同的分布。</p>
<p>就因为花了这几分钟，或者几个小时去亲自统计数据，真的可以帮你找到需要优先处理的任务，我发现花时间亲自检查数据非常值得，所以我强烈建议你们这样做，如果你在搭建你的机器学习系统的话，然后你想确定应该优先尝试哪些想法，或者哪些方向。</p>
<h5 id="快速搭建系统并迭代"><a href="#快速搭建系统并迭代" class="headerlink" title="快速搭建系统并迭代"></a>快速搭建系统并迭代</h5><p>一般来说，对于几乎所有的机器学习程序可能会有 50 个不同的方向可以前进，并且每个方向都是相对合理的可以改善你的系统。但挑战在于，你如何选择一个方向集中精力处理。</p>
<p>如果你将机器学习算法应用到新的应用程序里，你的主要目标是弄出能用的系统，你的主要目标并不是发明全新的机器学习算法，这是完全不同的目标，那时你的目标应该是想出某种效果非常好的算法。所以我鼓励你们搭建快速而粗糙的实现，然后用它做偏差/方差分析，用它做错误分析，然后用分析结果确定下一步优先要做的方向。</p>
<h5 id="不同分布数据进行训练和测试"><a href="#不同分布数据进行训练和测试" class="headerlink" title="不同分布数据进行训练和测试"></a>不同分布数据进行训练和测试</h5><p>深度学习算法对训练数据的胃口很大，当你收集到足够多带标签的数据构成训练集时，算法效果最好，这导致很多团队用尽一切办法收集数据，然后把它们堆到训练集里，让训练的数据量更大，即使有些数据，甚至是大部分数据都来自和开发集、测试集不同的分布(如网页爬高质量200K,用户上传低质量图片10K)。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570872074698.png" alt="1570872074698"></p>
<p>现在你就陷入困境了，因为你有一个相对小的数据集，只有 10,000 个样本来自那个分布，而你还有一个大得多的数据集来自另一个分布，图片的外观和你真正想要处理的并不一样。你的大部分精力都用在优化来自网页下载的图片，这其实不是你想要的。</p>
<p>建议这样：训练集，比如说还是 205,000 张图片，我们的训练集是来自网页下载的 200,000 张图片，然后如果需要的话，再加上 5000 张来自手机上传的图片。然后对于开发集和测试集，这数据集的大小是按比例画的，你的开发集和测试集都是手机图。</p>
<h5 id="数据分布不匹配时的偏差与方差的分析"><a href="#数据分布不匹配时的偏差与方差的分析" class="headerlink" title="数据分布不匹配时的偏差与方差的分析"></a>数据分布不匹配时的偏差与方差的分析</h5><p>当你的训练集来自和开发集、测试集不同分布时，分析偏差和方差的方式可能不一样</p>
<p>训练-开发集，这是一个新的数据子集，从训练集的分布里挖出来，但你不会用来训练你的网络。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570930138925.png" alt="1570930138925"></p>
<p>也许算法在开发集上做得不错，可能因为训练集很容易识别，因为训练集都是高分辨率图片，很清晰的图像，但开发集要难以识别得多。所以也许软件没有方差问题，这只不过反映了开发集包含更难准确分类的图片。所以这个分析的问题在于，当你看训练误差，再看开发误差，有两件事变了。首先算法只见过训练集数据，没见过开发集数据。第二，开发集数据来自不同的分布。而且因为你同时改变了两件事情，很难确认这增加的 9%误差率有多少是因为算法没看到开发集中的数据导致的，这是问题方差的部分，有多少是因为开发集数据就是不一样。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570930002910.png" alt="1570930002910"></p>
<h5 id="处理数据不匹配问题"><a href="#处理数据不匹配问题" class="headerlink" title="处理数据不匹配问题"></a>处理数据不匹配问题</h5><p>如果您的训练集来自和开发测试集不同的分布，如果错误分析显示你有一个数据不匹配的问题该怎么办？如果我发现有严重的数据不匹配问题，我通常会亲自做错误分析，尝试了解训练集和开发测试集的具体差异。技术上，为了避免对测试集过拟合，要做错误分析，你应该人工去看开发集而不是测试集。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570931168253.png" alt="1570931168253"></p>
<p><strong>尝试收集更多和真正重要的场合相似的数据</strong>，人工合成数据（artificial data synthesis）。</p>
<p>人工数据合成有一个潜在问题，比如说，你在安静的背景里录得10,000 小时音频数据，然后，比如说，你只录了一小时车辆背景噪音，那么，你可以这么做，将这 1 小时汽车噪音回放 10,000 次，并叠加到在安静的背景下录得的 10,000 小时数据。如果你这么做了，人听起来这个音频没什么问题。但是有一个风险，有可能你的学习算法对这1 小时汽车噪音过拟合。特别是，如果这组汽车里录的音频可能是你可以想象的所有汽车噪音背景的集合，如果你只录了一小时汽车噪音，那你可能只模拟了全部数据空间的一小部分，你可能只从汽车噪音的很小的子集来合成数据。</p>
<h5 id="迁移学习（Transfer-learning-）"><a href="#迁移学习（Transfer-learning-）" class="headerlink" title="迁移学习（Transfer learning ）"></a>迁移学习（Transfer learning ）</h5><p>深度学习中，最强大的理念之一就是，有的时候神经网络可以从一个任务中习得知识，并将这些知识应用到另一个独立的任务中。所以例如，也许你已经训练好一个神经网络，能够识别像猫这样的对象，然后使用那些知识，或者部分习得的知识去帮助您更好地阅读 x 射线扫描图，这就是所谓的迁移学习。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570931912128.png" alt="1570931912128"></p>
<p>假设你已经训练好一个图像识别神经网络，所以你首先用一个神经网络，并在(x,y)对上训练，其中x是图像，y是某些对象，图像是猫、狗、鸟或其他东西。如果你把这个神经网络拿来，然后让它适应或者说迁移，在不同任务中学到的知识，比如放射科诊断，就是说阅读X射线扫描图。你可以做的是把神经网络最后的输出层拿走，就把它删掉，还有进入到最后一层的权重删掉，然后为最后一层重新赋予随机权重，然后让它在放射诊断数据上训练。</p>
<p>如果你有足够多的数据，你可以重新训练神经网络中剩下的所有层。经验规则是，如果你有一个小数据集，就只训练输出层前的最后一层，或者也许是最后一两层。但是如果你有很多数据，那么也许你可以重新训练网络中的所有参数。如果你重新训练神经网络中的所有参数，那么这个在图像识别数据的初期训练阶段，有时称为预训练（pre-training），因为你在用图像识别数据去预先初始化，或者预训练神经网络的权重。然后，如果你以后更新所有权重，然后在放射科数据上训练，有时这个过程叫微调（fine tuning）。</p>
<p>为什么迁移学习这样做有效果呢？有很多低层次特征，比如说边缘检测、曲线检测、阳性对象检测（positive objects），从非常大的图像识别数据库中习得这些能力可能有助于你的学习算法在放射科诊断中做得更好，算法学到了很多结构信息，图像形状的信息，其中一些知识可能会很有用，所以学会了图像识别，它就可能学到足够多的信息，可以了解不同图像的组成部分是怎样的，学到线条、点、曲线这些知识，也许对象的一小部分，这些知识有可能帮助你的放射科诊断网络学习更快一些，或者需要更少的学习数据。</p>
<p>迁移学习起作用的场合是，在迁移来源问题中你有很多数据，但迁移目标问题你没有那么多数据。例如，假设图像识别任务中你有 1 百万个样本，所以这里数据相当多。可以学习低层次特征，可以在神经网络的前面几层学到如何识别很多有用的特征。但是对于放射科任务，也许你只有一百个样本，所以你的放射学诊断问题数据很少，也许只有 100 次X射线扫描，所以你从图像识别训练中学到的很多知识可以迁移，并且真正帮你加强放射科识别任务的性能，即使你的放射科数据很少。</p>
<p>所以总结一下，什么时候迁移学习是有意义的？1.如果你想从任务𝐵学习并迁移一些知识到任务𝐶，那么当任务𝐵和任务𝐶都有同样的输入x时，迁移学习是有意义的。在第一个例子中，𝐵和𝐶的输入都是图像，在第二个例子中，两者输入都是音频。2.当任务𝐵的数据比任务𝐶多得多时，迁移学习意义更大。所有这些假设的前提都是，你希望提高任务𝐶的性能，因为任务𝐶每个数据更有价值，对任务𝐶来说通常任务𝐵的数据量必须大得多，才有帮助，因为任务𝐵里单个样本的价值没有比任务𝐶单个样本价值大。</p>
<h5 id="多任务学习（Multi-task-learning"><a href="#多任务学习（Multi-task-learning" class="headerlink" title="多任务学习（Multi-task learning)"></a>多任务学习（Multi-task learning)</h5><p>在迁移学习中，你的步骤是串行的，你从任务𝐵里学习只是然后迁移到任务𝐶。在多任务学习中，你是同时开始学习的，试图让单个神经网络同时做几件事情，然后希望这里每个任务都能帮到其他所有任务。</p>
<p>我们来看一个例子，假设你在研发无人驾驶车辆，那么你的无人驾驶车可能需要同时检测不同的物体，比如检测行人、车辆、停车标志，还有交通灯各种其他东西。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570933101020.png" alt="1570933101020"></p>
<p>那么你现在可以做的是训练一个神经网络，来预测这些y值，你就得到这样的神经网络，输入x，现在输出是一个四维向量y。请注意，这里输出我画了四个节点，所以第一个节点就是我们想预测图中有没有行人，然后第二个输出节点预测的是有没有车，这里预测有没有停车标志，这里预测有没有交通灯，所以这里y^ 是四维的。整个训练集的平均损失和之前分类猫的例子主要区别在于，现在你要对𝑘 = 1到4求和，这与 softmax 回归的主要区别在于，与 softmax 回归不同，softmax 将单个标签分配给单个样本,只能有一个为1。而这张图可以有很多不同的标签，你要知道每张照片是否有行人、或汽车、停车标志或交通灯，多个物体可能同时出现在一张图里。</p>
<p>如果你训练了一个神经网络，试图最小化这个成本函数，你做的就是多任务学习。因为你现在做的是建立单个神经网络，观察每张图，然后解决四个问题，系统试图告诉你，每张图里面有没有这四个物体。另外你也可以训练四个不同的神经网络，而不是训练一个网络做四件事情。但神经网络一些早期特征，在识别不同物体时都会用到，然后你发现，训练一个神经网络做四件事情会比训练四个完全独立的神经网络分别做四件事性能要更好，这就是多任务学习的力量。</p>
<p>也许有些样本都有标记，但也许有些样本他们只标记了有没有车，然后还有一些是问号。即使是这样的数据集，你也可以在上面训练算法，同时做四个任务，即使一些图像只有一小部分标签，其他是问号或者不管是什么。然后你训练算法的方式，即使这里有些标签是问号，或者没有标记，这就是对𝑘从 1 到 4 求和，你就只对带 0 和 1 标签的𝑘值求和，所以当有问号的时候，你就在求和时忽略那个项，这样只对有标签的值求和，于是你就能利用这样的数据集。</p>
<p>那么多任务学习什么时候有意义呢？当三件事为真时，它就是有意义的。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570937014397.png" alt="1570937014397"></p>
<p>第一，如果你训练的一组任务，可以共用低层次特征。第二，如果每个任务中的数据量很相近，最后多任务学习往往在以下场合更有意义，当你可以训练一个足够大的神经网络，同时做好所有的工作，所以多任务学习的替代方法是为每个任务训练一个单独的神经网络。但如果你可以训练一个足够大的神经网络，那么多任务学习肯定不会或者很少会降低性能，我们都希望它可以提升性能，比单独训练神经网络来单独完成各个任务性能要更好。</p>
<p>所以总结一下，多任务学习能让你训练一个神经网络来执行许多任务，这可以给你更高的性能，比单独完成各个任务更高的性能。但要注意，实际上迁移学习比多任务学习使用频率更高。</p>
<h5 id="端到端的深度学习"><a href="#端到端的深度学习" class="headerlink" title="端到端的深度学习"></a>端到端的深度学习</h5><p>深度学习中最令人振奋的最新动态之一就是端到端深度学习的兴起，那么端到端学习到底是什么呢？简而言之，以前有一些数据处理系统或者学习系统，它们需要多个阶段的处理。那么端到端深度学习就是忽略所有这些不同的阶段，用单个神经网络代替它。</p>
<p>我们来看一些例子，以语音识别为例，你的目标是输入x，比如说一段音频，然后把它映射到一个输出y，就是这段音频的听写文本。所以传统上，语音识别需要很多阶段的处理。首先你会提取一些特征，一些手工设计的音频特征，也许你听过 MFCC，这种算法是用来从音频中提取一组特定的人工设计的特征。在提取出一些低层次特征之后，你可以应用机器学习算法在音频片段中找到音位，所以音位是声音的基本单位，比如说“Cat”这个词是三个音<br>节构成的，Cu-、Ah-和 Tu-，算法就把这三个音位提取出来，然后你将音位串在一起构成独立的词，然后你将词串起来构成音频片段的听写文本。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570938662864.png" alt="1570938662864"></p>
<p>和这种有很多阶段的流水线相比，端到端深度学习做的是，你训练一个巨大的神经网络，输入就是一段音频，输出直接是听写文本。事实证明，端到端深度学习的挑战之一是，你可能需要大量数据才能让系统表现良好。</p>
<p>我们再来看几个例子，比如机器翻译。传统上，机器翻译系统也有一个很复杂的流水线，比如英语机翻得到文本，然后做文本分析，基本上要从文本中提取一些特征之类的，经过很多步骤，你最后会将英文文本翻译成法文。因为对于机器翻译来说的确有很多(英文,法文)的数据对，端到端深度学习在机器翻译领域非常好用，那是因为在今天可以收集x − y对的大数据集，就是英文句子和对应的法语翻译。所以在这个例子中，端到端深度学习效果很好。</p>
<p>端到端深度学习系统是可行的，它表现可以很好，也可以简化系统架构，让你不需要搭建那么多手工设计的单独组件，但它也不是灵丹妙药，并不是每次都能成功，下面是它的一些优缺点。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1570939219156.png" alt="1570939219156"></p>
<p>首先端到端学习真的只是让数据说话。端到端深度学习的第二个好处就是这样，所需手工设计的组件更少，所以这也许能够简化你的设计工作流程，你不需要花太多时间去手工设计功能，手工设计这些中间表示方式。那么缺点呢？这里有一些缺点，首先，它可能需要大量的数据。另一个缺点是，它排除了可能有用的手工设计组件。但是当你没有太多的数据时，构造一个精心设计的系统，实际上可以将人类对这问题的很多认识直接注入到问题里，进入算法里应该挺有帮助的。</p>
<h3 id="卷积神经网络基础"><a href="#卷积神经网络基础" class="headerlink" title="卷积神经网络基础"></a>卷积神经网络基础</h3><h5 id="计算机视觉（Computer-vision）"><a href="#计算机视觉（Computer-vision）" class="headerlink" title="计算机视觉（Computer vision）"></a>计算机视觉（Computer vision）</h5><p>本节课将要学习的一些问题，比如图片分类，或者说图片识别，给出这张 64×64 的图片，让计算机去分辨出这是一只猫。在目标检测项目中，首先需要计算出图中有哪些物体，比如汽车，还有图片中的其他东西，再将它们模拟成一个个盒子，或用一些其他的技术识别出它们在图片中的位置。还有一个更有趣的例子，就是神经网络实现的图片风格迁移，比如说你有一张图片，但你想将这张图片转换为另外一种风格。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571559653256.png" alt="1571559653256"></p>
<p>在应用计算机视觉时要面临一个挑战，就是数据的输入可能会非常大。举个例子，前面我们一般操作的都是64×64 的小图片，实际上，它的数据量是 64×64×3，因为每张图片都有 3 个颜色通道。如果计算一下的话，可得知数据量为 12288，所以我们的特征向量𝑦维度为 12288。这其实还好，因为 64×64 真的是很小的一张图片。如果你要操作更大的图片，比如一张 1000×1000 的图片，它足有 1 兆那么大，但是特征向量的维度达到1000×1000×3，因为有 3 个 RGB 通道，所以数字将会是 300 万。这就意味着，特征向量x的维度高达 300 万。所以在第一隐藏层中，你也许会有 1000 个隐藏单元，而所有的权值组成了矩阵 W [1] 。如果你使用了标准的全连接网络，这个矩阵的大小将会是1000×300 万,这是个非常巨大的数字。在参数如此大量的情况下，难以获得足够的数据来防止神经网络发生过拟合和竞争需求，要处理包含 30 亿参数的神经网络，巨大的内存需求让人不太能接受。</p>
<p>为此，你需要进行卷积计算，它是卷积神经网络中非常重要的一块。</p>
<h5 id="边缘检测示例（Edge-detection-example-）"><a href="#边缘检测示例（Edge-detection-example-）" class="headerlink" title="边缘检测示例（Edge detection example ）"></a>边缘检测示例（Edge detection example ）</h5><p>卷积运算是卷积神经网络最基本的组成部分，使用边缘检测作为入门样例。在这个视频中，你会看到卷积是如何进行运算的。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571559885971.png" alt="1571559885971"></p>
<p>之前讲过神经网络的前几层是如何检测边缘的，然后，后面的层有可能检测到物体的部分区域，更靠后的一些层可能检测到完整的物体，这个例子中就是人脸。在这个视频中，你会看到如何在一张图片中进行边缘检测。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571559969673.png" alt="1571559969673"></p>
<p>看一个例子，这是一个 6×6 的灰度图像。因为是灰度图像，所以它是 6×6×1 的矩阵，为了检测图像中的垂直边缘，你可以构造一个 3×3矩阵。在共用习惯中，在卷积神经网络的术语中，它被称为过滤器。在论文它有时候会被称为核，而不是过滤器。使用过滤器这个术语。对这个 6×6 的图像进行卷积运算，卷积运算用“∗”来表示，用 3×3的过滤器对其进行卷积。</p>
<p>因此 6×6 矩阵和 3×3 矩阵进行卷积运算得到 4×4 矩阵。这些图片和过滤器是不同维度的矩阵，但左边矩阵容易被理解为一张图片，中间的这个被理解为过滤器，右边的图片我们可以理解为另一张图片，这个就是垂直边缘检测器。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571560271760.png" alt="1571560271760"></p>
<p>这是一个简单的 6×6 图像，左边的一半是 10，右边一半是 0。如果你把它当成一个图片，左边那部分看起来是白色的，像素值 10 是比较亮的像素值，右边像素值比较暗，我使用灰色来表示 0，尽管它也可以被画成黑的。图片里，有一个特别明显的垂直边缘在图像中间，这条垂直线是从黑到白的过渡线，或者从白色到深色。卷积运算<br>后，你得到的是右边的矩阵。</p>
<p>如果把最右边的矩阵当成图像，它是这个样子。在中间有段亮一点的区域，对应检查到这个 6×6 图像中间的垂直边缘。这里的维数似乎有点不正确，检测到的边缘太粗了。因为在这个例子中，图片太小了。如果你用一个 1000×1000 的图像，而不是 6×6 的图片，你会发现其会很好地检测出图像中的垂直边缘。在这个例子中，在输出图像中间的亮处，表示在图像中间有一个特别明显的垂直边缘。</p>
<h5 id="更多边缘检测内容"><a href="#更多边缘检测内容" class="headerlink" title="更多边缘检测内容"></a>更多边缘检测内容</h5><p>你已经见识到用卷积运算实现垂直边缘检测，在本视频中，你将学习如何区分正边和负边，这实际就是由亮到暗与由暗到亮的区别，也就是边缘的过渡。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571560597128.png" alt="1571560597128"></p>
<p>还是上一个视频中的例子，这张 6×6 的图片，左边较亮，而右边较暗，将它与垂直边缘检测滤波器进行卷积，检测结果就显示在了右边这幅图的中间部分。现在这幅图有什么变化呢？它的颜色被翻转了，变成了左边比较暗，而右边比较亮。现在亮度为 10 的点跑到了右边，为 0 的点则跑到了左边。如果你用它与相同的过滤器进行卷积，最后得到的图中间会是-30，而不是 30。如果你将矩阵转换为图片，就会是该矩阵下面图片的样子，表明是由暗向亮过渡。如果你不在乎这两者的区别，你可以取出矩阵的绝对值。但这个特定的过滤器确实可以为我们区分这两种明暗变化的区别。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571560805105.png" alt="1571560805105"></p>
<p>我们已经见过这个 3×3 的过滤器，它可以检测出垂直的边缘。所以，看到右边这个过滤器，我想你应该猜出来了，它能让你检测出水平的边缘。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571561171670.png" alt="1571561171670"></p>
<p>通过使用不同的过滤器，你可以找出垂直的或是水平的边缘。但事实上，对于这个 3×3 的过滤器来说，我们使用了其中的一种数字组合。计算机视觉的研究者们也会经常使用其他的数字组合，比如 Sobel 的过滤器， Scharr 过滤器等。随着深度学习的发展，我们学习的其中一件事就是当你真正想去检测出复杂图像的边缘，你不一定要去使用那些研究者们所选择的这九个数字，但你可以从中获益匪浅。把这矩阵中的 9 个数字当成 9 个参数，并且在之后你可以学习使用反向传播算法，其目标就是去理解这9 个参数。</p>
<h5 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h5><p>为了构建深度神经网络，你需要学会使用的一个基本的卷积操作就是 padding。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571561823489.png" alt="1571561823489"></p>
<p>我们在之前视频中看到，如果你用一个 3×3 的过滤器卷积一个 6×6 的图像，你最后会得到一个 4×4 的输出，也就是一个 4×4 矩阵。那是因为你的 3×3 过滤器在 6×6 矩阵中，只可能有 4×4 种可能的位置。这背后的数学解释是，如果我们有一个n × n的图像，用f × f的过滤器做卷积，那么输出的维度就是(n − f + 1) × (n − f + 1)。</p>
<p>这样的话会有两个缺点，第一个缺点是每次做卷积操作，你的图像就会缩小，从 6×6 缩小到 4×4，你可能做了几次之后，你的图像就会变得很小了，可能会缩小到只有 1×1 的大小。第二个缺点，如果你注意角落边缘的像素，这个像素点（绿色阴影标记）只被一个输出所触碰或者使用，因为它位于这个 3×3 的区域的一角。但如果是在中间的像素点，比如这个（红色方框标记），就会有许多 3×3 的区域与之重叠。所以那些在角落或者边缘区域的像素点在输出中采用较少，意味着你丢掉了图像边缘位置的许多信息。</p>
<p>为了解决这些问题，你可以在卷积操作之前填充这幅图像。在这个案例中，你可以沿着图像边缘再填充一层像素。如果你这样操作了，那么 6×6 的图像就被你填充成了一个 8×8 的图像。如果你用 3×3 的图像对这个 8×8 的图像卷积，你得到的输出就不是 4×4 的，而是 6×6的图像，你就得到了一个尺寸和原始图像 6×6 的图像。习惯上，你可以用 0 去填充，如果p是填充的数量，在这个案例中，p = 1，因为我们在周围都填充了一个像素点，输出也就变成了(n +2p − f + 1) × (n +2p − f + 1)。这个涂绿的像素点（左边矩阵）影响了输出中的这些格子（右边矩阵）。这样一来，丢失信息或者更准确来说角落或图像边缘的信息发挥的作用较小的这一缺点就被削弱了。</p>
<p>至于选择填充多少像素，通常有两个选择，分别叫做 Valid 卷积和 Same 卷积。Valid 卷积意味着不填充，另一个经常被用到的填充方法叫做 Same 卷积，那意味你填充后，你的输出大小和输入大小是一样的。习惯上，我推荐你只使用奇数的过滤器，你经常会看到 3×3 的过滤器，你也可能会看到一些 5×5，7×7 的过滤器，后面我们也会谈到 1×1 的过滤器。</p>
<h5 id="卷积步长（Strided-convolutions）"><a href="#卷积步长（Strided-convolutions）" class="headerlink" title="卷积步长（Strided convolutions）"></a>卷积步长（Strided convolutions）</h5><p>卷积中的步幅是另一个构建卷积神经网络的基本操作</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571562423233.png" alt="1571562423233"></p>
<p>之前我们移动蓝框的步长是 1，现在移动的步长是 2，我们让过滤器跳过 2 个步长，注意一下左上角，这个点移动到其后两格的点，跳过了一个位置。然后你还是将每个元素相乘并求和，你将会得到的结果是 100。</p>
<p>按照机器学习的惯例，我们通常不进行翻转操作。从技术上说，这个操作可能叫做互相关更好。但在大部分的深度学习文献中都把它叫做卷积运算，因此我们将在这些视频中使用这个约定。</p>
<h5 id="三维卷积（Convolutions-over-volumes）"><a href="#三维卷积（Convolutions-over-volumes）" class="headerlink" title="三维卷积（Convolutions over volumes）"></a>三维卷积（Convolutions over volumes）</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571563376284.png" alt="1571563376284"></p>
<p>这里的第一个 6 代表图像高度，第二个 6 代表宽度，这个3 代表通道的数目。同样你的过滤器也有高，宽和通道数，并且图像的通道数必须和过滤器的通道数匹配，所以这两个数（紫色方框标记的两个数）必须相等。先取红色通道的前 9 个数字，然后是绿色通道，然后再是蓝色通道，乘以左边黄色立方体覆盖的对应的 27 个数，然后把这些数都加起来，就得到了输出的第一个数字。</p>
<p>如果你想检测图像红色通道的边缘，而绿色通道全为 0，蓝色也全为 0。如果你把这三个堆叠在一起形成一个 3×3×3 的过滤器，那么这就是一个检测垂直边界的过滤器，但只对红色通道有用。按照计算机视觉的惯例，当你的输入有特定的高宽和通道数时，你的过滤器可以有不同的高，不同的宽，但是必须一样的通道数。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571575064532.png" alt="1571575064532"></p>
<p>如果你想同时用多个过滤器怎么办？（第一个）这可能是一个垂直边界检测器或者是学习检测其他的特征。第二个过滤器可以用橘色来表示，它可以是一个水平边缘检测器。所以和第一个过滤器卷积，可以得到第一个 4×4 的输出，然后卷积第二个过滤器，得到一个不同的 4×4 的输出。我们做完卷积，然后把这两个 4×4 的输出，取第一个把它放到前面，然后取第二个过滤器输出，我把它画在这，放到后面，就是一个 4×4×2 的输出立方体。</p>
<p>对立方体卷积的概念真的很有用，你现在可以用它的一小部分直接在三个通道的RGB 图像上进行操作。更重要的是，你可以检测两个特征，比如垂直和水平边缘或者 10 个或者 128 个或者几百个不同的特征，并且输出的通道数会等于你要检测的特征数。对于这里的符号，我一直用通道数（nc）来表示最后一个维度，在文献里大家也把它叫做 3 维立方体的深度。</p>
<h5 id="单层卷积网络"><a href="#单层卷积网络" class="headerlink" title="单层卷积网络"></a>单层卷积网络</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571576433362.png" alt="1571576433362"></p>
<p>我们已经讲了如何通过两个过滤器卷积处理一个三维图像，并输出两个不同的4×4 矩阵。假设使用第一个过滤器进行卷积，得到第一个 4×4 矩阵。使用第二个过滤器进行卷积得到另外一个 4×4 矩阵。各自形成一个卷积神经网络层，然后增加偏差，它是一个实数，通过 Python 的广播机制给这 16 个元素都加上同一偏差。然后应用非线性函数，为了说明，它是一个非线性激活函数 ReLU，输出结果是一个 4×4 矩阵。对于第二个 4×4 矩阵，我们加上不同的偏差，它也是一个实数。</p>
<p>这一部分（图中蓝色边框标记的部分）就是应用激活函数 ReLU 之前的值，它的作用类似于Z [1] ，最后应用非线性函数，得到的这个 4×4×2 矩阵，成为神经网络的下一层，也就是激活层。这就是a [0] 到a [1] 的演变过程，首先执行线性函数，然后所有元素相乘做卷积，具体做法是运用线性函数再加上偏差，然后应用激活函数 ReLU。</p>
<p>用 10 个过滤器来提取特征，如垂直边缘，水平边缘和其它特征。即使这些图片很大，参数却很少，这就是卷积神经网络的一个特征，叫作“ 避免过拟合”。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571577042210.png" alt="1571577042210"></p>
<p>卷积有很多种标记方法，这是我们最常用的卷积符号。大家在线搜索或查看开源代码时，关于高度，宽度和通道的顺序并没有完全统一的标准卷积,了解了卷积神经网络中某一卷积层的工作原理，我们就可以把它们堆叠起来形成一个深度卷积神经网络。</p>
<h5 id="简单卷积网络示例"><a href="#简单卷积网络示例" class="headerlink" title="简单卷积网络示例"></a>简单卷积网络示例</h5><p>假设你有一张图片，你想做图片分类或图片识别，把这张图片输入定义为x，然后辨别图片中有没有猫，用 0 或 1 表示，这是一个分类问题，我们来构建适用于这项任务的卷积神经网络。针对这个示例，我用了一张比较小的图片，大小是 39×39×3，这样设定可以使其中一些数字效果更好。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571577508713.png" alt="1571577508713"></p>
<p>这张 39×39×3 的输入图像就处理完毕了，为图片提取了 7×7×40 个特征，计算出来就是 1960 个特征。然后对该卷积进行处理，可以将其平滑或展开成 1960 个单元。平滑处理后可以输出一个向量，其填充内容是 logistic 回归单元还是 softmax 回归单元，完全取决于我们是想识图片上有没有猫，还是想识别K种不同对象中的一种，用y^ 表示最终神经网络的预测输出。明确一点，最后这一步是处理所有数字，即全部的 1960 个数字，把它们展开成一个很长的向量。为了预测最终的输出结果，我们把这个长向量填充到 softmax 回归函数中。</p>
<p>这是卷积神经网络的一个典型范例，设计卷积神经网络时，确定这些超参数比较费工夫。要决定过滤器的大小、步幅、padding 以及使用多少个过滤器。随着神经网络计算深度不断加深，通常开始时的图像也要更大一些，初始值为 39×39，高度和宽度会在一段时间内保持一致，然后随着网络深度的加深而逐渐减小，从 39 到 37，再到 17，最后到 7。而通道数量在增加，从 3 到 10，再到 20，最后到 40。在许多其它卷积神经网络中，你也可以看到这种趋势。</p>
<p>一个典型的卷积神经网络通常有三层，一个是卷积层，我们常常用 Conv 来标注。上一个例子，我用的就是 CONV。还有两种常见类型的层，我们留在后两节课讲。一个是池化层，我们称之为 POOL。最后一个是全连接层，用 FC 表示。虽然仅用卷积层也有可能构建出很好的神经网络，但大部分神经望楼架构师依然会添加池化层和全连接层。幸运的是，池化层和全连接层比卷积层更容易设计。</p>
<h5 id="池化层（Pooling-layers"><a href="#池化层（Pooling-layers" class="headerlink" title="池化层（Pooling layers)"></a>池化层（Pooling layers)</h5><p>除了卷积层，卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性,</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571577935466.png" alt="1571577935466"></p>
<p>假如输入是一个 4×4 矩阵，用到的池化类型是最大池化（max pooling）。执行最大池化的树池是一个 2×2 矩阵。执行过程非常简单，把 4×4 的输入拆分成不同的区域，我把这个区域用不同颜色来标记。对于 2×2的输出，输出的每个元素都是其对应颜色区域中的最大元素值。这是一个 2×2 矩阵，即f = 2，步幅是 2，即s = 2。</p>
<p>最大化运算的实际作用就是，如果在过滤器中提取到某个特征，那么保留其最大值。如果没有提取到这个特征，<br>可能在右上象限中不存在这个特征，那么其中的最大值也还是很小，这就是最大池化的直观理解。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571578148185.png" alt="1571578148185"></p>
<p>另外还有一种类型的池化，平均池化，它不太常用。我简单介绍一下，这种运算顾名思义，选取的不是每个过滤器的最大值，而是平均值。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571578246075.png" alt="1571578246075"></p>
<p>目前来说，最大池化比平均池化更常用。但也有例外，就是深度很深的神经网络，你可以用平均池化来分解规模为 7×7×1000 的网络的表示层，在整个空间内求平均值，得到1×1×1000，一会我们看个例子。但在神经网络中，最大池化要比平均池化用得更多。</p>
<p>总结一下，池化的超级参数包括过滤器大小f和步幅s，常用的参数值为f = 2，s= 2，应用频率非常高，其效果相当于高度和宽度缩减一半。</p>
<h5 id="卷积神经网络示例"><a href="#卷积神经网络示例" class="headerlink" title="卷积神经网络示例"></a>卷积神经网络示例</h5><p>有一张大小为 32×32×3 的输入图片，这是一张 RGB 模式的图片，你想做手写体数字识别。32×32×3 的 RGB 图片中含有某个数字，比如 7，你想识别它是从 0-9 这 10 个数字中的哪一个，我们构建一个神经网络来实现这个功能。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571578435669.png" alt="1571578435669"></p>
<p>人们在计算神经网络有多少层时，通常只统计具有权重和参数的层。因为池化层没有权重和参数，只有一些超参数。这里，我们把 CONV1和 POOL1 共同作为一个卷积，并标记为 Layer1。虽然你在阅读网络文章或研究报告时，你可能会看到卷积层和池化层各为一层的情况，这只是两种不同的标记术语.</p>
<h5 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h5><p>(接上）5×5×16 矩阵包含 400 个元素，现在将 POOL2 平整化为一个大小为 400 的一维向量。我们可以把平整化结果想象成这样的一个神经元集合，然后利用这 400 个单元构建下一层。下一层含有 120 个单元，这就是我们第一个全连接层，标记为 FC3。这 400 个单元与 120 个单元紧密相连，这就是全连接层。它很像我们在第一和第二门课中讲过的单神经网络层，这是一个标准的神经网络。它的权重矩阵为W [3] ，维度为 120×400。这就是所谓的“全连接”，因为这 400 个单元与这 120 个单元的每一项连接，还有一个偏差参数。最后输出 120 个维度，因为有 120 个输出。</p>
<p>然后我们对这个 120 个单元再添加一个全连接层，这层更小，假设它含有 84 个单元，标记为 FC4。最后，用这 84 个单元填充一个 softmax 单元。如果我们想通过手写数字识别来识别手写 0-9 这 10 个数字，这个 softmax 就会有 10 个输出。</p>
<p>此例中的卷积神经网络很典型，看上去它有很多超参数，关于如何选定这些参数，后面我提供更多建议。常规做法是，尽量不要自己设置超参数，而是查看文献中别人采用了哪些超参数，选一个在别人任务中效果很好的架构，那么它也有可能适用于你自己的应用程序。</p>
<p>现在，我想指出的是，随着神经网络深度的加深，高度nH  和宽度nW 通常都会减少，前面我就提到过，从 32×32 到 28×28，到 14×14，到 10×10，再到 5×5。所以随着层数增加，高度和宽度都会减小，而通道数量会增加，从 3 到 6 到 16 不断增加，然后得到一个全连接层。</p>
<p>在神经网络中，另一种常见模式就是一个或多个卷积后面跟随一个池化层，然后一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个 softmax。这是神经网络的另一种常见模式。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571579036127.png" alt="1571579036127"></p>
<p>第一，池化层和最大池化层没有参数；第二卷积层的参数相对较少，前面课上我们提到过，其实许多参数都存在于神经网络的全连接层。观察可发现，随着神经网络的加深，激活值尺寸会逐渐变小，如果激活值尺寸下降太快，也会影响神经网络性能。神经网络的基本构造模块我们已经讲完了，一个卷积神经网络包括卷积层、池化层和全连接层。根据我的经验，找到整合基本构造模块最好方法就是大量阅读别人的案例。</p>
<h5 id="为什么使用卷积"><a href="#为什么使用卷积" class="headerlink" title="为什么使用卷积"></a>为什么使用卷积</h5><p>和只用全连接层相比，卷积层的两个主要优势在于参数共享和稀疏连接</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571579178802.png" alt="1571579178802"></p>
<p>假设有一张 32×32×3 维度的图片，这是上节课的示例，假设用了 6 个大小为 5×5 的过滤器，输出维度为 28×28×6。32×32×3=3072，28×28×6=4704。我们构建一个神经网络，其中一层含有 3072 个单元，下一层含有 4074 个单元，两层中的每个神经元彼此相连，然后计算权重矩阵，它等于 4074×3072≈1400 万，所以要训练的参数很多。虽然以现在的技术，我们可以用 1400 多万个参数来训练网络，因为这张 32×32×3 的图片非常小，训练这么多参数没有问题。如果这是一张 1000×1000 的图片，权重矩阵会变得非常大。我们看看这个卷积层的参数数量，每个过滤器都是 5×5，一个过滤器有 25 个参数，再加上偏差参数，那么每个过滤器就有 26 个参数，一共有 6 个过滤器，所以参数共计 156 个，参数数量还是很少。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571579407747.png" alt="1571579407747"></p>
<p>卷积网络映射这么少参数有两个原因：<br>一是参数共享。观察发现，特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。也就是说，如果你用一个 3×3 的过滤器检测垂直边缘，那么图片的左上角区域，以及旁边的各个区域（左边矩阵中蓝色方框标记的部分）都可以使用这个 3×3 的过滤器。每个特征检测器以及输出都可以在输入图片的不同区域中使用同样的参数，以便提取垂直边缘或其它特征。它不仅适用于边缘特征这样的低阶特征，同样适用于高阶特征，例如提取脸上的眼睛，猫或者其他特征对象。直观感觉是，一个特征检测器，如垂直边缘检测器用于检测图片左上角区域的特征，这个特征很可能也适用于图片的右下角区域。因此在计算图片左上角和右下角区域时，你不需要添加其它特征检测器。假如有一个这样的数据集，其左上角和右下角可能有不同分布，也有可能稍有不同，但很相似，整张图片共享特征检测器，提取效果也很好。</p>
<p>第二个方法是使用稀疏连接，我来解释下。这个 0 是通过 3×3 的卷积计算得到的，它只依赖于这个 3×3 的输入的单元格，右边这个输出单元（元素 0）仅与 36 个输入特征中 9 个相连接。而且其它像素值都不会对输出产生任影响，这就是稀疏连接的概念。再举一个例子，这个输出（右边矩阵中红色标记的元素 30）仅仅依赖于这 9 个特征（左边矩阵红色方框标记的区域），看上去只有这 9 个输入特征与输出相连接，其它像素对输出没有任何影响。</p>
<p>神经网络可以通过这两种机制减少参数，以便我们用更小的训练集来训练它，从而预防过度拟合。你们也可能听过，卷积神经网络善于捕捉平移不变。通过观察可以发现，向右移动两个像素，图片中的猫依然清晰可见，因为神经网络的卷积结构使得即使移动几个像素，这张图片依然具有非常相似的特征，应该属于同样的输出标记。</p>
<h3 id="深度卷积网络：实例探究"><a href="#深度卷积网络：实例探究" class="headerlink" title="深度卷积网络：实例探究"></a>深度卷积网络：实例探究</h3><p>在计算机视觉任务中表现良好的神经网络框架往往也适用于其它任务，也许你的任务也不例外。</p>
<p>LeNet-5 网络，经常被引用的 AlexNet，还有 VGG 网络。这些都是非常有效的神经网络范例，当中的一些思路为现代计算机视觉技术的发展奠定了基础。</p>
<p>然后是 ResNet，又称残差网络。神经网络正在不断加深，对此你可能有所了解。ResNet神经网络训练了一个深达 152 层的神经网络，并且在如何有效训练方面，总结出了一些有趣的想法和窍门。课程最后，我们还会讲一个 Inception 神经网络的实例分析。</p>
<h5 id="经典网络（Classic-networks-）"><a href="#经典网络（Classic-networks-）" class="headerlink" title="经典网络（Classic networks ）"></a>经典网络（Classic networks ）</h5><p>这节课，我们来学习几个经典的神经网络结构，分别是 LeNet-5、AlexNet 和 VGGNet。</p>
<p>首先看看 LeNet-5 的网络结构，假设你有一张 32×32×1 的图片，LeNet-5 可以识别图中的手写数字，比如像这样手写数字 7。LeNet-5 是针对灰度图片训练的，所以图片的大小只有 32×32×1。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571796325642.png" alt="1571796325642"></p>
<p>相比现代版本，这里得到的神经网络会小一些，只有约 6 万个参数。而现在，我们经常看到含有一千万到一亿个参数的神经网络，比这大 1000 倍的神经网络也不在少数。不管怎样，如果我们从左往右看，随着网络越来越深，图像的高度和宽度在缩小，从最初的 32×32 缩小到 28×28，再到 14×14、10×10，最后只有 5×5。与此同时，随着网络层次的加深，通道数量一直在增加，从 1 增加到 6 个，再到 16 个。这个神经网络中还有一种模式至今仍然经常用到，就是一个或多个卷积层后面跟着一个池化层，然后又是若干个卷积层再接一个池化层，然后是全连接层，最后是输出，这种排列方式很常用。</p>
<p>举例说明的第二种神经网络是 AlexNet，AlexNet首先用一张227×227×3的图片作为输入，实际上原文中使用的图像是224×224×3，但是如果你尝试去推导一下，你会发现 227×227 这个尺寸更好一些。第一层我们使用 96 个11×11 的过滤器，步幅为 4，由于步幅是 4，因此尺寸缩小到 55×55，缩小了 4 倍左右。然后 用一个 3×3 的过滤器构建最大池化层，f = 3，步幅s为 2，卷积层尺寸缩小为 27×27×96。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571796604495.png" alt="1571796604495"></p>
<p>这种神经网络与 LeNet 有很多相似之处，不过 AlexNet 要大得多。正如前面讲到的 LeNet 或 LeNet-5 大约有 6 万个参数，而 AlexNet 包含约 6000 万个参数。当用于训练图像和数据集时，AlexNet 能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐藏单元或数据，这一点 AlexNet 表现出色。AlexNet 比 LeNet 表现更为出色的另一个原因是它使用了 ReLu 激活函数。</p>
<p>这节课要讲的第三个，也是最后一个范例是 VGG，也叫作 VGG-16 网络。值得注意的一点是，VGG-16 网络没有那么多超参数，这是一种只需要专注于构建卷积层的简单网络。首先用 3×3，步幅为 1 的过滤器构建卷积层，padding 参数为 same 卷积中的参数。然后用一个2×2，步幅为 2 的过滤器构建最大池化层。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571796903608.png" alt="1571796903608"></p>
<p>假设要识别这个图像，在最开始的两层用 64 个 3×3 的过滤器对输入图像进行卷积，输出结果是 224×224×64，因为使用了 same 卷积，通道数量也一样。VGG-16 其实是一个很深的网络，这里我并没有把所有卷积层都画出来。假设这个小图是我们的输入图像，尺寸是 224×224×3，进行第一个卷积之后得到224×224×64 的特征图，接着还有一层 224×224×64，得到这样 2 个厚度为 64 的卷积层，意味着我们用64个过滤器进行了两次卷积。</p>
<p>接下来创建一个池化层，池化层将输入图像进行压缩，从 224×224×64 缩小到多少呢？没错，减少到 112×112×64。然后又是若干个卷积层，使用 129 个过滤器，以及一些 same 卷积，我们看看输出什么结果，112×112×128.然后进行池化，可以推导出池化后的结果是这样（56×56×128）。接着再用 256 个相同的过滤器进行三次卷积操作，然后再池化，然后再卷积三次，再池化。如此进行几轮操作后，将最后得到的 7×7×512 的特征图进行全连接操作，得到 4096 个单元，然后进行 softmax 激活，输出从 1000 个对象中识别的结果。VGG-16 的这个数字 16，就是指在这个网络中包含 16 个卷积层和全连接层。确实是个很大的网络，总共包含约 1.38 亿个参数，即便以现在的标准来看都算是非常大的网络.</p>
<h5 id="残差网络-ResNets-Residual-Networks"><a href="#残差网络-ResNets-Residual-Networks" class="headerlink" title="残差网络(ResNets)(Residual Networks)"></a>残差网络(ResNets)(Residual Networks)</h5><p>非常非常深的神经网络是很难训练的，因为存在梯度消失和梯度爆炸问题。这节课我们学习跳跃连接（Skip connection），它可以从某一层网络层获取激活，然后迅速反馈给另外一层，甚至是神经网络的更深层。我们可以利用跳跃连接构建能够训练深度网络的ResNets，有时深度能够超过 100 层。</p>
<p>ResNets 是由残差块（Residual block）构建的，首先我解释一下什么是残差块。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571797414663.png" alt="1571797414663"></p>
<p>我们将a [l] 直接向后，拷贝到神经网络的深层，在 ReLU 非线性激活函数前加上a [l] ，这是一条捷径。a [l] 的信息直接到达神经网络的深层，不再沿着主路径传递。实际上这条捷径是在进行 ReLU非线性激活函数之前加上的，而这里的每一个节点都执行了线性函数和 ReLU 激活函数。除了捷径，你还会听到另一个术语“跳跃连接”，就是指a [l] 跳过一层或者好几层，从而将信息传递到神经网络的更深层。</p>
<p>ResNet 网络就是通过将很多这样的残差块堆积在一起，形成一个很深神经网络，加上所有跳跃连接，正如前一张幻灯片中看到的，每两层增加一个捷径，构成一个残差块。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571798132891.png" alt="1571798132891"></p>
<p>如果我们使用标准优化算法训练一个普通网络，比如说梯度下降法，或者其它热门的优化算法。如果没有残差，没有这些捷径或者跳跃连接，凭经验你会发现随着网络深度的加深，训练错误会先减少，然后增多。而理论上，随着网络深度的加深，应该训练得越来越好才对。也就是说，理论上网络深度越深越好。但实际上，如果没有残差网络，对于一个普通网络来说，深度越深意味着用优化算法越难训练。实际上，随着网络深度的加深，训练错误会越来越多。但有了 ResNets 就不一样了，即使网络再深，训练的表现却不错，比如说训练误差减少，就算是训练深达 100 层的网络也不例外。</p>
<h5 id="残差网络为什么有用"><a href="#残差网络为什么有用" class="headerlink" title="残差网络为什么有用"></a>残差网络为什么有用</h5><p>如何构建更深层次的 ResNets 网络的同时还不降低它们在训练集上的效率。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571799248155.png" alt="1571799248155"></p>
<p>我认为残差网络起作用的主要原因就是这些残差块学习恒等函数非常容易，你能确定网络性能不会受到影响，很多时候甚至可以提高效率，或者说至少不会降低网络的效率，因此创建类似残差网络可以提升网络性能。</p>
<p>之所以能实现跳跃连接是因为 same 卷积保留了维度，所以很容易得出这个捷径连接，并输出这两个相同维度的向量。如果输入和输出有不同维度，比如输入的维度是 128，a [l+2] 的维度是 256,那么，你都需要调整矩阵Ws 的维度。</p>
<h5 id="1×1-卷积"><a href="#1×1-卷积" class="headerlink" title="1×1  卷积"></a>1×1  卷积</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571799678094.png" alt="1571799678094"></p>
<p> 1×1 卷积可以从根本上理解为对这 32 个不同的位置都应用一个全连接层，全连接层的作用是输入 32 个数字，输出结果是 6×6×#filters（过滤器数量），以便在输入层上实施一个非平凡（non-trivial）计算。这种方法通常称为 1×1 卷积，有时也被称为 Network in Network。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571799859519.png" alt="1571799859519"></p>
<p>假设这是一个 28×28×192 的输入层，你可以使用池化层压缩它的高度和宽度，这个过程我们很清楚。但如果通道数量很大，该如何把它压缩为 28×28×32 维度的层呢？你可以用 32个大小为 1×1 的过滤器，严格来讲每个过滤器大小都是 1×1×192 维，因为过滤器中通道数量必须与输入层中通道的数量保持一致。但是你使用了 32 个过滤器，输出层为 28×28×32，这就是压缩通道数（nc）的方法，对于池化层我只是压缩了这些层的高度和宽度。</p>
<h5 id="谷歌-Inception-网络思想"><a href="#谷歌-Inception-网络思想" class="headerlink" title="谷歌 Inception  网络思想"></a>谷歌 Inception  网络思想</h5><p>构建卷积层时，你要决定过滤器的大小究竟是 1×1，3×3 还是 5×5，或者要不要添加池化层。而 Inception 网络的作用就是代替你来决定，虽然网络架构因此变得更加复杂，但网络表现却非常好.</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571800167984.png" alt="1571800167984"></p>
<p>有了这样的 Inception 模块，你就可以输入某个量，因为它累加了所有数字，这里的最终输出为 32+32+128+64=256。Inception 模块的输入为 28×28×192，输出为 28×28×256。基本思想是 Inception 网络不需要人为决定使用哪个过滤器或者是否需要池化，而是由网络自行确定这些参数，你可以给网络添加这些参数的所有可能值，然后把这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些过滤器组合。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571800517344.png" alt="1571800517344"></p>
<p>这是一个 28×28×192 的输入块，执行一个 5×5 卷积，它有 32 个过滤器，输出为 28×28×32。我们来计算这个 28×28×32 输出的计算成本，它有 32 个过滤器，因为输出有 32 个通道，每个过滤器大小为 5×5×192，输出大小为 28×28×32，所以你要计算 28×28×32 个数字。对于输出中的每个数字来说，你都需要执行 5×5×192 次乘法运算，所以乘法运算的总次数为每个输出值所需要执行的乘法运算次数（5×5×192）乘以输出值个数（28×28×32），把这些数相乘结果等于 1.2 亿（120422400）。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571800534680.png" alt="1571800534680"></p>
<p>这里还有另外一种架构，其结果是这样的，对于输入层，使用 1×1 卷积把输入值从 192 个通道减少到 16 个通道。然后对这个较小层运行5×5 卷积，得到最终输出。接下来我们看看这个计算成本，应用 1×1 卷积，过滤器个数为 16，每个过滤器大小为1×1×192，这两个维度相匹配（输入通道数与过滤器通道数），28×28×16 这个层的计算成本是，输出 28×28×192 中每个元素都做 192 次乘法，用 1×1×192 来表示，相乘结果约等于 240万。240 万只是第一个卷积层的计算成本，第二个卷积层的计算成本又是多少呢？这是它的输出，28×28×32，对每个输出值应用一个 5×5×16 维度的过滤器，计算结果为 1000 万。所以所需要乘法运算的总次数是这两层的计算成本之和，也就是 1204 万</p>
<p>如果你在构建神经网络层的时候，不想决定池化层是使用 1×1，3×3 还是 5×5的过滤器，那么 Inception 模块就是最好的选择。我们可以应用各种类型的过滤器，只需要把输出连接起来。之后我们讲到计算成本问题，我们学习了如何通过使用 1×1 卷积来构建瓶颈层，从而大大降低计算成本。</p>
<h5 id="Inception-网络（Inception-network-）"><a href="#Inception-网络（Inception-network-）" class="headerlink" title="Inception  网络（Inception network ）"></a>Inception  网络（Inception network ）</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571800863102.png" alt="1571800863102"></p>
<p>将这些方块全都连接起来。在这过程中，把得到的各个层的通道都加起来，最后得到一个 28×28×256 的输出。通道连接实际就是之前视频中看到过的，把所有方块连接在一起的操作。这就是一个 Inception 模块，而 Inception 网络所做的就是将这些模块都组合到一起。这里有一些额外的最大池化层来修改高和宽的维度。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571801027736.png" alt="1571801027736"></p>
<p>如果你读过论文的原文，你就会发现，这里其实还有一些分支，我现在把它们加上去。所以这些分支有什么用呢？在网络的最后几层，通常称为全连接层，在它之后是一个 softmax 层来做出预测，这些分支所做的就是通过隐藏层来做出预测，所以这其实是一个 softmax 输出。你应该把它看做 Inception 网络的一个细节，它确保了即便是隐藏单元和中间层也参与了特征计算，它们也能预测图片的分类。它在 Inception 网络中，起到一种调整的效果，并且能防止网络发生过拟合。</p>
<h5 id="迁移学习（Transfer-Learning）"><a href="#迁移学习（Transfer-Learning）" class="headerlink" title="迁移学习（Transfer Learning）"></a>迁移学习（Transfer Learning）</h5><p>如果你要做一个计算机视觉的应用，相比于从头训练权重，或者说从随机初始化权重开始，如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。计算机视觉的研究社区非常喜欢把许多数据集上传到网上，如果你听说过，比如 ImageNet，或者 MS COCO，或者 Pascal 类型的数据集，这些都是不同数据集的名字，它们都是由大家上传到网络的，并且有大量的计算机视觉研究者已经用这些数据集训练过他们的算法了。有时候这些训练过程需要花费好几周，并且需要很多的GPU，其它人已经做过了，并且经历了非常痛苦的寻最优过程，这就意味着你可以下载花费了别人好几周甚至几个月而做出来的开源的权重参数，把它当作一个很好的初始化用在你自己的神经网络上。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571801539063.png" alt="1571801539063"></p>
<p>你现在有一个三分类问题，图片里是 Tigger 还是 Misty，或者都不是。现在你可能没有Tigger 或者 Misty 的大量的图片，所以你的训练集会很小，你该怎么办呢？</p>
<p>我建议你从网上下载一些神经网络开源的实现，不仅把代码下载下来，也把权重下载下来。有许多训练好的网络，你都可以下载。你可以去掉这个 Softmax 层，创建你自己的 Softmax 单元，用来输出 Tigger、Misty 和neither 三个类别。就网络而言，我建议你把所有的层看作是冻结的，你冻结网络中所有层的参数，你只需要训练和你的 Softmax 层有关的参数。</p>
<p>另一个技巧，也许对一些情况有用，由于前面的层都冻结了，相当于一个固定的函数，不需要改变。因为你不需要改变它，也不训练它，取输入图像X，然后把它映射到这层（softmax的前一层）的激活函数。所以这个能加速训练的技巧就是，如果我们先计算这一层，计算特征或者激活值，然后把它们存到硬盘里。<br>取任意输入图像X，然后计算它的某个特征向量，这样你训练的就是一个很浅的 softmax 模型，用这个特征向量来做预测。</p>
<p>有很多方式可以实现，你可以取后面几层的权重，用作初始化，然后从这里开始梯度下降。或者你可以直接去掉这几层，换成你自己的隐藏单元和你自己的 softmax 输出层，这些方法值得一试。但是有一个规律，如果你有越来越多的数据，你需要冻结的层数越少，你能够训练的层数就越多。</p>
<p>最后，如果你有大量数据，你应该做的就是用开源的网络和它的权重，把这、所有的权重当作初始化，然后训练整个网络。</p>
<h5 id="数据增强（-Data-augmentation-）"><a href="#数据增强（-Data-augmentation-）" class="headerlink" title="数据增强（ Data augmentation ）"></a>数据增强（ Data augmentation ）</h5><p>大部分的计算机视觉任务使用很多的数据，所以数据增强是经常使用的一种技巧来提高计算机视觉系统的表现。当下在计算机视觉方面，计算机视觉的主要问题是没有办法得到充足的数据。对大多数机器学习应用，这不是问题，但是对计算机视觉，数据就远远不够。</p>
<p>最简单的数据增强方法就是垂直镜像对称；另一个经常使用的技巧是随机裁剪，给定一个数据集，然后开始随机裁剪；理论上，你也可以使用旋转，剪切（shearing：此处并非裁剪的含义，图像仅水平或垂直坐标发生变化）图像，可以对图像进行这样的扭曲变形，引入很多形式的局部弯曲等等。第三种经常使用的方法是彩色转换，有这样一张图片，然后给 R、G 和 B 三个通道上加上不同的失真值。</p>
<h5 id="计算机视觉现状"><a href="#计算机视觉现状" class="headerlink" title="计算机视觉现状"></a>计算机视觉现状</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571811264770.png" alt="1571811264770"></p>
<p>你可以认为大部分机器学习问题是介于少量数据和大量数据范围之间的。举个例子，我认为今天我们有相当数量的语音识别数据，至少相对于这个问题的复杂性而言。虽然现在图像识别或图像分类方面有相当大的数据集，因为图像识别是一个复杂的问题，通过分析像素并识别出它是什么，感觉即使在线数据集非常大，如超过一百万张图片，我们仍然希望我们能有更多的数据。还有一些问题，比如物体检测，我们拥有的数据更少。</p>
<p>当你有很多数据时，人们倾向于使用更简单的算法和更少的手工工程，因为我们不需要为这个问题精心设计特征。当你有大量的数据时，只要有一个大型的神经网络，甚至一个更简单的架构，可以是一个神经网络，就可以去学习它想学习的东西。</p>
<p>当我看机器学习应用时，我们认为通常我们的学习算法有两种知识来源，一个来源是被标记的数据，就像(x ， y)应用在监督学习。第二个知识来源是手工工程，有很多方法去建立一个手工工程系统，它可以是源于精心设计的特征，手工精心设计的网络体系结构或者是系统的其他组件。所以当你没有太多标签数据时，你只需要更多地考虑手工工程。</p>
<p>下面是一些有助于在基准测试中表现出色的小技巧</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571811545828.png" alt="1571811545828"></p>
<p>其中一个是集成，这就意味着在你想好了你想要的神经网络之后，可以独立训练几个神经网络，并平均它们的输出。比如说随机初始化三个、五个或者七个神经网络，然后训练所有这些网络，然后平均它们的输出。</p>
<p>你在论文中可以看到在测试时，对进准测试有帮助的另一个技巧就是 Multi-crop at test time，我的意思是你已经看到了如何进行数据增强，Multi-crop 是一种将数据增强应用到你的测试图像中的一种形式。</p>
<h3 id="目标检测（-Object-detection-）"><a href="#目标检测（-Object-detection-）" class="headerlink" title="目标检测（ Object detection ）"></a>目标检测（ Object detection ）</h3><h5 id="目标定位（Object-localization）"><a href="#目标定位（Object-localization）" class="headerlink" title="目标定位（Object localization）"></a>目标定位（Object localization）</h5><p>图片分类任务我们已经熟悉了，就是算法遍历图片，判断其中的对象是不是汽车，这就是图片分类。这节课我们要学习构建神经网络的另一个问题，即定位分类问题。这意味着，我们不仅要用算法判断图片中是不是一辆汽车，还要在图片中标记出它的位置，用边框或红色方框把汽车圈起来，这就是定位分类问题。其中“定位”的意思是判断汽车在图片中的具体位置。</p>
<p>训练集不仅包含神经网络要预测的对象分类标签，还要包含表示边界框的这四个数字，接着采用监督学习算法，输出一个分类标签，还有四个参数值，从而给出检测对象的边框位置。神经网络多输出几个单元，输出一个边界框。具体说就是让神经网络再多输出 4 个数字，标记为bx,by,bh,bw，这四个数字是被检测对象的边界框的参数化表示。第一个组件Pc 表示是否含有对象，</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571812142263.png" alt="1571812142263"></p>
<p>以上就是利用神经网络解决对象分类和定位问题的详细过程，结果证明，利用神经网络输出批量实数来识别图片中的对象是个非常有用的算法。下节课，我想和大家分享另一种思路，就是把神经网络输出的实数集作为一个回归任务，这个思想也被应用于计算机视觉的其它领域，也是非常有效的。</p>
<h5 id="特征点检测（Landmark-detection）"><a href="#特征点检测（Landmark-detection）" class="headerlink" title="特征点检测（Landmark detection）"></a>特征点检测（Landmark detection）</h5><p>神经网络可以通过输出图片上特征点的(x,y)坐标来实现对目标特征的识别，假设你正在构建一个人脸识别应用，出于某种原因，你希望算法可以给出眼角的具体位置。眼角坐标为(x,y)，你可以让神经网络的最后一层多输出两个数字lx 和ly ，作为眼角的坐标值。如果你想知道两只眼睛的四个眼角的具体位置，那么从左到右，依次用四个特征点来表示这四个眼角。</p>
<p>也许除了这四个特征点，你还想得到更多的特征点输出值，这些（图中眼眶上的红色特征点）都是眼睛的特征点，你还可以根据嘴部的关键点输出值来确定嘴的形状，从而判断人物是在微笑还是皱眉，也可以提取鼻子周围的关键特征点。为了便于说明，你可以设定特征点的个数，假设脸部有 64 个特征点，有些点甚至可以帮助你定义脸部轮廓或下颌轮廓。选定特征点个数，并生成包含这些特征点的标签训练集，然后利用神经网络输出脸部关键特征点的位置。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571812561045.png" alt="1571812561045"></p>
<p>最后一个例子，如果你对人体姿态检测感兴趣，你还可以定义一些关键特征点，如胸部的中点，左肩，左肘，腰等等。然后通过神经网络标注人物姿态的关键特征点，再输出这些标注过的特征点，就相当于输出了人物的姿态动作。</p>
<h5 id="目标检测（Object-detection"><a href="#目标检测（Object-detection" class="headerlink" title="目标检测（Object detection)"></a>目标检测（Object detection)</h5><p>学过了对象定位和特征点检测，今天我们来构建一个对象检测算法。这节课，我们将学习如何通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571812860011.png" alt="1571812860011"></p>
<p>假如你想构建一个汽车检测算法，步骤是，首先创建一个标签训练集，也就是x和y表示适当剪切的汽车图片样本，这张图片（编号 1）x是一个正样本，因为它是一辆汽车图片，这几张图片（编号 2、3）也有汽车，但这两张（编号 4、5）没有汽车。剪切出一些图片并打标签，有了这个标签训练集，你就可以开始训练卷积网络了,输入这些适当剪切过的图片（编号 6），卷积网络输出y，0 或 1 表示图片中有汽车或没有汽车。训练完这个卷积网络，就可以用它来实现滑动窗口目标检测，具体步骤如下。</p>
<p>假设这是一张测试图片，首先选定一个特定大小的窗口，比如图片下方这个窗口，将这个红色小方块输入卷积神经网络，卷积网络开始进行预测，即判断红色方框内有没有汽车。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571813038555.png" alt="1571813038555"></p>
<p>滑动窗口目标检测算法接下来会继续处理第二个图像，即红色方框稍向右滑动之后的区域，并输入给卷积网络，因此输入给卷积网络的只有红色方框内的区域，再次运行卷积网络，然后处理第三个图像，依次重复操作，直到这个窗口滑过图像的每一个角落。</p>
<p>重复上述操作，不过这次我们选择一个更大的窗口，截取更大的区域，并输入给卷积神经网络处理，你可以根据卷积网络对输入大小调整这个区域，然后输入给卷积网络，输出 0或 1。再以某个固定步幅滑动窗口，重复以上操作，遍历整个图像，输出结果。</p>
<p>然后第三次重复操作，这次选用更大的窗口。如果你这样做，不论汽车在图片的什么位置，总有一个窗口可以检测到它。</p>
<p>滑动窗口目标检测算法也有很明显的缺点，就是计算成本，因为你在图片中剪切出太多小方块，卷积网络要一个个地处理。如果你选用的步幅很大，显然会减少输入卷积网络的窗口个数，但是粗糙间隔尺寸可能会影响性能。反之，如果采用小粒度或小步幅，传递给卷积网络的小窗口会特别多，这意味着超高的计算成本。</p>
<h5 id="滑动窗口的卷积实现"><a href="#滑动窗口的卷积实现" class="headerlink" title="滑动窗口的卷积实现"></a>滑动窗口的卷积实现</h5><p>上节课，我们学习了如何通过卷积网络实现滑动窗口对象检测算法，但效率很低。这节课我们讲讲如何在卷积层上应用这个算法。</p>
<p>首先要知道如何把神经网络的全连接层转化成卷积层。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627162412790.png" alt="image-20200627162412790"></p>
<p>画一个这样的卷积网络，它的前几层和之前的一样，而对于下一层，也就是这个全连接层，我们可以用 5×5 的过滤器来实现，数量是 400 个，输入图像大小为 5×5×16，用 5×5 的过滤器对它进行卷<br>积操作，过滤器实际上是 5×5×16，因为在卷积过程中，过滤器会遍历这 16 个通道，所以这两处的通道数量必须保持一致，输出结果为 1×1。假设应用 400 个这样的 5×5×16 过滤器，输出维度就是 1×1×400，我们不再把它看作一个含有 400 个节点的集合，而是一个 1×1×400的输出层。从数学角度看，它和全连接层是一样的，因为这 400 个节点中每个节点都有一个5×5×16 维度的过滤器，所以每个值都是上一层这些 5×5×16 激活值经过某个任意线性函数的输出结果。</p>
<p>掌握了卷积知识，我们再看看如何通过卷积实现滑动窗口对象检测算法。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627162444224.png" alt="image-20200627162444224"></p>
<p>假设输入给卷积网络的图片大小是 14×14×3，测试集图片是 16×16×3，现在给这个输入图片加上黄色条块，在最初的滑动窗口算法中，你会把这片蓝色区域输入卷积网络（红色笔标记）生成 0 或 1 分类。接着滑动窗口，步幅为 2 个像素，向右滑动 2 个像素，将这个绿框区域输入给卷积网络，运行整个卷积网络，得到另外一个标签 0 或 1。继续将这个橘色区域输入给卷积网络，卷积后得到另一个标签，最后对右下方的紫色区域进行最后一次卷积操作。我们在这个 16×16×3 的小图像上滑动窗口，卷积网络运行了 4 次，于是输出了了 4 个标签。</p>
<p>结果发现，这 4 次卷积操作中很多计算都是重复的。所以执行滑动窗口的卷积时使得卷积网络在这 4 次前向传播过程中共享很多计算.最终，在输出层这 4 个子方块中，蓝色的是图像左上部分14×14 的输出（红色箭头标识），右上角方块是图像右上部分（绿色箭头标识）的对应输出，左下角方块是输入层左下角（橘色箭头标识），也就是这个 14×14 区域经过卷积网络处理后的结果，同样，右下角这个方块是卷积网络处理输入层右下角 14×14 区域(紫色箭头标识)的结果。</p>
<p>所以该卷积操作的原理是我们不需要把输入图像分割成四个子集，分别执行前向传播，而是把它们作为一张图片输入给卷积网络进行计算，其中的公共区域可以共享很多计算，就像这里我们看到的这个 4 个 14×14 的方块一样。</p>
<p>以上就是在卷积层上应用滑动窗口算法的内容，它提高了整个算法的效率。不过这种算法仍然存在一个缺点，就是边界框的位置可能不够准确。</p>
<h5 id="Bounding-Box-预测（Bounding-box-predictions-）"><a href="#Bounding-Box-预测（Bounding-box-predictions-）" class="headerlink" title="Bounding Box  预测（Bounding box predictions ）"></a>Bounding Box  预测（Bounding box predictions ）</h5><p>最完美的边界框甚至不是方形，稍微有点长方形（红色方框所示），长宽比有点向水平方向延伸，有没有办法让这个算法输出更精准的边界框呢？</p>
<p>其中一个能得到更精准边界框的算法是 YOLO 算法，YOLO(You only look once)意思是你只看一次</p>
<p>是这么做的，比如你的输入图像是 100×100 的，然后在图像上放一个网格。为了介绍起来简单一些，我用 3×3 网格，实际实现时会用更精细的网格，可能是 19×19。基本思路是使用图像分类和定位算法，前几个视频介绍过的，然后将算法应用到 9 个格子上。（基本思路是，采用图像分类和定位算法，本周第一个视频中介绍过的，逐一应用在图像的 9 个格子中。）更具体一点，你需要这样定义训练标签，所以对于 9 个格子中的每一个指定一个标签y，y是 8 维的.pc 等于 0 或 1 取决于这个绿色格子中是否有图像。然后bx,by,bh,bw作用就是，如果那个格子里有对象，那么就给出边界框坐标。c1,c2,c2表示具体要识别的类别。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627164619019.png" alt="image-20200627164619019"></p>
<p>你怎么指定这个边界框呢？</p>
<p>我们约定左上这个点是(0,0)，然后右下这个点是(1,1) ,要指定橙色中点的位置，bx 大概是 0.4，因为它的位置大概是水平长度的0.4，然后by大概是 0.3，然后边界框的高度用格子总体宽度的比例表示，所以这个红框的宽度可能是蓝线的 90%，所以bh 是 0.9，它的高度也许是格子总体高度的一半，这样的话bw就是 0.5。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627164952279.png" alt="image-20200627164952279"></p>
<h5 id="交并比（Intersection-over-union）"><a href="#交并比（Intersection-over-union）" class="headerlink" title="交并比（Intersection over union）"></a>交并比（Intersection over union）</h5><p>你如何判断对象检测算法运作良好呢？在本视频中，你将了解到并交比函数。交并比（loU）函数做的是计算两个边界框交集和并集之比。一般约定，在计算机检测任务中，如果IoU ≥ 0.5，就说检测正确，如果预测器和实际边界框完美重叠，loU 就是 1.0.5 是人为约定，没有特别深的理论依据，如果你想更严格一点，可以把阈值定为 0.6。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627165703471.png" alt="image-20200627165703471"></p>
<h5 id="非极大值抑制（Non-max-suppression-）"><a href="#非极大值抑制（Non-max-suppression-）" class="headerlink" title="非极大值抑制（Non-max suppression ）"></a>非极大值抑制（Non-max suppression ）</h5><p>到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。非极大值抑制这个方法可以确保你的算法对每个对象只检测一次，我们讲一个例子。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627170635526.png" alt="image-20200627170635526"></p>
<p>实践中当你运行对象分类和定位算法时，对于每个格子都运行一次，所以这个格子（编号 1）可能会认为这辆车中点应该在格子内部，这几个格子（编号 2、3）也会这么认为。对于左边的车子也一样.</p>
<p>我们分步介绍一下非极大抑制是怎么起效的，因为你要在 361 个格子上都运行一次图像检测和定位算法，那么可能很多格子都会举手说我的pc ，我这个格子里有车的概率很高，而不是 361 个格子中仅有两个格子会报告它们检测出一个对象。</p>
<p>所以当你运行算法的时候，最后可能会对同一个对象做出多次检测，所以非极大值抑制做的就是清理这些检测结果。这样一辆车只检测一次，而不是每辆车都触发多次检测。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627170920900.png" alt="image-20200627170920900"></p>
<p>首先看pc概率最大的那个，这个例子（右边车辆）中是 0.9，然后就说这是最可靠的检测，所以我们就用高亮标记，就说我这里找到了一辆车。这么做之后，非极大值抑制就会逐一审视剩下的矩形，所有和这个最大的边框有很高交并比，高度重叠的其他边界框，那么这些输出就会被抑制。所以这两个矩形pc 分别是 0.6 和 0.7，这两个矩形和淡蓝色矩形重叠程度很高，所以会被抑制，变暗，表示它们被抑制了.</p>
<h5 id="Anchor-Boxes"><a href="#Anchor-Boxes" class="headerlink" title="Anchor Boxes"></a>Anchor Boxes</h5><p>到目前为止，对象检测中存在的一个问题是每个格子只能检测出一个对象，如果你想让一个格子检测出多个对象，你可以这么做，就是使用 anchor box 这个概念，我们从一个例子开始讲吧。</p>
<p>假设你有这样一张图片，对于这个例子，我们继续使用 3×3 网格，注意行人的中点和汽车的中点几乎在同一个地方，两者都落入到同一个格子中。它将无法输出检测结果，所以我必须从两个检测结果中选一个。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627172242335.png" alt="image-20200627172242335"></p>
<p>而 anchor box 的思路是，这样子，预先定义两个不同形状的 anchor box，或者 anchor box 形状，你要做的是把预测结果和这两个 anchor box 关联起来。一般来说，你可能会用更多的 anchor box，可能要 5 个甚至更多，但对于这个视频，我们就用两个 anchor box，这样介绍起来简单一些。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627172448107.png" alt="image-20200627172448107"></p>
<p>现在用到 anchor box 这个概念，是这么做的。现在每个对象都和之前一样分配到同一个格子中，分配到对象中点所在的格子中，以及分配到和对象形状交并比最高的 anchor box中。所以这里有两个 anchor box，你就取这个对象，如果你的对象形状是这样的（编号 1，红色框），你就看看这两个 anchor box，anchor box 1 形状是这样（编号 2，紫色框），anchorbox 2 形状是这样（编号 3，紫色框），然后你观察哪一个 anchor box 和实际边界框（编号1，红色框）的交并比更高，不管选的是哪一个，这个对象不只分配到一个格子，而是分配到一对，即（grid cell ，anchor box）对，这就是对象在目标标签中的编码方式。所以现在输出 y就是 3×3×16，行人更类似于 anchor box 1 的形状，所以对于行人来说，我们将她分配到向量的上半部分。</p>
<p>现在还有一些额外的细节，如果你有两个 anchor box，但在同一个格子中有三个对象，这种情况算法处理不好，你希望这种情况不会发生，但如果真的发生了，这个算法并没有很好的处理办法，对于这种情况，我们就引入一些打破僵局的默认手段。还有这种情况，两个对象都分配到一个格子中，而且它们的 anchor box 形状也一样，这是算法处理不好的另一种情况，你需要引入一些打破僵局的默认手段，专门处理这种情况，希望你的数据集里不会出现这种情况，其实出现的情况不多，所以对性能的影响应该不会很大。</p>
<h5 id="YOLO-算法（YOLO-algorithm-）"><a href="#YOLO-算法（YOLO-algorithm-）" class="headerlink" title="YOLO  算法（YOLO algorithm ）"></a>YOLO  算法（YOLO algorithm ）</h5><p>你们已经学到对象检测算法的大部分组件了，在这个视频里，我们会把所有组件组装在一起构成 YOLO 对象检测算法。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627173818473.png" alt="image-20200627173818473"></p>
<p>我们先看看如何构造你的训练集，假设你要训练一个算法去检测三种对象，行人、汽车和摩托车，你还需要显式指定完整的背景类别。这里有 3 个类别标签，如果你要用两个 anchor box，那么输出 y就是 3×3×2×8，其中 3×3 表示 3×3 个网格，2 是 anchor box 的数量，你需要遍历 9 个格子，然后构成对应的目标向量y。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627174032970.png" alt="image-20200627174032970"></p>
<p>最后你要运行一下这个非极大值抑制，为了让内容更有趣一些，我们看看一张新的测试图像，这就是运行非极大值抑制的过程。如果你使用两个 anchor box，那么对于 9 个格子中任何一个都会有两个预测的边界框，其中一个的概率pc很低。但 9 个格子中，每个都有两个预测的边界框，比如说我们得到的边界框是是这样的，注意有一些边界框可以超出所在格子的高度和宽度（编号 1 所示）。接下来你抛弃概率很低的预测，去掉这些连神经网络都说，这里很可能什么都没有，所以你需要抛弃这些（编号 2 所示）</p>
<p>最后，如果你有三个对象检测类别，你希望检测行人，汽车和摩托车，那么你要做的是，对于每个类别单独运行非极大值抑制，处理预测结果所属类别的边界框，用非极大值抑制来处理行人类别，用非极大值抑制处理车子类别，然后对摩托车类别进行非极大值抑制，运行三次来得到最终的预测结果。</p>
<h5 id="候选区域（Region-proposals）"><a href="#候选区域（Region-proposals）" class="headerlink" title="候选区域（Region proposals）"></a>候选区域（Region proposals）</h5><p> R-CNN 的算法，意思是带区域的卷积网络，或者说带区域的 CNN。这个算法尝试选出一些区域，在这些区域上运行卷积网络分类器是有意义的，所以这里不再针对每个滑动窗运行检测算法，而是只选择一些窗口，在少数窗口上运行卷积网络分类器。</p>
<p>选出候选区域的方法是运行图像分割算法，分割的结果是下边的图像，为了找出可能存在对象的区域。比如说，分割算法在这里得到一个色块，所以你可能会选择这样的边界框（编号 1），然后在这个色块上运行分类器，就像这个绿色的东西（编号 2），在这里找到一个色块，接下来我们还会在那个矩形上（编号 2）运行一次分类器，看看有没有东西。在这种情况下，如果在蓝色色块上（编号 3）运行分类器，希望你能检测出一个行人，如果你在青色色块(编号 4)上运行算法，也许你可以发现一辆车，我也不确定。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627174948200.png" alt="image-20200627174948200"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627175024164.png" alt="image-20200627175024164"></p>
<h4 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h4><p>在人脸识别的相关文献中，人们经常提到人脸验证（face verification）和人脸识别（face recognition）</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200627175855057.png" alt="image-20200627175855057"></p>
<p>如果你有一张输入图片，以及某人的 ID 或者是名字，人脸验证系统要做的是，验证输入图片是否是这个人。有时候也被称作 1 对 1 问题，只需要弄明白这个人是否和他声称的身份相符。<br>人脸识别问题比人脸验证问题难很多（整理者注：1 对多问题（1:K））</p>
<p>假设你有一个验证系统，准确率是 99%，还可以。但是现在，假设在识别系统中，K= 100，如果你把这个验证系统应用在 100 个人身上，人脸识别上，你犯错的机会就是 100 倍了。如果每个人犯错的概率是 1%，如果你有一个上百人的数据库，如果你想得到一个可接受的识别误差，你要构造一个验证系统，其准确率为 99.9%或者更高,才能保证有很大几率不出错。</p>
<h5 id="One-Shot-学习（One-shot-learning-）"><a href="#One-Shot-学习（One-shot-learning-）" class="headerlink" title="One-Shot  学习（One-shot learning ）"></a>One-Shot  学习（One-shot learning ）</h5><p>人脸识别所面临的一个挑战就是你需要解决一次学习问题，这意味着在大多数人脸识别应用中，你需要通过单单一张图片或者单单一个人脸样例就能去识别这个人。而历史上，当深度学习只有一个训练样例时，它的表现并不好。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628114628225.png" alt="image-20200628114628225"></p>
<p>所以要让人脸识别能够做到一次学习，为了能有更好的效果，你现在要做的应该是学习Similarity 函数。详细地说，你想要神经网络学习这样一个用d表示的函数，它以两张图片作为输入，然后输出这两张图片的差异值。</p>
<p>要将它应用于识别任务，你要做的是拿这张新图片（编号 6），然后用d函数去比较这两张图片（编号 1 和编号 6），这样可能会输出一个非常大的数字，在该例中，比如说这个数字是 10。之后你再让它和数据库中第二张图（编号 2）片比较，因为这两张照片是同一个人，所以我们希望会输出一个很小的数。然后你再用它与数据库中的其他图片（编号 3、4）进行比较，通过这样的计算，最终你能够知道，这个人确实是 Danielle。</p>
<h5 id="Siamese-网络（Siamese-network"><a href="#Siamese-网络（Siamese-network" class="headerlink" title="Siamese  网络（Siamese network)"></a>Siamese  网络（Siamese network)</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628114827154.png" alt="image-20200628114827154"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628114934803.png" alt="image-20200628114934803"></p>
<h5 id="Triplet-损失"><a href="#Triplet-损失" class="headerlink" title="Triplet  损失"></a>Triplet  损失</h5><p>要想通过学习神经网络的参数来得到优质的人脸图片编码，方法之一就是定义三元组损失函数然后应用梯度下降。</p>
<p>这就是为什么叫做三元组损失，它代表你通常会同时看三张图片，你需要看 Anchor 图片、Postive 图片，还有 Negative 图片</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628115218616.png" alt="image-20200628115218616"></p>
<h5 id="人脸验证与二分类（-Face-verification-and-binary-classification"><a href="#人脸验证与二分类（-Face-verification-and-binary-classification" class="headerlink" title="人脸验证与二分类（ Face verification and binary classification)"></a>人脸验证与二分类（ Face verification and binary classification)</h5><p>Triplet loss 是一个学习人脸识别卷积网络参数的好方法，还有其他学习参数的方法，让我们看看如何将人脸识别当成一个二分类问题。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628115602408.png" alt="image-20200628115602408"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628115553752.png" alt="image-20200628115553752"></p>
<p>输入是一对图片，这是你的训练输入x（编号 1、2），输出y是 0 或者 1，取决于你的输入是相似图片还是非相似图片。与之前类似，你正在训练一个Siamese 网络，意味着上面这个神经网络拥有的参数和下面神经网络的相同（编号 3 和 4 所示的网络），两组参数是绑定的，这样的系统效果很好。</p>
<p>不需要存储原始图像，如果你有一个很大的员工数据库，你不需要为每个员工每次都计算这些编码。这个预先计算的思想，可以节省大量的计算.</p>
<h4 id="神经风格迁移"><a href="#神经风格迁移" class="headerlink" title="神经风格迁移"></a>神经风格迁移</h4><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628115813846.png" alt="image-20200628115813846"></p>
<h5 id="深度卷积网络-学习什么（What-are-deep-ConvNetslearning-）"><a href="#深度卷积网络-学习什么（What-are-deep-ConvNetslearning-）" class="headerlink" title="深度卷积网络 学习什么（What are deep ConvNetslearning ）"></a>深度卷积网络 学习什么（What are deep ConvNetslearning ）</h5><p>来看一个例子，假如你训练了一个卷积神经网络，是一个 Alexnet，轻量级网络，你希望将看到不同层之间隐藏单元的计算结果。</p>
<p>从第一层的隐藏单元开始，假设你遍历了训练集，然后找到那些使得单元激活最大化的一些图片，或者是图片块。换句话说，将你的训练集经过神经网络，然后弄明白哪一张图片最大限度地激活特定的单元。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628120050843.png" alt="image-20200628120050843"></p>
<p>第一层，你能在输入图片的区域看到，大概是这个角度的边缘,第二层似乎检测到更复杂的形状和模式，比如说这个隐藏单元（编号 1），它会找到有很多垂线的垂直图案.第三层明显，检测到更复杂的模式。似乎开始检测到人类，有的似乎检测特定的图案，蜂窝形状或者方形。第四层，检测到的模式和特征更加复杂，有的学习成了一个狗的检测器。</p>
<h5 id="代价函数（Cost-function-）"><a href="#代价函数（Cost-function-）" class="headerlink" title="代价函数（Cost function ）"></a>代价函数（Cost function ）</h5><p>记住我们的问题，给你一个内容图像C，给定一个风格图片S，而你的目标是生成一个新图片G。为了实现神经风格迁移，你要做的是定义一个关于G的代价函数J用来评判某个生成图像的好坏，我们将使用梯度下降法去最小化J(G)，以便于生成这个图像。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628120539066.png" alt="image-20200628120539066"></p>
<h5 id="内容代价函数（Content-cost-function-）"><a href="#内容代价函数（Content-cost-function-）" class="headerlink" title="内容代价函数（Content cost function ）"></a>内容代价函数（Content cost function ）</h5><p>通常l会选择在网络的中间层，既不太浅也不很深，然后用一个预训练的卷积模型，可以是 VGG  网络或者其他的网络也可以。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628120909998.png" alt="image-20200628120909998"></p>
<h5 id="风格代价函数（Style-cost-function-）"><a href="#风格代价函数（Style-cost-function-）" class="headerlink" title="风格代价函数（Style cost function ）"></a>风格代价函数（Style cost function ）</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628121209972.png" alt="image-20200628121209972"></p>
<p>相关系数这个概念为你提供了一种去测量这些不同的特征的方法，比如这些垂直纹理，这些橙色或是其他的特征去测量它们在图片中的各个位置同时出现或不同时出现的频率。</p>
<p>如果我们在通道之间使用相关系数来描述通道的风格，你能做的就是测量你的生成图像中第一个通道（编号 1）是否与第二个通道（编号 2）相关，通过测量，你能得知在生成的图像中垂直纹理和橙色同时出现或者不同时出现的频率，这样你将能够测量生成的图像的风格与输入的风格图像的相似程度。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628121357739.png" alt="image-20200628121357739"></p>
<p>这就是输入的风格图像所构成的风格矩阵，然后，我们再对生成图像做同样的操作。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628121619706.png" alt="image-20200628121619706"></p>
<h5 id="一维到三维推广（1D-and-3D-generalizations-of-models）"><a href="#一维到三维推广（1D-and-3D-generalizations-of-models）" class="headerlink" title="一维到三维推广（1D and 3D generalizations of models）"></a>一维到三维推广（1D and 3D generalizations of models）</h5><p>即使我们大部分讨论的图像数据，某种意义上而言都是 2D 数据，考虑到图像如此普遍，许多你所掌握的思想不仅局限于 2D 图像，甚至可以延伸至 1D，乃至 3D 数据。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628122552856.png" alt="image-20200628122552856"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20200628122658022.png" alt="image-20200628122658022"></p>
<h3 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h3><h5 id="为什么选择序列模型？"><a href="#为什么选择序列模型？" class="headerlink" title="为什么选择序列模型？"></a>为什么选择序列模型？</h5><p>我们先看一些例子，这些例子都有效使用了序列模型。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571036986094.png" alt="1571036986094"></p>
<p>所以这些问题都可以被称作使用标签数据 (x,y)作为训练集的监督学习。但从这一系列例子中你可以看出序列问题有很多不同类型。有些问题里，输入数据 x和输出数据y都是序列，但就算在那种情况下，x和y有时也会不一样长。或者像上图编号 1 所示和上图编号 2 的x和y有相同的数据长度。在另一些问题里，只有 x或者只有y是序列。</p>
<h5 id="序列模型数学符号"><a href="#序列模型数学符号" class="headerlink" title="序列模型数学符号"></a>序列模型数学符号</h5><p>命名实体识别系统可以用来查找不同类型的文本中的人名、公司名、时间、地点、国家名和货币名等等。现在给定这样的输入数据x，假如你想要一个序列模型输出y，使得输入的每个单词都对应一个输出值，同时这个y能够表明输入的单词是否是人名的一部分。技术上来说这也许不是最好的输出形式，还有更加复杂的输出形式，它不仅能够表明输入词是否是人名的一部分，它还能够告诉你这个人名在这个句子里从哪里开始到哪里结束。</p>
<p>用x \<t> 来索引这个序列的中间位置。t意味着它们是时序序列，但不论是否是时序序列，我们都将用t来索引序列中的位置。同时我们用T x 来表示输入序列的长度,用T y来表示输出序列的长度.</t></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571037457563.png" alt="1571037457563"></p>
<p>如果你遇到了一个不在你词表中的单词，答案就是创建一个新的标记，也就是一个叫做 Unknow Word 的伪单词，用\<unk>作为标记，来表示不在词表中的单词.</unk></p>
<h5 id="循环神经网络模型（Recurrent-Neural-Network-Model"><a href="#循环神经网络模型（Recurrent-Neural-Network-Model" class="headerlink" title="循环神经网络模型（Recurrent Neural Network Model)"></a>循环神经网络模型（Recurrent Neural Network Model)</h5><p>现在我们讨论一下怎样才能建立一个模型，建立一个神经网络来学习X到Y的映射。</p>
<p>传统标准网络这个方法并不好，主要有两个问题：一、是输入和输出数据在不同例子中可以有不同的长度；二、一个像这样单纯的神经网络结构，它并不共享从文本的不同位置上学到的特征。具体来说，如果神经网络已经学习到了在位置 1 出现的 Harry 可能是人名的一部分，那么如果Harry 出现在其他位置，比如x\<t> 时，它也能够自动识别其为人名的一部分的话，这就很棒了。再次，输入是 10,000 维的 one-hot 向量，那么第一层的权重矩阵就会有着巨量的参数。</t></p>
<p>那么什么是循环神经网络呢？在每一个时间步中，循环神经网络传递一个激活值到下一个时间步中用于计算。如果你在教材中或是研究论文中看到了右边这种图表的画法（上图编号 2 所示），它可以在心中将这图展开成左图那样。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571037926023.png" alt="1571037926023"></p>
<p>这个循环神经网络的一个缺点就是它只使用了这个序列中之前的信息来做出预测，并没有使用序列中后部分的信息，如果给定了这个句子，“Teddy Roosevelt was a great President.”，为了判断 Teddy是否是人名的一部分，仅仅知道句中前两个词是完全不够的，还需要知道句中后部分的信息，这也是十分有用的。我们会在之后的双向循环神经网络（BRNN）的视频中处理这个问题。</p>
<p>用W ax 来表示管理着从x <1> 到隐藏层的连接的一系列参数，每个时间步使用的都是相同的参数W ax 。而激活值也就是水平联系是由参数W aa 决定的，同时每一个时间步都使用相同的参数W aa，同样的输出结果由W ya 决定.</1></p>
<p>这里是一张清理后的神经网络示意图，和我之前提及的一样，一般开始先输入a <0> ，它是一个零向量。接着就是前向传播过程，先计算激活值a <1> ，然后再计算y<1> 。</1></1></0></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571038257737.png" alt="1571038257737"></p>
<p>循环神经网络用的激活函数经常是 tanh，不过有时候也会用 ReLU，但是 tanh 是更通常的选择，我们有其他方法来避免梯度消失问题。选用哪个激活函数是取决于你的输出y，如果它是一个二分问题，那么会用 sigmoid 函数作为激活函数，如果是k类别分类问题的话，那么可以选用 softmax 作为激活函数。</p>
<p>为了帮我们建立更复杂的神经网络，我实际要将这个符号简化一下</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571038816029.png" alt="1571038816029"></p>
<h5 id="RNN的反向传播"><a href="#RNN的反向传播" class="headerlink" title="RNN的反向传播"></a>RNN的反向传播</h5><p>我们将来了解反向传播是怎样在循环神经网络中运行的。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571038997134.png" alt="1571038997134"></p>
<p>这就是完整的计算图，在之前的例子中，你已经见过反向传播，所以你应该能够想得到反向传播算法需要在相反的方向上进行计算和传递信息，最终你做的就是把前向传播的箭头都反过来，在这之后你就可以计算出所有合适的量，然后你就可以通过导数相关的参数，用梯度下降法来更新参数。</p>
<p>RNN 反向传播示意图：</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571039183004.png" alt="1571039183004"></p>
<h5 id="不同类型的循环神经网络"><a href="#不同类型的循环神经网络" class="headerlink" title="不同类型的循环神经网络"></a>不同类型的循环神经网络</h5><p>现在你已经了解了一种 RNN 结构，它的输入量Tx 等于输出数量Ty 。事实上，对于其他一些应用，Tx  和Ty  并不一定相等。在这个视频里，你会看到更多的 RNN 的结构。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571039446169.png" alt="1571039446169"></p>
<p>一对一：图片分类；一对多：音乐生成；多对一：文本情感分类；多对多：实体识别，机器翻译。</p>
<h5 id="语言模型和序列生成"><a href="#语言模型和序列生成" class="headerlink" title="语言模型和序列生成"></a>语言模型和序列生成</h5><p>在自然语言处理中，构建语言模型是最基础的也是最重要的工作之一，并且能用 RNN很好地实现，你将学习用 RNN 构建一个语言模型。</p>
<p>语言模型所做的就是，它会告诉你某个特定的句子它出现的概率是多少。对于语言模型来说，用来表示这些序列比用x来表示要更好，然后语言模型会估计某个句子序列中各个单词出现的可能性。</p>
<p>那么如何建立一个语言模型呢？为了使用 RNN 建立出这样的模型，你首先需要一个训练集，包含一个很大的英文文本语料库（corpus）或者其它的语言，你想用于构建模型的语言的语料库。语料库是自然语言处理的一个专有名词，意思就是很长的或者说数量众多的英文句子组成的文本。</p>
<p>如果你的训练集中有一些词并不在你的字典里，你可以把不在你的字典的词 Mau 替换成一个叫做 UNK 的代表未知词的标志，我们只针对 UNK 建立概率模型，而不是针对这个具体的词 Mau。</p>
<p>完成标识化的过程后，这意味着输入的句子都映射到了各个标志上，或者说字典中的各个词上。下一步我们要构建一个 RNN 来构建这些序列的概率模型。在下一张幻灯片中会看到的一件事就是最后你会将x \<t> 设为y &lt;t−1&gt;</t></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571040629276.png" alt="1571040629276"></p>
<p>y^ <1> 的输出是 softmax 的计算结果，它只是预测第一个词的概率，而不去管结果是什么。在我们的例子中，最终会得到单词Cats。然后 RNN 进入下个时间步，在下一时间步中，仍然使用激活项a <1> ，在这步要做的是计算出第二个词会是什么。现在我们依然传给它正确的第一个词，我们会告诉它第一个词就是 Cats，然后在第二个时间步中，输出结果同样经过 softmax 层进行预测，RNN 的职责就是预测这些词的概率（上图编号 3 所示），以此类推，一直到最后。</1></1></p>
<h5 id="对新序列采样（Sampling-novel-sequences-）"><a href="#对新序列采样（Sampling-novel-sequences-）" class="headerlink" title="对新序列采样（Sampling novel sequences ）"></a>对新序列采样（Sampling novel sequences ）</h5><p>在你训练一个序列模型之后，要想了解到这个模型学到了什么，一种非正式的方法就是进行一次新序列采样，从你的 RNN 语言模型中生成一个随机选择的句子。记住一个序列模型模拟了任意特定单词序列的概率，我们要做的就是对这些概率分布进行采样来生成一个新的单词序列，和原文本有相似的文本风格，如莎士比亚文风，新闻文风等。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571041723310.png" alt="1571041723310"></p>
<p>那么你要怎样知道一个句子结束了呢？方法之一就是，如果代表句子结尾的标识在你的字典中，你可以一直进行采样直到得到 EOS 标识（上图编号 6 所示），这代表着已经抵达结尾，可以停止采样了。另一种情况是，如果你的字典中没有这个词，你可以决定从 20 个或100 个或其他个单词进行采样，然后一直将采样进行下去直到达到所设定的时间步。</p>
<p>根据你实际的应用，你还可以构建一个基于字符的 RNN 结构，在这种情况下，你的字典仅包含从 a 到 z 的字母，可能还会有空格符，如果你需要的话，还可以有数字 0 到 9。优点就是你不必担心会出现未知的标识，例如基于字符的语言模型会将 Mau 这样的序列也视为可能性非零的序列。不过基于字符的语言模型一个主要缺点就是你最后会得到太多太长的序列，大多数英语句子只有 10 到 20 个的单词，但却可能包含很多很多字符。并且基于字符的语言模型训练起来计算成本比较高昂。</p>
<h5 id="循环神经网络的梯度消失（Vanishing-gradients-with-RNNs）"><a href="#循环神经网络的梯度消失（Vanishing-gradients-with-RNNs）" class="headerlink" title="循环神经网络的梯度消失（Vanishing gradients with RNNs）"></a>循环神经网络的梯度消失（Vanishing gradients with RNNs）</h5><p>你已经了解了 RNN 时如何工作的了，并且知道如何应用到具体问题上，比如命名实体识别，比如语言模型，你也看到了怎么把反向传播用于 RNN。其实，基本的 RNN 算法还有一个很大的问题，就是梯度消失的问题。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571042446861.png" alt="1571042446861"></p>
<p>这个例子中的句子有长期的依赖，最前面的单词单复数对句子后面的单词（was,were)有影响。但是我们目前见到的基本的 RNN 模型（上图编号 3 所示的网络模型），不擅长捕获这种长期依赖效应。</p>
<p>你应该还记得之前讨论的训练很深的网络，我们讨论了梯度消失的问题。比如说一个很深很深的网络（上图编号 4 所示），100 层，甚至更深，对这个网络从左到右做前向传播然后再反向传播。我们知道如果这是个很深的神经网络，从输出y^ 得到的梯度很难传播回去，很难影响靠前层的权重，很难影响前面层（编号 5 所示的层）的计算。</p>
<p>对于有同样问题的 RNN，首先从左到右前向传播，然后反向传播。但是反向传播会很困难，因为同样的梯度消失的问题，后面层的输出误差（上图编号 6 所示）很难影响前面层（上图编号 7 所示的层）的计算。上图编号 11 所示的一个数值主要与附近的输入（上图编号 12 所示）有关，上图编号 6 所示的输出，基本上很难受到序列靠前的输入（上图编号 10 所示）的影响.</p>
<p>尽管我们一直在讨论梯度消失问题，但是，你应该记得我们在讲很深的神经网络时，我们也提到了梯度爆炸，我们在反向传播的时候，随着层数的增多，梯度不仅可能指数型的下降，也可能指数型的上升。梯度爆炸很容易发现，因为参数会大到崩溃，你会看到很多 NaN，或者不是数字的情况，这意味着你的网络计算出现了数值溢出。如果你发现了梯度爆炸的问题，一个解决方法就是用梯度修剪。梯度修剪的意思就是观察你的梯度向量，如果它大于某个阈值，缩放梯度向量，保证它不会太大，这就是通过一些最大值来修剪的方法。</p>
<h5 id="GRU-单元（Gated-Recurrent-Unit-（GRU-））"><a href="#GRU-单元（Gated-Recurrent-Unit-（GRU-））" class="headerlink" title="GRU  单元（Gated Recurrent Unit （GRU ））"></a>GRU  单元（Gated Recurrent Unit （GRU ））</h5><p>你已经了解了基础的 RNN 模型的运行机制，在本节视频中你将会学习门控循环单元，它改变了 RNN 的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题.</p>
<p>RNN 隐藏层的单元的可视化呈现。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571043809693.png" alt="1571043809693"></p>
<p>当我们从左到右读这个句子，GRU 单元将会有个新的变量称为c，代表细胞（cell），即记忆细胞.记忆细胞的作用是提供了记忆的能力，比如说一只猫是单数还是复数，所以当它看到之后的句子的时候，它仍能够判断句子的主语是单数还是复数。使用不同的符号c和a来表示记忆细胞的值和输出的激活值，即使它们是一样的。我现在使用个标记是因为当我们等会说到LSTMs的时候，这两个会是不同的值，但是现在对于GRU，a\<t> 的值等于c\<t> 的激活值。这些等式表示了 GRU 单元的计算，在每个时间步，我们将用一个候选值重写记忆细胞，即c ̃ \<t> 的值，所以它就是个候选值，替代了c \<t> 的值。</t></t></t></t></p>
<p>重点来了，在 GRU 中真正重要的思想是我们有一个门,下标为u的大写希腊字母（G），这是一个 0 到 1 之间的值，sigmoid 函数的输出总是非常接近 0 或者非常接近 1。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571043945772.png" alt="1571043945772"></p>
<p>这就是 GRU 单元或者说是一个简化过的 GRU 单元，它的优点就是通过门决定，当你从左（上图编号 10 所示）到右扫描一个句子的时候，这个时机是要更新某个记忆细胞，还是不更新，不更新（上图编号 11 所示，表示一直不更新）直到你到你真的需要使用记忆细胞的时候（上图编号 12 所示），这可能在句子之前就决定了。</p>
<p>对于完整的 GRU 单元我要做的一个改变就是在我们计算的第一个式子中给记忆细胞的新候选值加上一个新的项，我要添加一个门 r （下图编号 1 所示），你可以认为r代表相关性（relevance）。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571044930893.png" alt="1571044930893"></p>
<p>这就是 GRU，即门控循环单元，这是 RNN 的其中之一。这个结构可以更好捕捉非常长范围的依赖，让 RNN 更加有效。</p>
<h5 id="长短期记忆（LSTM-（long-short-term-memory-）unit-）"><a href="#长短期记忆（LSTM-（long-short-term-memory-）unit-）" class="headerlink" title="长短期记忆（LSTM （long short term memory ）unit ）"></a>长短期记忆（LSTM （long short term memory ）unit ）</h5><p>在上一个视频中你已经学了 GRU（门控循环单元）。它能够让你可以在序列中学习非常深的连接。其他类型的单元也可以让你做到这个，比如 LSTM 即长短时记忆网络，甚至比 GRU更加有效</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571057902547.png" alt="1571057902547"></p>
<p>这就是 LSTM 主要的式子（上图编号 2 所示），此处c!=a，我们像以前那样有一个更新门Gu和表示更新的参数Wu,一个 LSTM 的新特性是不只有一个更新门控制，这里的这两项（上图编号 6，7 所示），我们将用不同的项来代替它们，要用别的项来取代G u 和1 − Gu ，这里（上图编号 6 所示）我们用Gu 。然后这里（上图编号 7 所示）用遗忘门（the forget gate），我们叫它Gf,,然后我们有一个新的输出门Go(上图9)。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571058201529.png" alt="1571058201529"></p>
<p>然后这有个有意思的事情，你会注意到上面这里有条线（上图编号 10 所示的线），这条线显示了只要你正确地设置了遗忘门和更新门，LSTM 是相当容易把c<0> 的值（上图编号 11 所示）一直往下传递到右边，比如c<3> =c<0> （上图编号 12 所示）。这就是为什么 LSTM 和 GRU 非常擅长于长时间记忆某个值，对于存在记忆细胞中的某个值，即使经过很长很长的时间步。</0></3></0></p>
<p>你可能会想到这里和一般使用的版本会有些不同，最常用的版本可能是门值不仅取决于a &lt;t−1&gt; 和x \<t> ，有时候也可以偷窥一下c &lt;t−1&gt; 的值（上图编号 13 所示），这叫做“窥视孔连接”（peephole connection）。<br>LSTM 前向传播图：</t></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571058464967.png" alt="1571058464967"></p>
<p>GRU 的优点是这是个更加简单的模型，所以更容易创建一个更大的网络，而且它只有两个门，在计算性上也运行得更快，然后它可以扩大模型的规模。但是 LSTM 更加强大和灵活，因为它有三个门而不是两个。如果你想选一个使用，我认为 LSTM 在历史进程上是个更优先的选择，所以如果你必须选一个，我感觉今天大部分的人还是会把 LSTM 作为默认的选择来尝试。</p>
<h5 id="双向循环神经网络（Bidirectional-RNN-）"><a href="#双向循环神经网络（Bidirectional-RNN-）" class="headerlink" title="双向循环神经网络（Bidirectional RNN ）"></a>双向循环神经网络（Bidirectional RNN ）</h5><p>这个模型可以让你在序列的某点处不仅可以获取之前的信息，还可以获取未来的信息,下面解释双向 RNN 的工作原理。</p>
<p>我在这上面加个向右的箭头来表示前向的循环单元，并且他们这样连接，我之所以在这些地方画上了箭头是因为我们想要增加一个反向循环层，这个a反向连接就依次反向向前连接。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571059465965.png" alt="1571059465965"></p>
<p>给定一个句子”He said Teddy Roosevelt…”来预测 Teddy 是不是人名的一部分，你需要同时考虑过去和未来的信息。这就是双向循环神经网络，并且这些基本单元不仅仅是标准 RNN 单元，也可以是 GRU单元或者 LSTM 单元。事实上，很多的 NLP 问题，对于大量有自然语言处理问题的文本，有LSTM 单元的双向 RNN 模型是用的最多的。</p>
<p>这个双向 RNN网络模型的缺点就是你需要完整的数据的序列，你才能预测任意位置。比如说你要构建一个语音识别系统，那么双向 RNN 模型需要你考虑整个语音表达，但是如果直接用这个去实现的话，你需要等待这个人说完.</p>
<h5 id="深层循环神经网络（Deep-RNNs-）"><a href="#深层循环神经网络（Deep-RNNs-）" class="headerlink" title="深层循环神经网络（Deep RNNs ）"></a>深层循环神经网络（Deep RNNs ）</h5><p>目前你学到的不同 RNN 的版本，每一个都可以独当一面。但是要学习非常复杂的函数，通常我们会把 RNN 的多个层堆叠在一起构建更深的模型。这节视频里我们会学到如何构建这些更深的 RNN。</p>
<p>深层的 RNN 网络跟这个有点像，用手画的这个网络（下图左边），然后把它按时间展开就是了deep RNN。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571102283869.png" alt="1571102283869"></p>
<p>用a [l]\<t> 来表示第 l 层的激活值，这个\<t>表示第t个时间点,第一层第一个时间点的激活值a [1]<1> .</1></t></t></p>
<p>对于像左边这样标准的神经网络，你可能见过很深的网络，甚至于 100 层深，而对于RNN 来说，有三层就已经不少了。由于时间的维度，RNN 网络会变得相当大，即使只有很少的几层，很少会看到这种网络堆叠到 100 层。但有一种会容易见到，就是在每一个上面堆叠循环层，把这里的输出去掉（上图编号 1 所示），然后换成一些深的层，这些层并不水平连接，只是一个深层的网络，然后用来预测y<1> ,这种结构有三个循环单元，在时间上连接，接着一个网络在后面接一个网络。</1></p>
<p>通常这些单元（上图编号 3 所示）没必要非是标准的 RNN，最简单的 RNN 模型，也可以是 GRU 单元或者LSTM 单元，并且，你也可以构建深层的双向 RNN 网络。由于深层的 RNN 训练需要很多计算资源，需要很长的时间，尽管看起来没有多少循环层，这个也就是在时间上连接了三个深层的循环层，你看不到多少深层的循环层，不像卷积神经网络一样有大量的隐含层。</p>
<h3 id="自然语言处理与词嵌入"><a href="#自然语言处理与词嵌入" class="headerlink" title="自然语言处理与词嵌入"></a>自然语言处理与词嵌入</h3><h5 id="词汇表征（Word-Representation-）"><a href="#词汇表征（Word-Representation-）" class="headerlink" title="词汇表征（Word Representation ）"></a>词汇表征（Word Representation ）</h5><p>词嵌入（word embeddings），这是语言表示的一种方式，可以让算法自动的理解一些类似的词，比如男人对女人，比如国王对王后。通过词嵌入的概念你就可以构建 NLP 应用了，即使你的模型标记的训练集相对较小。one-hot表示方法的一大缺点就是它把每个词孤立起来，这样使得算法对相关词的泛化能力不强。这是因为任何两个 one-hot 向量的内积都是 0，如果你取两个向量，比如 king和 queen，然后计算它们的内积，结果就是 0。换一种表示方式会更好，如果我们不用 one-hot 表示，而是用特征化的表示来表示每个词.</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571188216739.png" alt="1571188216739"></p>
<p>举个例子，对于这些词，比如我们想知道这些词与 Gender（ 性别）的关系。假定男性的性别为-1，女性的性别为+1，那么 man 的性别值可能就是-1，而 woman 就是+1。最终根据经验 king 就是-0.95，queen 是+0.97，apple 和 orange 没有性别可言。所以你可以想很多的特征，为了说明，我们假设有 300 个不同的特征，这样的话你就有了这一列数字（上图编号 1 所示），这里我只写了 4 个，实际上是 300 个数字，这样就组成了一个 300 维的向量来表示 man 这个词。接下来，我想用e5391 这个符号来表示，就像这样(上图编号 2 所示）。如果用这种表示方法来表示 apple 和 orange 这些词，那么 apple 和 orange 的这种表示肯定会非常相似.</p>
<p>后面的几个视频，我们会找到一个学习词嵌入的方式，这里只是希望你能理解这种高维特征的表示能够比 one-hot 更好的表示不同的单词。而我们最终学习的特征不会像这里一样这么好理解，没有像第一个特征是性别，第二个特征是高贵，第三个特征是年龄等等这些，新的特征表示的东西肯定会更难搞清楚。</p>
<p>如果我们能够学习到一个 300 维的特征向量，或者说 300 维的词嵌入，通常我们可以做一件事，把这 300 维的数据嵌入到一个二维空间里，这样就可以可视化了。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571188377038.png" alt="1571188377038"></p>
<p>如果观察这种词嵌入的表示方法，你会发现 man 和 woman 这些词聚集在一块（上图编号 1 所示），king 和<br>queen 聚集在一块（上图编号 2 所示），这些都是人，也都聚集在一起（上图编号 3 所示）。动物都聚集在一起（上图编号 4 所示），水果也都聚集在一起（上图编号 5 所示），像 1、2、3、4 这些数字也聚集在一起（上图编号 6 所示）。如果把这些生物看成一个整体，他们也聚集在一起（上图编号 7 所示）。</p>
<h5 id="使用词嵌入"><a href="#使用词嵌入" class="headerlink" title="使用词嵌入"></a>使用词嵌入</h5><p>下面是一個命名實體识别的例子</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571188960022.png" alt="1571188960022"></p>
<p>词嵌入能够达到这种效果，其中一个原因就是学习词嵌入的算法会考察非常大的文本集，也许是从网上找到的，这样你可以考察很大的数据集可以是 1 亿个单词，甚至达到 100 亿也都是合理的，大量的无标签的文本的训练集。你可以发现 orange（ 橙子）和 durian（ 榴莲）相近，farmer（ 农民）和 cultivator（ 培育家）相近。</p>
<p>总结一下，这是如何用词嵌入做迁移学习的步骤。<br>第一步，先从大量的文本集中学习词嵌入。一个非常大的文本集，或者可以下载网上预训练好的词嵌入模型，网上你可以找到不少，词嵌入模型并且都有许可。<br>第二步，你可以用这些词嵌入模型把它迁移到你的新的只有少量标注训练集的任务中，比如说用这个 300 维的词嵌入来表示你的单词。这样做的一个好处就是你可以用更低维度的特征向量代替原来的 10000 维的 one-hot 向量，现在你可以用一个 300 维更加紧凑的向量。尽管 one-hot 向量很快计算，而学到的用于词嵌入的 300 维的向量会更加紧凑。<br>第三步，当你在你新的任务上训练模型时，在你的命名实体识别任务上，只有少量的标记数据集上，你可以自己选择要不要继续微调，用新的数据调整词嵌入。实际中，只有这个第二步中有很大的数据集你才会这样做，如果你标记的数据集不是很大，通常我不会在微调词嵌入上费力气。</p>
<h5 id="词嵌入的特性"><a href="#词嵌入的特性" class="headerlink" title="词嵌入的特性"></a>词嵌入的特性</h5><p>词嵌入还有一个迷人的特性就是它还能帮助实现类比推理。假如我提出一个问题，man 如果对应 woman，那么king 应该对应什么？你们应该都能猜到 king 应该对应 queen。能否有一种算法来自动推导出这种关系，下面就是实现的方法,用相似度。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571189765075.png" alt="1571189765075"></p>
<h5 id="嵌入矩阵（Embedding-Matrix"><a href="#嵌入矩阵（Embedding-Matrix" class="headerlink" title="嵌入矩阵（Embedding Matrix)"></a>嵌入矩阵（Embedding Matrix)</h5><p>当你应用算法来学习词嵌入时，实际上是学习一个嵌入矩阵，假设我们的词汇表含有 10,000 个单词，词汇表里有 a，aaron，orange，zulu，可能还有一个未知词标记\<unk>。我们要做的就是学习一个嵌入矩阵E，它将是一个<br>300×10,000 的矩阵，如果你的词汇表里有 10,000 个，或者加上未知词就是 10,001 维。这个矩阵的各列代表的是词汇表中 10,000 个不同的单词所代表的不同向量。</unk></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571190390469.png" alt="1571190390469"></p>
<p>把矩阵𝐹和这个one-hot向量相乘，最后得到的其实就是这个300维的列,就是单词 orange 下的这一列，它等于e6257 ，这个符号是我们用来表示这个 300×1 的嵌入向量的符号，它表示的单词是 orange。在实践中你会使用一个专门的函数来单独查找矩阵E的某列，而不是用通常的矩阵乘法来做,例如在 Keras 中就有一个嵌入层，然后我们用这个嵌入层更有效地从嵌入矩阵中提取出你需要的列，而不是对矩阵进行很慢很复杂的乘法运算。</p>
<h5 id="学习词嵌入"><a href="#学习词嵌入" class="headerlink" title="学习词嵌入"></a>学习词嵌入</h5><p>你将要学习一些具体的算法来学习词嵌入。假如你在构建一个语言模型，并且用神经网络来实现这个模型。于是在训练过程中，你可能想要你的神经网络能够做到比如输入：“I want a glass of orange ___.”，然后预测这句话的下一个词。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571191116845.png" alt="1571191116845"></p>
<p>下面我将介绍如何建立神经网络来预测序列中的下一个单词,我们从第一个词 I 开始，建立一个 one-hot 向量表示这个单词 I,这是一个 one-hot 向量,它是一个 10,000 维的向量。然后要做的就是生成一个参数矩阵E，然后用E乘以O 4343 ，得到嵌入向量e 4343.然后我们对其他的词也做相同的操作。</p>
<p>于是现在你有许多 300 维的嵌入向量。我们能做的就是把它们全部放进神经网络中，经过神经网络以后再通过 softmax 层（上图编号 4 所示），这个 softmax也有自己的参数，然后这个 softmax 分类器会在 10,000 个可能的输出中预测结尾这个单词。</p>
<p>实际上更常见的是有一个固定的历史窗口，举个例子，你总是想预测给定四个单词（上图编号 1 所示）后的下一个单词，注意这里的 4 是算法的超参数。这就是如何适应很长或者很短的句子，方法就是总是只看前 4 个单词，所以说我只用这 4 个单词（上图编号 2 所示）而不去看这几个词（上图编号 3 所示）。這個个模型的参数就是矩阵E，对所有的单词用的都是同一个矩阵E，而不是对应不同的位置上的不同单词用不同的矩阵。然后这些权重（上图编号 5 所示）也都是算法的参数，你可以用反向传播来进行梯度下降来最大化训练集似然，通过序列中给定的 4 个单词去重复地预测出语料库中下一个单词什么。</p>
<p>如果你的目标是学习一个嵌入向量，研究人员已经尝试过很多不同类型的上下文。如果你要建立一个语言模型，那么一般选取目标词之前的几个词作为上下文。但如果你的目标不是学习语言模型本身的话，那么你可以选择其他的上下文。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571191479373.png" alt="1571191479373"></p>
<p>你可以提出这样一个学习问题，它的上下文是左边和右边的四个词，你可以把目标词左右各 4 个词作为上下文（上图编号 3 所示这就意味着我们提出了一个这样的问题，算法获得左边 4 个词，也就是 a glass of orange，还有右边四个词 to go along with，然后要求预测出中间这个词（上图编号 4 所示）。提出这样一个问题，这个问题需要将左边的还有右边这 4 个词的嵌入向量提供给神经网络，就像我们之前做的那样来预测中间的单词是什么，来预测中间的目标词，这也可以用来学习词嵌入。</p>
<p>研究者发现，如果你真想建立一个语言模型，用目标词的前几个单词作为上下文是常见做法（上图编号 9 示）。但如果你的目标是学习词嵌入，那么你就可以用这些其他类型的上下文（上图编号 10 所示），它们也能得到很好的词嵌入。</p>
<h5 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h5><p>你已经见到了如何学习一个神经语言模型来得到更好的词嵌入，在本视频中你会见到 Word2Vec 算法，这是一种简单而且计算时更加高效的方式来学习这种类型的嵌入。</p>
<p>于是我们将构造一个监督学习问题，它给定上下文词，要求你预测在这个词正负 10 个词距或者正负 5 个词距内随机选择的某个目标词。假设在训练集中给定了一个这样的句子：“I want a glass of orange juice to go along with my cereal.”，在 Skip-Gram 模型中，我们要做的是抽取上下文和目标词配对，来构造一个监督学习问题。上下文不一定总是目标单词之前离得最近的四个单词，或最近的n个单词。我们要的做的是随机选一个词作为上下文词，比如选 orange 这个词，然后我们要做的是随机在一定词距内选另一个词，比如在上下文词前后 5 个词内或者前后 10 个词内，我们就在这个范围内选择目标词。可能你正好选到了 juice 作为目标词，正好是下一个词（表示 orange的下一个词）也有可能你选到了前面第二个词，所以另一种配对目标词可以是 glass，还可能正好选到了单词 my 作为目标词。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571194211944.png" alt="1571194211944"></p>
<p>这大体上就是一个可以找到词嵌入的简化模型和神经网络（上图编号 2 所示），其实就是个 softmax 单元。矩阵𝐹将会有很多参数，所以矩阵E有对应所有嵌入向量e c的参数（上图编号 6 所示），softmax 单元也有θt 的参数（上图编号 3 所示）。如果优化这个关于所有这些参数的损失函数，你就会得到一个较好的嵌入向量集，这个就叫做 Skip-Gram模型。它把一个像 orange 这样的词作为输入，并预测这个输入词，从左数或从右数的某个词，预测上下文词的前面一些或者后面一些是什么词。</p>
<p>实际上使用这个算法会遇到一些问题，首要的问题就是计算速度。这个分母的求和操作是相当慢的，实际10,000 已经是相当慢的了，所以扩大词汇表就更加困难了。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571194415590.png" alt="1571194415590"></p>
<p>这里有一些解决方案，如分级（hierarchical）的 softmax 分类器和 负采样（Negative Sampling）。使用一个分级（hierarchical）的 softmax 分类器，意思就是说不是一下子就确定到底是属于 10,000 类中的哪一类。想象如果你有一个分类器，它告诉你目标词是在词汇表的前 5000 个中还是在词汇表的后 5000 个词中，一直类推，直到最终你找到一个词准确所在的分类器。</p>
<p>在实践中分级 softmax 分类器不会使用一棵完美平衡的分类树或者说一棵左边和右边分支的词数相同的对称树。实际上，分级的 softmax分类器会被构造成常用词在顶部，然而不常用的词像 durian 会在树的更深处。因为你想更常见的词会更频繁，所以你可能只需要少量检索就可以获得常用单词像 the 和 of。</p>
<p>一旦你对上下文 c 进行采样，那么目标词 t 就会在上下文 c 的正负 10 个词距内进行采样。但是你要如何选择上下文c？一种选择是你可以就对语料库均匀且随机地采样，如果你那么做，你会发现有一些词，像 the、of、a，and、to 诸如此类是出现得相当频繁的，你会发现你的上下文到目标词的映射会相当频繁地得到这些种类的词，但是其他词，像 orange、apple 或 durian 就不会那么频繁地出现了。实际上词p(c)的分布并不是单纯的在训练集语料库上均匀且随机的采样得到的，而是采用了不同的分级来平衡更常见的词和不那么常见的词.</p>
<p>实际上有两个不同版本的 Word2Vec 模型，Skip-Gram 只是其中的一个，另一个叫做CBOW，即连续词袋模型（Continuous Bag-Of-Words Model），它获得中间词两边的的上下文，然后用周围的词去预测中间的词，这个模型也很有效，也有一些优点和缺点。CBOW 是从原始语句推测目标字词；而 Skip-Gram 正好相反，是从目标字词推测出原始语句。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571194871380.png" alt="1571194871380"></p>
<h5 id="负采样（Negative-Sampling"><a href="#负采样（Negative-Sampling" class="headerlink" title="负采样（Negative Sampling)"></a>负采样（Negative Sampling)</h5><p>你会看到一个改善过的学习问题叫做负采样，它能做到与你刚才看到的 Skip-Gram 模型相似的事情，但是用了一个更加有效的学习算法.我们在这个算法中要做的是构造一个新的监督学习问题，那么问题就是给定一对单词，<br>比如 orange 和 juice，我们要去预测这是否是一对上下文词-目标词（context-target）。</p>
<p>在这个例子中 orange 和 juice 就是个正样本，那么 orange 和 king 就是个负样本，我们把它标为 0。我们要做的就是采样得到一个上下文词和一个目标词，在这个例子中就是orange 和 juice，我们用 1 作为标记.</p>
<p>正样本跟上个视频中生成的方式一模一样，先抽取一个上下文词，在一定词距内比如说正负 10 个词距内选一个目标词，这就是生成这个表的第一行，即 orange–juice -1 的过程。然后为了生成一个负样本，你将用相同的上下文词，再在字典中随机选一个词，在这里我随机选了单词 king，标记为 0。还是 orange，再可能正好选到 of这个词，再把这个标记为 0，注意 of 被标记为 0，即使 of 的确出现在 orange 词的前面,只要是在选的，都标为0。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571195653127.png" alt="1571195653127"></p>
<p>接下来我们将构造一个监督学习问题，其中学习算法输入x,输入这对词,要去预测目标的标签y,因此问题就是给定一对词，像 orange 和 juice，你觉得它们会一起出现么？小数据集的话，K从 5 到 20 比较好。如果你的数据集很大，K就选的小一点。为了定义模型，我们将使用记号c表示上下文词，记号t表示可能的目标词，我再用y表示 0 和 1，表示是否是一对上下文-目标词。</p>
<p>不使用一个巨大的 10,000 维度的 softmax，因为计算成本很高，而是把它转变为 10,000 个二分类问题，每个都很容易计算，每次迭代我们要做的只是训练它们其中的 5 个，一般而言就是K + 1个，其中K个负样本和 1 个正样本。这也是为什么这个算法计算成本更低，因为只需更新K + 1个逻辑单元，K + 1个二分类问题，相对而言每次迭代的成本比更新 10,000 维的 softmax 分类器成本低</p>
<p>这个算法有一个重要的细节就是如何选取负样本，即在选取了上下文词 orange 之后，你如何对这些词进行采样生成负样本？一个办法是对中间的这些词进行采样，即候选的目标词，你可以根据其在语料中的经验频率进行采样，就是通过词出现的频率对其进行采样。但问题是这会导致你在 like、the、of、and 诸如此类的词上有很高的频率。另一个极端就是用均匀且随机地抽取负样本.采用公式的方法采样，f(w 𝑗 )是观测到的在语料库中的某个英文词的词频.</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571196350537.png" alt="1571196350537"></p>
<p>去下载其他人的词向量是很好的方法，在此基础上改进。</p>
<h5 id="GloVe-词向量（GloVe-Word-Vectors"><a href="#GloVe-词向量（GloVe-Word-Vectors" class="headerlink" title="GloVe  词向量（GloVe Word Vectors)"></a>GloVe  词向量（GloVe Word Vectors)</h5><p>了解了几个计算词嵌入的算法，另一个在 NLP 社区有着一定势头的算法是 GloVe算法，这个算法并不如Word2Vec 或是 Skip-Gram 模型用的多，但是也有人热衷于它.GloVe 代表用词表示的全局变量（global vectors for word representation）。</p>
<p>假定X ij 是单词i在单词j上下文中出现的次数，那么这里i和j就和t和c的功能一样，所以你可以认为X ij等同于X tc 。对于 GloVe 算法，我们可以定义上下文和目标词为任意两个位置相近的单词，假设是左右各10 词的距离，那么X ij就是一个能够获取单词i和单词j出现位置相近时或是彼此接近的频率的计数器.</p>
<p>GloVe 模型做的就是进行优化，我们将他们之间的差距进行最小化处理：</p>
<p>对于这个（下图编号 1 所示）来说，你想要知道的是告诉你这两个单词之间有多少联系,换句话说就是他们同时出现的频率是多少.然后，我们要做的是解决参数θ和e的问题，用梯度下降来最小化上面的公式，你只想要学习一些向量，这样他们的输出能够对这两个单词同时出现的频率进行良好的预测。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571197193342.png" alt="1571197193342"></p>
<p>如果Xij是等于 0 的话，那log0就是未定义的，是负无穷大的，因此要做的就是添加一个额外的加权项f(Xij)（上图编号 2 所示）。它另一个作用是，有些词在英语里出现十分频繁，比如说 this，is，of，a 等等，有些情况，这叫做 停止词，但是在频繁词和不常用词之间也会有一个连续统（continuum）。即使是像 durion 这样不常用的词，它也能给予大量有意义的运算，同时也能够给像 this，is，of，a 这样在英语里出现更频繁的词更大但不至于过分的权重。</p>
<p>当你在使用我们了解过的算法的一种来学习一个词嵌入时，例如我们之前的幻灯片里提到的 GloVe 算法，会发生一件事就是你不能保证嵌入向量的独立组成部分是能够理解的，不像前面例子中的gender，size等。</p>
<h5 id="情感分类（Sentiment-Classification"><a href="#情感分类（Sentiment-Classification" class="headerlink" title="情感分类（Sentiment Classification"></a>情感分类（Sentiment Classification</h5><p>情感分类任务就是看一段文本，然后分辨这个人是否喜欢他们在讨论的这个东西。输入x是一段文本，而输出y是你要预测的相应情感。比如说是一个餐馆评价的星级.如果在很大的训练集上训练E，比如一百亿的单词，这样你就会获得很多知识，甚至从有些不常用的词中获取，然后应用到你的问题上，即使你的标记数据集里没有这些词。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571206219097.png" alt="1571206219097"></p>
<p>这里用的平均值运算单元，这个算法适用于任何长短的评论，因为即使你的评论是 100个词长，你也可以对这一百个词的特征向量求和或者平均它们，然后得到一个表示一个 300维的特征向量表示，然后把它送进你的 softmax 分类器，所以这个平均值运算效果不错。它实际上会把所有单词的意思给平均起来，或者把你的例子中所有单词的意思加起来就可以用了。<br>这个算法有一个问题就是没考虑词序，尤其是这样一个负面的评价，”Completely lacking in good taste, good service, and good ambiance.”，但是 good 这个词出现了很多次，有 3 个good，你的分类器很可能认为这是一个好的评论，尽管事实上这是一个差评，只有一星的评价。</p>
<p><img src="/../../132456/blogSource/_posts/n../assets/blogimg/1571206333247.png" alt="1571206333247"></p>
<p>如果你训练一个这样的算法，最后会得到一个很合适的情感分类的算法。由于你的词嵌入是在一个更大的数据集里训练的，这样效果会更好，更好的泛化一些没有见过的新的单词。</p>
<h5 id="词嵌入除偏（Debiasing-Word-Embeddings"><a href="#词嵌入除偏（Debiasing-Word-Embeddings" class="headerlink" title="词嵌入除偏（Debiasing Word Embeddings)"></a>词嵌入除偏（Debiasing Word Embeddings)</h5><p>现在机器学习和人工智能算法正渐渐地被信任用以辅助或是制定极其重要的决策，因此我们想尽可能地确保它们不受非预期形式偏见影响，比如说性别歧视、种族歧视等等。本节视频中我会向你展示词嵌入中一些有关减少或是消除这些形式的偏见的办法。</p>
<p>比如：已经完成学习的词嵌入可能会输出 Man：Computer Programmer，同时输出 Woman：Homemaker，那个结果看起来是错的，并且它执行了一个十分不良的性别歧视。</p>
<p>偏见趋势可以将它看做 1D 子空间，所以这个无偏见趋势就会是 299D 的子空间。我已经略微简化了，原文章中的描述这个偏见趋势可以比 1 维更高</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571207074320.png" alt="1571207074320"></p>
<p>1.用一个更加复杂的算法叫做 SVU，也就是奇异值分解，如果你对主成分分析（Principle Component Analysis）很熟悉的话，奇异值分解这个算法的一些方法和主成分分析 (PCA)其实很类似。</p>
<p>2.中和步骤，所以对于那些定义不确切的词可以将其处理一下，避免偏见。不过也有一些词像 doctor ,babysitter 我们想使之在性别方面是中立的。减少或是消除他们的性别歧视趋势的成分，也就是说减少他们在这个水平方向上的距离</p>
<p>3.均衡步，意思是说你可能会有这样的词对，grandmother 和 grandfather，或者是 girl和 boy，对于这些词嵌入，你只希望性别是其区别。babysitter和grandmother之间的距离或者说是相似度实际上是小于babysitter和grandfather之间的,在最后的均衡步中，我们想要确保的是像 grandmother 和 grandfather 这样的词都能够有一致的相似度，或者说是相等的距离，和 babysitter 或是 doctor 这样性别中立的词一样。</p>
<h3 id="序列模型和注意力机制"><a href="#序列模型和注意力机制" class="headerlink" title="序列模型和注意力机制"></a>序列模型和注意力机制</h3><h5 id="序列结构的各种序列"><a href="#序列结构的各种序列" class="headerlink" title="序列结构的各种序列"></a>序列结构的各种序列</h5><p>在这一周，你将会学习 seq2seq（sequence to sequence）模型，从机器翻译到语音识别，它们都能起到很大的作用，从最基本的模型开始。之后你还会学习集束搜索（Beam search）和注意力模型（Attention Model），一直到最后的音频模型，比如语音。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571207799664.png" alt="1571207799664"></p>
<p>首先，我们先建立一个网络，这个网络叫做编码网络（encoder network）（上图编号 1所示），它是一个 RNN 的结构， RNN 的单元可以是 GRU 也可以是 LSTM。每次只向该网络中输入一个法语单词，将输入序列接收完毕后，这个 RNN 网络会输出一个向量来代表这个输入序列。之后你可以建立一个解码网络，我把它画出来（上图编号 2 所示），它以编码网络的输出作为输入，编码网络是左边的黑色部分（上图编号 1 所示），之后它可以被训练为每次输出一个翻译后的单词，一直到它输出序列的结尾或者句子结尾标记，这个解码网络的工作就结束了。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571207894300.png" alt="1571207894300">还有一个与此类似的结构被用来做图像描述，给出一张图片，比如这张猫的图片（上图编号 1 所示），它能自动地输出该图片的描述，一只猫坐在椅子上.在之前的卷积网络课程中，你已经知道了如何将图片输入到卷积神经网络中，比如一个预训练的 AlexNet 结构（上图编号 2 方框所示），然后让其学习图片的编码，或者学习图片的一系列特征。我们去掉最后的 softmax单元（上图编号 3 所示），这个预训练的 AlexNet 结构会给你一个 4096 维的特征向量，向量表示的就是这只猫的图片，所以这个预训练网络可以是图像的编码网络。接着你可以把这个向量输入到 RNN 中（上图编号 4 方框所示），RNN 要做的就是生成图像的描述，每次生成一个单词.</p>
<h5 id="选择最可能的句子"><a href="#选择最可能的句子" class="headerlink" title="选择最可能的句子"></a>选择最可能的句子</h5><p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571209308057.png" alt="1571209308057"></p>
<p>机器翻译模型其实和语言模型非常相似，不同在于语言模型总是以零向量（上图编号 4 所示）开始，而 encoder 网络会计算出一系列向量（上图编号 2 所示）来表示输入的句子。当你使用这个模型来进行机器翻译时，你并不是从得到的分布中进行随机取样，而是你要找到一个英语句子y,使得条件概率最大化。</p>
<p>如果你的字典中有 10,000 个单词，并且你的翻译可能有 10 个词那么长，那么可能的组合就有 10,000 的 10 次方这么多，这仅仅是10 个单词的句子，从这样大一个字典中来挑选单词，所以可能的句子数量非常巨大，不可能去计算每一种组合的可能性。所以这时最常用的办法就是用一个近似的搜索算法，这个近似的搜索算法做的就是它会尽力地，尽管不一定总会成功，但它将挑选出句子y使得条件概率最大化，尽管它不能保证找到的y值一定可以使概率最大化，但这已经足够了,下节课中学习集束搜索。 </p>
<h5 id="集束搜索（Beam-Search-）"><a href="#集束搜索（Beam-Search-）" class="headerlink" title="集束搜索（Beam Search ）"></a>集束搜索（Beam Search ）</h5><p>这节，你会明白怎么把集束搜索算法应用到你自己的工作中。贪婪算法只会挑出最可能的那一个单词，然后继续。而集束搜索则会考虑多个选择，集束搜索算法会有一个参数 B，叫做集束宽（beam width）。在这个例子中我把这个集束宽设成 3，这样就意味着集束搜索不会只考虑一个可能结果，而是一次会考虑 3 个，比如对第一个单词有不同选择的可能性，最后找到 in、jane、september。</p>
<p>让我们看看集束搜索算法的第二步，已经选出了 in、jane、september 作为第一个单词三个最可能的选择，集束算法接下来会针对每个第一个单词考虑第二个单词是什么。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571210280755.png" alt="1571210280755"></p>
<p>在第二步里我们更关心的是要找到最可能的第一个和第二个单词对，所以不仅仅是第二个单词有最大的概率，而是第一个、第二个单词对有最大的概率，按照条件概率的准则，这个可以表示成第一个单词的概率乘以第二个单词的概率。这果集束搜索找到了第一个和第二个单词对最可能的三个选择是“in September”或者“jane is”或者“jane visits”，这就意味着我们去掉了 september 作为英语翻译结果的第一个单词的选择。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571210601665.png" alt="1571210601665"></p>
<p>然后继续，接着进行集束搜索的第四步，再加一个单词继续，最终这个过程的输出一次增加一个单词，集束搜索最终会找到“Jane visits africa in september”这个句子，终止在句尾符号。</p>
<h5 id="改进集束搜索"><a href="#改进集束搜索" class="headerlink" title="改进集束搜索"></a>改进集束搜索</h5><p>你已经学到了基本的束搜索算法，这个视频里,我们会学到一些技巧, 能够使算法运行的更好。长度归一化（Length normalization）就是对束搜索算法稍作调整的一种方式，B的选取也至关重要。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571211192176.png" alt="1571211192176"></p>
<p>前面讲到束搜索就是最大化这个概率，这些符号看起来可能比实际上吓人，但这就是我们之前见到的乘积概率（the product probabilities）。如果计算这些，其实这些概率值都是小于 1 的，通常远小于 1。很多小于 1<br>的数乘起来，会得到很小很小的数字，会造成数值下溢（numerical underflow）。在实践中,我们不会最大化这<br>个乘积，而是取log值。这样我们会得到一个数值上更稳定的算法，不容易出现四舍五入的误差，数值的舍入误差（rounding errors）或者说数值下溢（numerical underflow）。</p>
<p>如果参照原来的目标函数（this original objective），如果有一个很长的句子，那么这个句子的概率会很低，因为乘了很多项小于 1 的数字来估计句子的概率。所以这个目标函数有一个缺点，它可能不自然地倾向于简短的翻译结果，它更偏向短的输出。我们可以把它归一化，通过除以翻译结果的单词数量，这样就是取每个单词的概率对数值的平均了，这样很明显地减少了对输出长的结果的惩罚，有时会用一个更柔和的方法（a softer approach），在Ty 上加上指数α，α可以等于 0.7。</p>
<p>最后还有一些实现的细节，如何选择束宽 B。如果束宽很大，你会考虑很多的可能，你会得到一个更好的结果，因为你要考虑很多的选择，但是算法会运行的慢一些，内存占用也会增大，计算起来会慢一点。而如果你用小的束宽，结果会没那么好，因为你在算法运行中，保存的选择更少，但是你的算法运行的更快，内存占用也小。到束宽为 3、到 10，你会看到一个很大的改善。但是当束宽从 1000 增加到 3000 时，效果就没那么明显了。不同于BFS,DFS这些算法，这些都是精确的搜索算法（exact search algorithms），束搜索运行的更快，但是不能保证一定能找到 argmax 的准确的最大值。</p>
<h5 id="集束搜索的误差分析"><a href="#集束搜索的误差分析" class="headerlink" title="集束搜索的误差分析"></a>集束搜索的误差分析</h5><p>你将会学习到误差分析和束搜索算法是如何相互起作用的，以及你怎样才能发现是束搜索算法出现了问题，需要花时间解决，还是你的 RNN 模型出了问题，要花时间解决。我们先来看看如何对束搜索算法进行误差分析。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571212881333.png" alt="1571212881333"></p>
<p>再接着你遍历了更多的例子，有时是束搜索算法出现了问题，有时是模型出现了问题，等等。通过这个过程，你就能够执行误差分析，得出束搜索算法和 RNN 模型出错的比例是多少。只有当你发现是束搜索算法造成了大部分错误时，才值得花费努力增大集束宽度。相反地，如果你发现是 RNN 模型出了更多错，那么你可以进行更深层次的分析，来决定是需要增加正则化还是获取更多的训练数据，抑或是尝试一个不同的网络结构，或是其他方案。</p>
<h5 id="Bleu得分"><a href="#Bleu得分" class="headerlink" title="Bleu得分"></a>Bleu得分</h5><p>机器翻译（machine translation）的一大难题是一个法语句子可以有多种英文翻译而且都同样好，所以当有多个同样好的答案时，怎样评估一个机器翻译系统呢？BLEU  得分做的就是，给定一个机器生成的翻译，它能够自动地计算一个分数来衡量机器翻译的好坏。直觉告诉我们，只要这个机器生成的翻译与任何一个人工翻译的结果足够接近，那么它就会得到一个高的 BLEU 分数。顺便提一下 BLEU 代表 bilingual evaluation understudy (双语评估替补)。</p>
<p>衡量机器翻译输出质量的方法之一是观察输出结果的每一个词看其是否出现在参考中，这被称做是机器翻译的精确<br>度,但是下面的句子输出7个the，精度为7/7=100%，但输出结果很差。另外，我们在达到上限时截断计数，这就是改良后的精确度评估，为2/7，这些方案都不太好。</p>
<p>到目前为止，我们都只是关注单独的单词，在 BLEU 得分中，你不想仅仅考虑单个的单词，你也许也想考虑成对的单词，我们定义一下二元词组（bigrams）的 BLEU 得分。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571215752213.png" alt="1571215752213"></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571215985146.png" alt="1571215985146"></p>
<p>基于我们在一元词组中学到的内容，我们将改良后的一元词组精确度定义为P 1 ，P代表的是精确度。这里的下标 1 的意思是一元词组。你也可以定义P n 为n元词组精确度，用 n-gram 替代掉一元词组。所以这就是机器翻译输出中的n元词组的countclip 之和除以n元词组的出现次数之和。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571216211587.png" alt="1571216211587"></p>
<p>最后，我们将这些组合一下来构成最终的 BLEU 得分。我们实际上会用额外的一个叫做 BP 的惩罚因子（the BP penalty）来调整这项。BP 的意思是“简短惩罚”（ brevity penalty）。如果你输出了一个非常短的翻译，那么它会更容易得到一个高精确度。因为输出的大部分词可能都出现在参考之中，不过我们并不想要特别短的翻译结果。实践中，很少人会从零实现一个 BLEU 得分（implement a BLEU score from scratch），有很多开源的实现结果，你可以下载下来然后直接用来评估你的系统。</p>
<h5 id="注意力机制（Attention-Model）"><a href="#注意力机制（Attention-Model）" class="headerlink" title="注意力机制（Attention Model）"></a>注意力机制（Attention Model）</h5><p>注意力模型或者说注意力这种思想（The attention algorithm, the attention idea）已经是深度学习中最重要的思想之一，我们看看它是怎么运作的。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571282972958.png" alt="1571282972958"></p>
<p>像这样给定一个很长的法语句子，在你的神经网络中，这个绿色的编码器要做的就是读整个句子，然后记忆整个句子，再在感知机中传递，而对于这个紫色的神经网络，即解码网络（the decoder network）将生成英文翻译。人工翻译并不会通过读整个法语句子，再记忆里面的东西，然后从零开始，机械式地翻译成一个英语句子。而人工翻译，首先会做的可能是先翻译出句子的部分，再看下一部分，并翻译这一部分。</p>
<p>你会通过句子，一点一点地翻译，因为记忆整个的像这样的的句子是非常困难的。你在下面这个编码解码结构中，会看到它对于短句子效果非常好，于是它会有一个相对高的 Bleu 分（Bleu score），但是对于长句子而言，比如说大于 30 或者 40 词的句子，它的表现就会变差。注意力模型，它翻译得很像人类，一次翻译句子的一部分。而且有了注意力模型，机器翻译系统的表现会像这个一样，因为翻译只会翻译句子的一部分，你不会看到这个有一<br>个巨大的下倾（huge dip），这个下倾实际上衡量了神经网络记忆一个长句子的能力。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571283241947.png" alt="1571283241947"></p>
<p>我们要对单词做的就是，对于句子里的每五个单词，计算一个句子中单词的特征集，也有可能是周围的词，让我们试试，生成英文翻译。我们将使用另一个RNN 生成英文翻译，这是我平时用的 RNN 记号。我不用A来表示感知机（the activation），这是为了避免和这里的感知机（the activations）混淆。我会用另一个不同的记号，我会用S<br>来表示 RNN 的隐藏状态（the hidden state in this RNN).</p>
<p>当你尝试生成第一个词，即输出，那么我们应该看输入的法语句子的哪个部分？注意力模型就会计算注意力权重（a set of attention weights），我们将用α&lt;1,1&gt; 来表示当你生成第一个词时你应该放多少注意力在这个第一块信息处。然后我们算第二个，这个叫注意力权重，我们应该花多少注意力在输入的第二个词上面。依次类推，当生成一个特定的英文词时，这允许它在每个时间步去看周围词距内的法语词要花多少注意力。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571283564069.png" alt="1571283564069"></p>
<p>你已经见到了,注意力模型如何让一个神经网络只注意到一部分的输入句子。当它在生成句子的时候，更像人类翻译。让我们把这些想法转化成确切的式子，来实现注意力模型。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571283648650.png" alt="1571283648650"></p>
<p>我们先假定有一个输入句子，并使用双向的 RNN，或者双向的 GRU或者双向的 LSTM，去计算每个词的特征。对于前向传播（the forward occurrence），你有第一个时间步的前向传播的激活值（a forward occurrence first time step），第一个时间步后向传播的激活值，后向的激活值，以此类推。他们一共向前了五个时间步，也向后了五个时间步，技术上我们把这里设置为 0。a \<t> 就是时间步t上的特征向量。为了保持记号的一致性，我们用第二个，也就是t′，实际上我将用t′来索引法语句子里面的词,接下来我们只进行前向计算，就是说这是个单向的 RNN，用状态S表示生成翻译。所以第一个时间步，它应该生成y <1> ，当你输入上下文C的时候就会这样，如果你想用时间来索引它，你可以写C<1> ，a参数告诉我们上下文有多少取决于我们得到的特征，或者我们从不同时间步中得到的激活值。所以我们定义上下文的方式实际上来源于被注意力权重加权的不同时间步中的特征值。换句话来说，当你在t处生成输出词，你应该花多少注意力在第t′个输入词上面，这是生成输出的其中一步。然后下一个时间步，你会生成第二个输出。</1></1></t></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571284095137.png" alt="1571284095137"></p>
<p>现在我们如何计算这些e项，一种我们可以用的方式是用下面这样的小的神经网络，s &lt;t−1&gt; 就是神经网络在上个时间步的状态，于是这里我们有一个神经网络,如果你想要生成y \<t> ，那么s &lt;t−1&gt; 就是上一时间步的隐藏状态。然后a &lt;t′&gt; ，即上个时间步的的特征是另一个输入。直观来想就是，如果你想要决定要花多少注意力在t′的激活值上。</t></p>
<h5 id="语音识别（Speech-recognition-）"><a href="#语音识别（Speech-recognition-）" class="headerlink" title="语音识别（Speech recognition ）"></a>语音识别（Speech recognition ）</h5><p>seq2seq 模型是如何应用于音频数据的（audio data），比如语音（the speech）。现在你有一个音频片段x（an audio clip,x），你的任务是自动地生成文本y。</p>
<p>不过在 end-to-end 模型中，我们发现这种音位表示法（phonemes representations）已经不再必要了，而是可以构建一个系统，通过向系统中输入音频片段（audio clip），然后直接输出音频的文本（a transcript），而不需要使用这种人工设计的表示方法。</p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571557027383.png" alt="1571557027383"></p>
<p> CTC 损失函数（CTC cost）来做语音识别。CTC 就是 Connectionist Temporal Classification,假设语音片段内容是某人说：”the quick brown fox”，这时我们使用一个新的网络，结构像这个样子，这里输入𝑦和输出𝑧的数量都是一样的，因为我在这里画的，只是一个简单的单向 RNN 结构。然而在实际中，它有可能是双向的 LSTM 结构，或者双向的 GIU 结构，并且通常是很深的模型。但注意一下这里时间步的数量，它非常地大。在语音识别中，通常输入的时间步数量（the number of input time steps）要比输出的时间步的数量（the number of output time steps）多出很多。</p>
<p>比如你有一段 10 秒的音频，并且特征（features）是 100 赫兹的，即每秒有 100 个样本，于是这段 10 秒的音频片段就会有 1000 个输入，就是简单地用 100 赫兹乘上 10 秒。所以有 1000 个输入，但可能你的输出就没有 1000 个字母了，或者说没有 1000 个字符。这时要怎么办呢？CTC 损失函数允许 RNN 生成这样的输出：ttt，这是一个特殊的字符，叫做空白符，我们这里用下划线表示，这句话开头的音可表示为h_eee_ _ <em>，然后这里可能有个空格，我们用这个来表示空格，之后是</em> _ _qqq__，这样的输出也被看做是正确的输出。</p>
<p>CTC  损失函数的一个基本规则是将空白符之间的重复的字符折叠起来，再说清楚一些，我这里用下划线来表示这个特殊的空白符（a special blank character ），它和空格（the space character ）是不一样的。</p>
<h5 id="触发字检测（Trigger-Word-Detection"><a href="#触发字检测（Trigger-Word-Detection" class="headerlink" title="触发字检测（Trigger Word Detection)"></a>触发字检测（Trigger Word Detection)</h5><p>学习了很多关于深度学习和序列模型的内容，于是我们可以真正去简便地描绘出一个触发字系统（a trigger word system）,触发字系统的例子包括 Amazon echo，它通过单词 Alexa 唤醒；还有百度 DuerOS 设备，通过”小度你好”来唤醒；苹果的 Siri 用 Hey Siri 来唤醒等。</p>
<p>我们要做的就是把一个 音频片段（an audio clip ）计算出它的声谱图特征（spectrogram features）得到特征向量 ）得到特征向量x<1> , x <2> , x <3> ..，然后把它放到 RNN 中，最后要做的，就是定义我们的目标标签y。</3></2></1></p>
<p><img src="https://pic-1253537137.cos.ap-guangzhou.myqcloud.com/pic/pic/2019-07-25-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1571557303981.png" alt="1571557303981"></p>

      
		<!-- 在这里添加版权内容-->
		
				<! -- 添加版权信息 -->
<! -- 设置版权信息格式 -->
<style type="text/css">
div.article-footer-copyright{
   border-top:1px solid #d3d3d3;
   margin: 20px auto;     
   padding-left:2em;
   width: 100%;
}
div.article-footer-copyright span,.copyright abbr{
  color:#3d3d3d;
}
div.article-footer-copyright{
	margin-top:2em;
	padding:1.5em;
	border:1px solid #d3d3d3;
	background-color:#eaeaea;
}
div.article-footer-copyright {
	line-height: 160%;
	margin: 10px;
	font-size: 90%;
    color: #A3A3A3
}
</style>
<br>
<!-- 版权信息内容在这里 -->
<div class="article-footer-copyright">
本文作者：<b><a href="/index.html" target="_blank" title="方既白">方既白</a></b>，采用署名-非商业性使用-相同方式共享<a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a>许可协议</br>
本文标题：<b><a href="/2019/20190725深度学习笔记/" target="_blank" title="吴恩达深度学习笔记汇总1-神经网络和深度学习">吴恩达深度学习笔记汇总1-神经网络和深度学习</a></b>
</br>
本文链接：<b><a href="https://blog.syzhou.site/2019/20190725深度学习笔记/" target="_blank" title="吴恩达深度学习笔记汇总1-神经网络和深度学习">https://blog.syzhou.site/2019/20190725深度学习笔记/</a></b>
</div>
<! -- 添加版权信息 -->
		
		<!--添加版权内容结束-->
      
        <div class="page-reward">
          <a href="javascript:;" class="page-reward-btn tooltip-top">
            <div class="tooltip tooltip-east">
            <span class="tooltip-item">
              赏
            </span>
            <span class="tooltip-content">
              <span class="tooltip-text">
                <span class="tooltip-inner">
                  <p class="reward-p"><i class="icon icon-quo-left"></i>谢谢你请我吃糖果<i class="icon icon-quo-right"></i></p>
                  <div class="reward-box">
                    
                    <div class="reward-box-item">
                      <img class="reward-img" src="/assets/img/alipay.png">
                      <span class="reward-type">支付宝</span>
                    </div>
                    
                    
                    <div class="reward-box-item">
                      <img class="reward-img" src="/assets/img/weixin.png">
                      <span class="reward-type">微信</span>
                    </div>
                    
                  </div>
                </span>
              </span>
            </span>
          </div>
          </a>
        </div>
      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      
	<div class="article-category tagcloud">
		<i class="icon-book icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="/categories/learning//" class="article-tag-list-link color5">技术学习</a>
        		</li>
      		
		</ul>
	</div>


      

      
        
<div class="share-btn share-icons tooltip-left">
  <div class="tooltip tooltip-east">
    <span class="tooltip-item">
      <a href="javascript:;" class="share-sns share-outer">
        <i class="icon icon-share"></i>
      </a>
    </span>
    <span class="tooltip-content">
      <div class="share-wrap">
        <div class="share-icons">
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="icon icon-weibo"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="icon icon-weixin"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="icon icon-qq"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="icon icon-douban"></i>
          </a>
          <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a>
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="icon icon-facebook"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="icon icon-twitter"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="icon icon-google"></i>
          </a>
        </div>
      </div>
    </span>
  </div>
</div>

<div class="page-modal wx-share js-wx-box">
    <a class="close js-modal-close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="http://bshare.optimix.asia/barCode?site=weixin&url=http:/2019/20190725深度学习笔记/" alt="微信分享二维码">
    </div>
</div>

<div class="mask js-mask"></div>
      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

  
<nav id="article-nav">
  
    <a href="/2019/20190725Tensorflow学习笔记/" id="article-nav-newer" class="article-nav-link-wrap">
      <i class="icon-circle-left"></i>
      <div class="article-nav-title">
        
          Tensorflow学习笔记
        
      </div>
    </a>
  
  
    <a href="/2019/20190724机器学习笔记/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">吴恩达机器学习学习笔记汇总1</div>
      <i class="icon-circle-right"></i>
    </a>
  
</nav>


<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
        <div class="toc-container tooltip-left">
            <i class="icon-font icon-category"></i>
            <div class="tooltip tooltip-east">
                <span class="tooltip-item">
                </span>
                <span class="tooltip-content">
                    <div class="toc-article">
                    <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#课程概述"><span class="toc-number">1.</span> <span class="toc-text">课程概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#深度学习应用"><span class="toc-number">2.</span> <span class="toc-text">深度学习应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#神经网络编程基础"><span class="toc-number">3.</span> <span class="toc-text">神经网络编程基础</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#二分类-Binary-Classification"><span class="toc-number">3.1.</span> <span class="toc-text">二分类(Binary Classification)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#逻辑回归-Logistic-Regression"><span class="toc-number">3.2.</span> <span class="toc-text">逻辑回归(Logistic Regression)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#梯度下降法（Gradient-Descent-）"><span class="toc-number">3.3.</span> <span class="toc-text">梯度下降法（Gradient Descent ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#计算图（Computation-Graph）"><span class="toc-number">3.4.</span> <span class="toc-text">计算图（Computation Graph）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#使用计算图求导数"><span class="toc-number">3.5.</span> <span class="toc-text">使用计算图求导数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#逻辑回归中的梯度下降"><span class="toc-number">3.6.</span> <span class="toc-text">逻辑回归中的梯度下降</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#m-个样本的梯度下降"><span class="toc-number">3.7.</span> <span class="toc-text">m 个样本的梯度下降</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#向量化-Vectorization"><span class="toc-number">3.8.</span> <span class="toc-text">向量化(Vectorization)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#向量化逻辑回归"><span class="toc-number">3.9.</span> <span class="toc-text">向量化逻辑回归</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#向量化-logistic-回归的梯度输出"><span class="toc-number">3.10.</span> <span class="toc-text">向量化 logistic  回归的梯度输出</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Python-中的广播（Broadcasting）"><span class="toc-number">3.11.</span> <span class="toc-text">Python  中的广播（Broadcasting）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#关于numpy向量的说明"><span class="toc-number">3.12.</span> <span class="toc-text">关于numpy向量的说明</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Jupyter-快速入门"><span class="toc-number">3.13.</span> <span class="toc-text">Jupyter 快速入门</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#logistic-损失函数的解释"><span class="toc-number">3.14.</span> <span class="toc-text">logistic  损失函数的解释</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#浅层神经网络"><span class="toc-number"></span> <span class="toc-text">浅层神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#神经网络概述"><span class="toc-number">0.1.</span> <span class="toc-text">神经网络概述</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#神经网络的表示"><span class="toc-number">0.2.</span> <span class="toc-text">神经网络的表示</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#神经网络的计算"><span class="toc-number">0.3.</span> <span class="toc-text">神经网络的计算</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#多样本神经网络的向量化计算"><span class="toc-number">0.4.</span> <span class="toc-text">多样本神经网络的向量化计算</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#向量化实现的解释"><span class="toc-number">0.5.</span> <span class="toc-text">向量化实现的解释</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#激活函数（Activation-functions-）"><span class="toc-number">0.6.</span> <span class="toc-text">激活函数（Activation functions ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#为什么需要非线性激活函数"><span class="toc-number">0.7.</span> <span class="toc-text">为什么需要非线性激活函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#激活函数的导数"><span class="toc-number">0.8.</span> <span class="toc-text">激活函数的导数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#神经网络的梯度下降"><span class="toc-number">0.9.</span> <span class="toc-text">神经网络的梯度下降</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#直观理解反向传播"><span class="toc-number">0.10.</span> <span class="toc-text">直观理解反向传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#随机初始化"><span class="toc-number">0.11.</span> <span class="toc-text">随机初始化</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#深层神经网络"><span class="toc-number">1.</span> <span class="toc-text">深层神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#深层神经网络-1"><span class="toc-number">1.1.</span> <span class="toc-text">深层神经网络</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#前向传播和反向传播"><span class="toc-number">1.2.</span> <span class="toc-text">前向传播和反向传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#深层网络中的前向传播"><span class="toc-number">1.3.</span> <span class="toc-text">深层网络中的前向传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#核对矩阵的维数"><span class="toc-number">1.4.</span> <span class="toc-text">核对矩阵的维数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#为什么使用深层表示"><span class="toc-number">1.5.</span> <span class="toc-text">为什么使用深层表示</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#搭建神经网络块"><span class="toc-number">1.6.</span> <span class="toc-text">搭建神经网络块</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#参数-VS-超参数（Parameters-vs-Hyperparameters-）"><span class="toc-number">1.7.</span> <span class="toc-text">参数 VS  超参数（Parameters vs Hyperparameters ）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#深度学习的实践层面"><span class="toc-number">2.</span> <span class="toc-text">深度学习的实践层面</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#训练，验证，测试集（Train-Dev-Test-sets-）"><span class="toc-number">2.1.</span> <span class="toc-text">训练，验证，测试集（Train / Dev / Test sets ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#偏差，方差（Bias-Variance）"><span class="toc-number">2.2.</span> <span class="toc-text">偏差，方差（Bias /Variance）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#机器学习基础"><span class="toc-number">2.3.</span> <span class="toc-text">机器学习基础</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#正则化（Regularization）"><span class="toc-number">2.4.</span> <span class="toc-text">正则化（Regularization）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#为-什-么-正-则-化-有-利-于-预-防-过-拟-合"><span class="toc-number">2.5.</span> <span class="toc-text">为 什 么 正 则 化 有 利 于 预 防 过 拟 合</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#dropout-正则化（Dropout-Regularization"><span class="toc-number">2.6.</span> <span class="toc-text">dropout  正则化（Dropout Regularization)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#理解-dropout"><span class="toc-number">2.7.</span> <span class="toc-text">理解 dropout</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#其他正则化方法"><span class="toc-number">2.8.</span> <span class="toc-text">其他正则化方法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#归一化输入（Normalizing-inputs"><span class="toc-number">2.9.</span> <span class="toc-text">归一化输入（Normalizing inputs)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#梯度消失-梯度爆炸（Vanishing-Exploding-gradients-）"><span class="toc-number">2.10.</span> <span class="toc-text">梯度消失/ 梯度爆炸（Vanishing / Exploding gradients ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#神经网络的权重初始化"><span class="toc-number">2.11.</span> <span class="toc-text">神经网络的权重初始化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#梯度的数值逼近和梯度检验（Gradient-checking-）"><span class="toc-number">2.12.</span> <span class="toc-text">梯度的数值逼近和梯度检验（Gradient checking ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#梯度检验应用的注意事项"><span class="toc-number">2.13.</span> <span class="toc-text">梯度检验应用的注意事项</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#优化算法-Optimization-algorithms"><span class="toc-number">3.</span> <span class="toc-text">优化算法 (Optimization algorithms)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Mini-batch梯度下降"><span class="toc-number">3.1.</span> <span class="toc-text">Mini-batch梯度下降</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#理解-mini-batch-梯度下降法"><span class="toc-number">3.2.</span> <span class="toc-text">理解 mini-batch  梯度下降法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#指数加权平均数"><span class="toc-number">3.3.</span> <span class="toc-text">指数加权平均数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#指数加权平均的偏差修正"><span class="toc-number">3.4.</span> <span class="toc-text">指数加权平均的偏差修正</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#动量梯度下降法（Gradient-descent-with-Momentum-）"><span class="toc-number">3.5.</span> <span class="toc-text">动量梯度下降法（Gradient descent with Momentum ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#RMSprop"><span class="toc-number">3.6.</span> <span class="toc-text">RMSprop</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Adam-优化算法"><span class="toc-number">3.7.</span> <span class="toc-text">Adam 优化算法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#学习率衰减-Learning-rate-decay"><span class="toc-number">3.8.</span> <span class="toc-text">学习率衰减(Learning rate decay)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#局部最优的问题"><span class="toc-number">3.9.</span> <span class="toc-text">局部最优的问题</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#超-参-数-调-试-Batch-正-则-化-和-程-序-框-架"><span class="toc-number">4.</span> <span class="toc-text">超 参 数 调 试 Batch 正 则 化 和 程 序 框 架</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#调试处理（Tuning-process-）"><span class="toc-number">4.1.</span> <span class="toc-text">调试处理（Tuning process ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#超参数合适的范围"><span class="toc-number">4.2.</span> <span class="toc-text">超参数合适的范围</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#超参数调试实践"><span class="toc-number">4.3.</span> <span class="toc-text">超参数调试实践</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#归一化网络的激活函数：Batch-Norm"><span class="toc-number">4.4.</span> <span class="toc-text">归一化网络的激活函数：Batch Norm</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#将-Batch-Norm-拟合进神经网络"><span class="toc-number">4.5.</span> <span class="toc-text">将 Batch Norm  拟合进神经网络</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#测试时的Batch-Norm"><span class="toc-number">4.6.</span> <span class="toc-text">测试时的Batch Norm</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Softmax-回归（Softmax-regression）"><span class="toc-number">4.7.</span> <span class="toc-text">Softmax  回归（Softmax regression）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#深度学习框架"><span class="toc-number">4.8.</span> <span class="toc-text">深度学习框架</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tensorflow"><span class="toc-number">4.9.</span> <span class="toc-text">tensorflow</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结构化深度学习策略"><span class="toc-number"></span> <span class="toc-text">结构化深度学习策略</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#正交化（Orthogonalization）"><span class="toc-number">0.1.</span> <span class="toc-text">正交化（Orthogonalization）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#单一数字评估指标"><span class="toc-number">0.2.</span> <span class="toc-text">单一数字评估指标</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#满足和优化指标（Satisficing-and-optimizing-metrics-）"><span class="toc-number">0.3.</span> <span class="toc-text">满足和优化指标（Satisficing and optimizing metrics ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#训练-开发-测试集划分"><span class="toc-number">0.4.</span> <span class="toc-text">训练/ 开发/ 测试集划分</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#开发集和测试集的大小"><span class="toc-number">0.5.</span> <span class="toc-text">开发集和测试集的大小</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#什么时候该改变开发-测试集和指标"><span class="toc-number">0.6.</span> <span class="toc-text">什么时候该改变开发/ 测试集和指标</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#为什么是人的表现"><span class="toc-number">0.7.</span> <span class="toc-text">为什么是人的表现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#可避免偏差（Avoidable-bias-）"><span class="toc-number">0.8.</span> <span class="toc-text">可避免偏差（Avoidable bias ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#理解人的表现"><span class="toc-number">0.9.</span> <span class="toc-text">理解人的表现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#超过人的表现"><span class="toc-number">0.10.</span> <span class="toc-text">超过人的表现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#改善你的模型的表现"><span class="toc-number">0.11.</span> <span class="toc-text">改善你的模型的表现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#进行误差分析"><span class="toc-number">0.12.</span> <span class="toc-text">进行误差分析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#清除标注错误的数据"><span class="toc-number">0.13.</span> <span class="toc-text">清除标注错误的数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#快速搭建系统并迭代"><span class="toc-number">0.14.</span> <span class="toc-text">快速搭建系统并迭代</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#不同分布数据进行训练和测试"><span class="toc-number">0.15.</span> <span class="toc-text">不同分布数据进行训练和测试</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#数据分布不匹配时的偏差与方差的分析"><span class="toc-number">0.16.</span> <span class="toc-text">数据分布不匹配时的偏差与方差的分析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#处理数据不匹配问题"><span class="toc-number">0.17.</span> <span class="toc-text">处理数据不匹配问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#迁移学习（Transfer-learning-）"><span class="toc-number">0.18.</span> <span class="toc-text">迁移学习（Transfer learning ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#多任务学习（Multi-task-learning"><span class="toc-number">0.19.</span> <span class="toc-text">多任务学习（Multi-task learning)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#端到端的深度学习"><span class="toc-number">0.20.</span> <span class="toc-text">端到端的深度学习</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#卷积神经网络基础"><span class="toc-number"></span> <span class="toc-text">卷积神经网络基础</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#计算机视觉（Computer-vision）"><span class="toc-number">0.1.</span> <span class="toc-text">计算机视觉（Computer vision）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#边缘检测示例（Edge-detection-example-）"><span class="toc-number">0.2.</span> <span class="toc-text">边缘检测示例（Edge detection example ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#更多边缘检测内容"><span class="toc-number">0.3.</span> <span class="toc-text">更多边缘检测内容</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Padding"><span class="toc-number">0.4.</span> <span class="toc-text">Padding</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#卷积步长（Strided-convolutions）"><span class="toc-number">0.5.</span> <span class="toc-text">卷积步长（Strided convolutions）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#三维卷积（Convolutions-over-volumes）"><span class="toc-number">0.6.</span> <span class="toc-text">三维卷积（Convolutions over volumes）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#单层卷积网络"><span class="toc-number">0.7.</span> <span class="toc-text">单层卷积网络</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#简单卷积网络示例"><span class="toc-number">0.8.</span> <span class="toc-text">简单卷积网络示例</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#池化层（Pooling-layers"><span class="toc-number">0.9.</span> <span class="toc-text">池化层（Pooling layers)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#卷积神经网络示例"><span class="toc-number">0.10.</span> <span class="toc-text">卷积神经网络示例</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#全连接层"><span class="toc-number">0.11.</span> <span class="toc-text">全连接层</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#为什么使用卷积"><span class="toc-number">0.12.</span> <span class="toc-text">为什么使用卷积</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#深度卷积网络：实例探究"><span class="toc-number"></span> <span class="toc-text">深度卷积网络：实例探究</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#经典网络（Classic-networks-）"><span class="toc-number">0.1.</span> <span class="toc-text">经典网络（Classic networks ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#残差网络-ResNets-Residual-Networks"><span class="toc-number">0.2.</span> <span class="toc-text">残差网络(ResNets)(Residual Networks)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#残差网络为什么有用"><span class="toc-number">0.3.</span> <span class="toc-text">残差网络为什么有用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#1×1-卷积"><span class="toc-number">0.4.</span> <span class="toc-text">1×1  卷积</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#谷歌-Inception-网络思想"><span class="toc-number">0.5.</span> <span class="toc-text">谷歌 Inception  网络思想</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Inception-网络（Inception-network-）"><span class="toc-number">0.6.</span> <span class="toc-text">Inception  网络（Inception network ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#迁移学习（Transfer-Learning）"><span class="toc-number">0.7.</span> <span class="toc-text">迁移学习（Transfer Learning）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#数据增强（-Data-augmentation-）"><span class="toc-number">0.8.</span> <span class="toc-text">数据增强（ Data augmentation ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#计算机视觉现状"><span class="toc-number">0.9.</span> <span class="toc-text">计算机视觉现状</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#目标检测（-Object-detection-）"><span class="toc-number"></span> <span class="toc-text">目标检测（ Object detection ）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#目标定位（Object-localization）"><span class="toc-number">0.1.</span> <span class="toc-text">目标定位（Object localization）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#特征点检测（Landmark-detection）"><span class="toc-number">0.2.</span> <span class="toc-text">特征点检测（Landmark detection）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#目标检测（Object-detection"><span class="toc-number">0.3.</span> <span class="toc-text">目标检测（Object detection)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#滑动窗口的卷积实现"><span class="toc-number">0.4.</span> <span class="toc-text">滑动窗口的卷积实现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Bounding-Box-预测（Bounding-box-predictions-）"><span class="toc-number">0.5.</span> <span class="toc-text">Bounding Box  预测（Bounding box predictions ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#交并比（Intersection-over-union）"><span class="toc-number">0.6.</span> <span class="toc-text">交并比（Intersection over union）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#非极大值抑制（Non-max-suppression-）"><span class="toc-number">0.7.</span> <span class="toc-text">非极大值抑制（Non-max suppression ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Anchor-Boxes"><span class="toc-number">0.8.</span> <span class="toc-text">Anchor Boxes</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#YOLO-算法（YOLO-algorithm-）"><span class="toc-number">0.9.</span> <span class="toc-text">YOLO  算法（YOLO algorithm ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#候选区域（Region-proposals）"><span class="toc-number">0.10.</span> <span class="toc-text">候选区域（Region proposals）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#人脸识别"><span class="toc-number">1.</span> <span class="toc-text">人脸识别</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#One-Shot-学习（One-shot-learning-）"><span class="toc-number">1.1.</span> <span class="toc-text">One-Shot  学习（One-shot learning ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Siamese-网络（Siamese-network"><span class="toc-number">1.2.</span> <span class="toc-text">Siamese  网络（Siamese network)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Triplet-损失"><span class="toc-number">1.3.</span> <span class="toc-text">Triplet  损失</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#人脸验证与二分类（-Face-verification-and-binary-classification"><span class="toc-number">1.4.</span> <span class="toc-text">人脸验证与二分类（ Face verification and binary classification)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#神经风格迁移"><span class="toc-number">2.</span> <span class="toc-text">神经风格迁移</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#深度卷积网络-学习什么（What-are-deep-ConvNetslearning-）"><span class="toc-number">2.1.</span> <span class="toc-text">深度卷积网络 学习什么（What are deep ConvNetslearning ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#代价函数（Cost-function-）"><span class="toc-number">2.2.</span> <span class="toc-text">代价函数（Cost function ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#内容代价函数（Content-cost-function-）"><span class="toc-number">2.3.</span> <span class="toc-text">内容代价函数（Content cost function ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#风格代价函数（Style-cost-function-）"><span class="toc-number">2.4.</span> <span class="toc-text">风格代价函数（Style cost function ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#一维到三维推广（1D-and-3D-generalizations-of-models）"><span class="toc-number">2.5.</span> <span class="toc-text">一维到三维推广（1D and 3D generalizations of models）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#循环神经网络"><span class="toc-number"></span> <span class="toc-text">循环神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#为什么选择序列模型？"><span class="toc-number">0.1.</span> <span class="toc-text">为什么选择序列模型？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#序列模型数学符号"><span class="toc-number">0.2.</span> <span class="toc-text">序列模型数学符号</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#循环神经网络模型（Recurrent-Neural-Network-Model"><span class="toc-number">0.3.</span> <span class="toc-text">循环神经网络模型（Recurrent Neural Network Model)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#RNN的反向传播"><span class="toc-number">0.4.</span> <span class="toc-text">RNN的反向传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#不同类型的循环神经网络"><span class="toc-number">0.5.</span> <span class="toc-text">不同类型的循环神经网络</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#语言模型和序列生成"><span class="toc-number">0.6.</span> <span class="toc-text">语言模型和序列生成</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#对新序列采样（Sampling-novel-sequences-）"><span class="toc-number">0.7.</span> <span class="toc-text">对新序列采样（Sampling novel sequences ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#循环神经网络的梯度消失（Vanishing-gradients-with-RNNs）"><span class="toc-number">0.8.</span> <span class="toc-text">循环神经网络的梯度消失（Vanishing gradients with RNNs）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#GRU-单元（Gated-Recurrent-Unit-（GRU-））"><span class="toc-number">0.9.</span> <span class="toc-text">GRU  单元（Gated Recurrent Unit （GRU ））</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#长短期记忆（LSTM-（long-short-term-memory-）unit-）"><span class="toc-number">0.10.</span> <span class="toc-text">长短期记忆（LSTM （long short term memory ）unit ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#双向循环神经网络（Bidirectional-RNN-）"><span class="toc-number">0.11.</span> <span class="toc-text">双向循环神经网络（Bidirectional RNN ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#深层循环神经网络（Deep-RNNs-）"><span class="toc-number">0.12.</span> <span class="toc-text">深层循环神经网络（Deep RNNs ）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#自然语言处理与词嵌入"><span class="toc-number"></span> <span class="toc-text">自然语言处理与词嵌入</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#词汇表征（Word-Representation-）"><span class="toc-number">0.1.</span> <span class="toc-text">词汇表征（Word Representation ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#使用词嵌入"><span class="toc-number">0.2.</span> <span class="toc-text">使用词嵌入</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#词嵌入的特性"><span class="toc-number">0.3.</span> <span class="toc-text">词嵌入的特性</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#嵌入矩阵（Embedding-Matrix"><span class="toc-number">0.4.</span> <span class="toc-text">嵌入矩阵（Embedding Matrix)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#学习词嵌入"><span class="toc-number">0.5.</span> <span class="toc-text">学习词嵌入</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Word2Vec"><span class="toc-number">0.6.</span> <span class="toc-text">Word2Vec</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#负采样（Negative-Sampling"><span class="toc-number">0.7.</span> <span class="toc-text">负采样（Negative Sampling)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#GloVe-词向量（GloVe-Word-Vectors"><span class="toc-number">0.8.</span> <span class="toc-text">GloVe  词向量（GloVe Word Vectors)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#情感分类（Sentiment-Classification"><span class="toc-number">0.9.</span> <span class="toc-text">情感分类（Sentiment Classification</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#词嵌入除偏（Debiasing-Word-Embeddings"><span class="toc-number">0.10.</span> <span class="toc-text">词嵌入除偏（Debiasing Word Embeddings)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#序列模型和注意力机制"><span class="toc-number"></span> <span class="toc-text">序列模型和注意力机制</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#序列结构的各种序列"><span class="toc-number">0.1.</span> <span class="toc-text">序列结构的各种序列</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#选择最可能的句子"><span class="toc-number">0.2.</span> <span class="toc-text">选择最可能的句子</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#集束搜索（Beam-Search-）"><span class="toc-number">0.3.</span> <span class="toc-text">集束搜索（Beam Search ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#改进集束搜索"><span class="toc-number">0.4.</span> <span class="toc-text">改进集束搜索</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#集束搜索的误差分析"><span class="toc-number">0.5.</span> <span class="toc-text">集束搜索的误差分析</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Bleu得分"><span class="toc-number">0.6.</span> <span class="toc-text">Bleu得分</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#注意力机制（Attention-Model）"><span class="toc-number">0.7.</span> <span class="toc-text">注意力机制（Attention Model）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#语音识别（Speech-recognition-）"><span class="toc-number">0.8.</span> <span class="toc-text">语音识别（Speech recognition ）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#触发字检测（Trigger-Word-Detection"><span class="toc-number">0.9.</span> <span class="toc-text">触发字检测（Trigger Word Detection)</span></a></li></ol></li></ol>
                    </div>
                </span>
            </div>
        </div>
        
    </div>
</aside>



  
  
  

  

  

  
    
	
	  <section id="comments" class="comments">
		<style>
		  .comments{margin:30px;padding:10px;background:#fff}
		  @media screen and (max-width:800px){.comments{margin:auto;padding:10px;background:#fff}}
		</style>
		<div id="vcomment" class="comment"></div>
<script src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script>
<script src="//cdn.jsdelivr.net/npm/leancloud-storage/dist/av-min.js"></script>
<script src='//cdn.jsdelivr.net/npm/valine/dist/Valine.min.js'></script>
<script>
   var notify = 'false' == true ? true : false;
   var verify = 'false' == true ? true : false;
   new Valine({
            av: AV,
            el: '#vcomment',
            notify: notify,
            verify: verify,
            app_id: "8Krq24SNwAuetFahF7XbCDY0-gzGzoHsz",
            app_key: "waqSnwyci4BiQnlGr4qOXGPG",
            placeholder: "瞎白话",
            avatar: "",
            avatar_cdn: "https://sdn.geekzu.org/avatar/",
            pageSize: 15
    });
    if(window.location.hash){
          var checkExist = setInterval(function() {
            if (document.getElementById(window.location.hash.replace("#",""))) {
              location.href = window.location.hash;
              clearInterval(checkExist);
            }
          }, 250);
        }
</script>
	  </section>
	
	


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2023 方既白
    	</div>
		<span id="busuanzi_container_site_pv">
			本站总访问量<span id="busuanzi_value_site_pv"></span>次
		</span>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: true,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 50%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有</a></li>
      
        
      
        
      
      <li style="width: 50%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">基础</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">复习</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">Git</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">项目</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">C</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">面试</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Java</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">web</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">机器学习</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color2">python</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color1">Linux</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color4">分布式</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color5">Code</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">随笔</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">摄影</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">金融</a>
              </li>
             
              <li class="article-tag-list-item">
                <a href="javascript:void(0)" class="js-tag color3">游戏</a>
              </li>
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">周思远&lt;br/&gt;
大工软院19届&lt;br/&gt;
毕业于华科&lt;br/&gt;
就职于鹅厂&lt;br/&gt;
编程新手一枚&lt;br/&gt;
热爱动漫与大海&lt;br/&gt;
会的不深，项目不强&lt;br/&gt;
写写博客，记录生活
</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>